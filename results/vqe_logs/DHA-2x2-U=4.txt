spin up orbital energies: {0: -2.0, 2: 0, 4: 0, 6: 2.0}
spin down orbital energies:  {1: -2.0, 3: 0, 5: 0, 7: 2.0}
spin up indices:  [0, 2]    spin down indices:  [1, 3] 

ground state energy:  -2.102748483462071
particle number:  4

learning rate =  0.0999999982885729
Find operators
1j [1^ 0^ 5 4] + -1j [5^ 4^ 1 0]
1j [1^ 0^ 7 6] + -1j [7^ 6^ 1 0]
1j [3^ 0^ 7 4] + -1j [7^ 4^ 3 0]
1j [3^ 2^ 5 4] + -1j [5^ 4^ 3 2]
1j [3^ 2^ 7 6] + -1j [7^ 6^ 3 2]
-1j [2^ 1^ 7 4] + 1j [7^ 4^ 2 1]
1j [2^ 1^ 6 5] + -1j [6^ 5^ 2 1]
-1j [3^ 0^ 6 5] + 1j [6^ 5^ 3 0]
with max gradients
[2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0]

iter: 1 | loss: -0.000000 | norm:  5.656854 | fidelity:  0.424914 | Sz:  0.000000 | S^2: -0.000000
iter: 2 | loss: -1.236918 | norm:  3.170238 | fidelity:  0.585334 | Sz:  0.000000 | S^2:  0.000024
iter: 3 | loss: -1.676207 | norm:  1.847928 | fidelity:  0.678290 | Sz:  0.000000 | S^2:  0.001120
iter: 4 | loss: -1.630161 | norm:  2.459890 | fidelity:  0.713741 | Sz:  0.000000 | S^2:  0.006122
iter: 5 | loss: -1.522143 | norm:  2.852999 | fidelity:  0.739124 | Sz: -0.000000 | S^2:  0.011387
iter: 6 | loss: -1.525012 | norm:  2.702197 | fidelity:  0.775101 | Sz: -0.000000 | S^2:  0.011019
iter: 7 | loss: -1.605387 | norm:  2.317704 | fidelity:  0.818434 | Sz:  0.000000 | S^2:  0.006421
iter: 8 | loss: -1.697125 | norm:  2.015003 | fidelity:  0.861482 | Sz:  0.000000 | S^2:  0.002135
iter: 9 | loss: -1.773858 | norm:  1.846393 | fidelity:  0.899352 | Sz:  0.000000 | S^2:  0.000405
iter: 10 | loss: -1.832067 | norm:  1.680365 | fidelity:  0.929221 | Sz: -0.000000 | S^2:  0.000401
iter: 11 | loss: -1.868498 | norm:  1.507873 | fidelity:  0.949941 | Sz: -0.000000 | S^2:  0.000453
iter: 12 | loss: -1.884584 | norm:  1.431580 | fidelity:  0.962735 | Sz:  0.000000 | S^2:  0.000356
iter: 13 | loss: -1.888206 | norm:  1.496122 | fidelity:  0.969882 | Sz:  0.000000 | S^2:  0.002702
iter: 14 | loss: -1.890445 | norm:  1.599536 | fidelity:  0.973294 | Sz:  0.000000 | S^2:  0.011888
iter: 15 | loss: -1.901681 | norm:  1.596802 | fidelity:  0.974212 | Sz:  0.000000 | S^2:  0.031925
iter: 16 | loss: -1.923462 | norm:  1.423668 | fidelity:  0.972942 | Sz: -0.000000 | S^2:  0.065169
iter: 17 | loss: -1.945753 | norm:  1.131325 | fidelity:  0.968983 | Sz: -0.000000 | S^2:  0.111220
iter: 18 | loss: -1.955724 | norm:  0.890038 | fidelity:  0.962088 | Sz:  0.000000 | S^2:  0.165450
iter: 19 | loss: -1.948910 | norm:  0.905490 | fidelity:  0.953325 | Sz: -0.000000 | S^2:  0.218847
iter: 20 | loss: -1.932839 | norm:  1.099684 | fidelity:  0.945023 | Sz:  0.000000 | S^2:  0.260715
iter: 21 | loss: -1.921036 | norm:  1.251981 | fidelity:  0.939655 | Sz:  0.000000 | S^2:  0.282965
iter: 22 | loss: -1.923256 | norm:  1.261838 | fidelity:  0.938592 | Sz: -0.000000 | S^2:  0.282845
iter: 23 | loss: -1.939860 | norm:  1.125197 | fidelity:  0.941607 | Sz:  0.000000 | S^2:  0.262832
iter: 24 | loss: -1.963362 | norm:  0.897557 | fidelity:  0.947251 | Sz: -0.000000 | S^2:  0.228811
iter: 25 | loss: -1.984337 | norm:  0.684346 | fidelity:  0.953671 | Sz: -0.000000 | S^2:  0.187879
iter: 26 | loss: -1.997199 | norm:  0.611869 | fidelity:  0.959422 | Sz:  0.000000 | S^2:  0.146441
iter: 27 | loss: -2.002310 | norm:  0.675835 | fidelity:  0.963836 | Sz:  0.000000 | S^2:  0.108993
iter: 28 | loss: -2.003750 | norm:  0.745260 | fidelity:  0.966876 | Sz:  0.000000 | S^2:  0.077915
iter: 29 | loss: -2.005184 | norm:  0.746960 | fidelity:  0.968650 | Sz: -0.000000 | S^2:  0.054038
iter: 30 | loss: -2.007482 | norm:  0.682808 | fidelity:  0.969082 | Sz:  0.000000 | S^2:  0.037321
iter: 31 | loss: -2.009343 | norm:  0.598418 | fidelity:  0.967956 | Sz: -0.000000 | S^2:  0.027148
iter: 32 | loss: -2.009528 | norm:  0.549726 | fidelity:  0.965202 | Sz: -0.000000 | S^2:  0.022398
iter: 33 | loss: -2.008366 | norm:  0.551010 | fidelity:  0.961100 | Sz:  0.000000 | S^2:  0.021598
iter: 34 | loss: -2.007441 | norm:  0.565330 | fidelity:  0.956261 | Sz: -0.000000 | S^2:  0.023313
iter: 35 | loss: -2.008107 | norm:  0.560435 | fidelity:  0.951411 | Sz:  0.000000 | S^2:  0.026536
iter: 36 | loss: -2.010549 | norm:  0.534796 | fidelity:  0.947169 | Sz: -0.000000 | S^2:  0.030833
iter: 37 | loss: -2.014010 | norm:  0.500693 | fidelity:  0.943925 | Sz: -0.000000 | S^2:  0.036154
iter: 38 | loss: -2.017479 | norm:  0.461589 | fidelity:  0.941815 | Sz: -0.000000 | S^2:  0.042476
iter: 39 | loss: -2.020092 | norm:  0.411898 | fidelity:  0.940791 | Sz: -0.000000 | S^2:  0.049485
iter: 40 | loss: -2.021255 | norm:  0.359831 | fidelity:  0.940751 | Sz: -0.000000 | S^2:  0.056503
iter: 41 | loss: -2.020848 | norm:  0.341224 | fidelity:  0.941638 | Sz:  0.000000 | S^2:  0.062678
iter: 42 | loss: -2.019619 | norm:  0.376578 | fidelity:  0.943483 | Sz:  0.000000 | S^2:  0.067322
iter: 43 | loss: -2.019099 | norm:  0.424204 | fidelity:  0.946319 | Sz:  0.000000 | S^2:  0.070185
iter: 44 | loss: -2.020635 | norm:  0.429472 | fidelity:  0.950022 | Sz:  0.000000 | S^2:  0.071491
iter: 45 | loss: -2.024162 | norm:  0.366349 | fidelity:  0.954202 | Sz:  0.000000 | S^2:  0.071747
iter: 46 | loss: -2.027952 | norm:  0.241947 | fidelity:  0.958256 | Sz:  0.000000 | S^2:  0.071472
iter: 47 | loss: -2.029874 | norm:  0.106681 | fidelity:  0.961612 | Sz:  0.000000 | S^2:  0.071007
iter: 48 | loss: -2.029102 | norm:  0.144562 | fidelity:  0.964003 | Sz:  0.000000 | S^2:  0.070483
iter: 49 | loss: -2.026702 | norm:  0.256460 | fidelity:  0.965530 | Sz:  0.000000 | S^2:  0.069902
iter: 50 | loss: -2.024681 | norm:  0.315650 | fidelity:  0.966514 | Sz:  0.000000 | S^2:  0.069263
iter: 51 | loss: -2.024320 | norm:  0.308298 | fidelity:  0.967195 | Sz: -0.000000 | S^2:  0.068633
iter: 52 | loss: -2.025467 | norm:  0.250881 | fidelity:  0.967617 | Sz:  0.000000 | S^2:  0.068168
iter: 53 | loss: -2.027017 | norm:  0.184006 | fidelity:  0.967640 | Sz: -0.000000 | S^2:  0.068061
iter: 54 | loss: -2.028052 | norm:  0.161097 | fidelity:  0.967126 | Sz:  0.000000 | S^2:  0.068459
iter: 55 | loss: -2.028432 | norm:  0.181146 | fidelity:  0.966060 | Sz:  0.000000 | S^2:  0.069378
iter: 56 | loss: -2.028546 | norm:  0.195139 | fidelity:  0.964565 | Sz: -0.000000 | S^2:  0.070668
iter: 57 | loss: -2.028701 | norm:  0.186467 | fidelity:  0.962816 | Sz: -0.000000 | S^2:  0.072040
iter: 58 | loss: -2.028929 | norm:  0.167030 | fidelity:  0.960994 | Sz:  0.000000 | S^2:  0.073147
iter: 59 | loss: -2.029139 | norm:  0.153151 | fidelity:  0.959253 | Sz:  0.000000 | S^2:  0.073675
iter: 60 | loss: -2.029293 | norm:  0.146097 | fidelity:  0.957731 | Sz:  0.000000 | S^2:  0.073400
iter: 61 | loss: -2.029406 | norm:  0.138364 | fidelity:  0.956548 | Sz:  0.000000 | S^2:  0.072201
iter: 62 | loss: -2.029475 | norm:  0.131958 | fidelity:  0.955811 | Sz: -0.000000 | S^2:  0.070070
iter: 63 | loss: -2.029487 | norm:  0.133981 | fidelity:  0.955577 | Sz:  0.000000 | S^2:  0.067127
iter: 64 | loss: -2.029500 | norm:  0.138429 | fidelity:  0.955839 | Sz:  0.000000 | S^2:  0.063648
iter: 65 | loss: -2.029611 | norm:  0.130772 | fidelity:  0.956516 | Sz:  0.000000 | S^2:  0.060055
iter: 66 | loss: -2.029795 | norm:  0.106627 | fidelity:  0.957446 | Sz: -0.000000 | S^2:  0.056835
iter: 67 | loss: -2.029913 | norm:  0.082811 | fidelity:  0.958430 | Sz:  0.000000 | S^2:  0.054432
iter: 68 | loss: -2.029873 | norm:  0.088773 | fidelity:  0.959291 | Sz: -0.000000 | S^2:  0.053141
iter: 69 | loss: -2.029767 | norm:  0.111315 | fidelity:  0.959925 | Sz:  0.000000 | S^2:  0.053080
iter: 70 | loss: -2.029769 | norm:  0.119533 | fidelity:  0.960291 | Sz:  0.000000 | S^2:  0.054204
iter: 71 | loss: -2.029963 | norm:  0.104132 | fidelity:  0.960414 | Sz:  0.000000 | S^2:  0.056349
iter: 72 | loss: -2.030215 | norm:  0.074575 | fidelity:  0.960333 | Sz: -0.000000 | S^2:  0.059254
iter: 73 | loss: -2.030365 | norm:  0.057537 | fidelity:  0.960128 | Sz: -0.000000 | S^2:  0.062563
iter: 74 | loss: -2.030378 | norm:  0.067965 | fidelity:  0.959902 | Sz: -0.000000 | S^2:  0.065845
iter: 75 | loss: -2.030324 | norm:  0.078569 | fidelity:  0.959751 | Sz: -0.000000 | S^2:  0.068658
iter: 76 | loss: -2.030298 | norm:  0.075545 | fidelity:  0.959749 | Sz: -0.000000 | S^2:  0.070648
iter: 77 | loss: -2.030289 | norm:  0.065749 | fidelity:  0.959902 | Sz: -0.000000 | S^2:  0.071639
iter: 78 | loss: -2.030273 | norm:  0.062777 | fidelity:  0.960178 | Sz: -0.000000 | S^2:  0.071654
iter: 79 | loss: -2.030269 | norm:  0.066309 | fidelity:  0.960523 | Sz:  0.000000 | S^2:  0.070888
iter: 80 | loss: -2.030299 | norm:  0.064650 | fidelity:  0.960866 | Sz: -0.000000 | S^2:  0.069621
iter: 81 | loss: -2.030358 | norm:  0.054527 | fidelity:  0.961144 | Sz: -0.000000 | S^2:  0.068149
iter: 82 | loss: -2.030416 | norm:  0.044718 | fidelity:  0.961319 | Sz: -0.000000 | S^2:  0.066725
iter: 83 | loss: -2.030446 | norm:  0.045161 | fidelity:  0.961373 | Sz: -0.000000 | S^2:  0.065524
iter: 84 | loss: -2.030447 | norm:  0.048912 | fidelity:  0.961306 | Sz:  0.000000 | S^2:  0.064636
iter: 85 | loss: -2.030454 | norm:  0.046331 | fidelity:  0.961142 | Sz:  0.000000 | S^2:  0.064065
iter: 86 | loss: -2.030462 | norm:  0.039137 | fidelity:  0.960902 | Sz: -0.000000 | S^2:  0.063751
iter: 87 | loss: -2.030465 | norm:  0.036708 | fidelity:  0.960611 | Sz: -0.000000 | S^2:  0.063603
iter: 88 | loss: -2.030464 | norm:  0.040209 | fidelity:  0.960290 | Sz:  0.000000 | S^2:  0.063528
iter: 89 | loss: -2.030480 | norm:  0.040137 | fidelity:  0.959965 | Sz:  0.000000 | S^2:  0.063465
iter: 90 | loss: -2.030507 | norm:  0.032338 | fidelity:  0.959658 | Sz: -0.000000 | S^2:  0.063391
iter: 91 | loss: -2.030523 | norm:  0.022554 | fidelity:  0.959392 | Sz: -0.000000 | S^2:  0.063322
iter: 92 | loss: -2.030509 | norm:  0.023720 | fidelity:  0.959188 | Sz:  0.000000 | S^2:  0.063293
iter: 93 | loss: -2.030491 | norm:  0.031324 | fidelity:  0.959076 | Sz:  0.000000 | S^2:  0.063341
iter: 94 | loss: -2.030480 | norm:  0.034094 | fidelity:  0.959062 | Sz: -0.000000 | S^2:  0.063486
iter: 95 | loss: -2.030495 | norm:  0.030524 | fidelity:  0.959153 | Sz: -0.000000 | S^2:  0.063724
iter: 96 | loss: -2.030519 | norm:  0.024326 | fidelity:  0.959329 | Sz: -0.000000 | S^2:  0.064023
iter: 97 | loss: -2.030539 | norm:  0.019824 | fidelity:  0.959564 | Sz:  0.000000 | S^2:  0.064335
iter: 98 | loss: -2.030549 | norm:  0.017820 | fidelity:  0.959831 | Sz:  0.000000 | S^2:  0.064606
iter: 99 | loss: -2.030544 | norm:  0.017660 | fidelity:  0.960096 | Sz:  0.000000 | S^2:  0.064793
iter: 100 | loss: -2.030540 | norm:  0.019931 | fidelity:  0.960341 | Sz: -0.000000 | S^2:  0.064877
iter: 101 | loss: -2.030533 | norm:  0.022485 | fidelity:  0.960541 | Sz: -0.000000 | S^2:  0.064868
iter: 102 | loss: -2.030535 | norm:  0.021655 | fidelity:  0.960682 | Sz: -0.000000 | S^2:  0.064807
iter: 103 | loss: -2.030539 | norm:  0.016541 | fidelity:  0.960753 | Sz:  0.000000 | S^2:  0.064749
iter: 104 | loss: -2.030548 | norm:  0.011509 | fidelity:  0.960753 | Sz:  0.000000 | S^2:  0.064750
iter: 105 | loss: -2.030543 | norm:  0.013829 | fidelity:  0.960683 | Sz:  0.000000 | S^2:  0.064841
iter: 106 | loss: -2.030538 | norm:  0.017736 | fidelity:  0.960560 | Sz: -0.000000 | S^2:  0.065026
iter: 107 | loss: -2.030545 | norm:  0.017134 | fidelity:  0.960409 | Sz: -0.000000 | S^2:  0.065269
iter: 108 | loss: -2.030548 | norm:  0.012174 | fidelity:  0.960247 | Sz: -0.000000 | S^2:  0.065509
iter: 109 | loss: -2.030551 | norm:  0.008302 | fidelity:  0.960103 | Sz:  0.000000 | S^2:  0.065676

learning rate =  0.0088366226915555
Find operators
-1j [5^ 0^ 6 3] + 1j [6^ 3^ 5 0]
1j [4^ 1^ 7 2] + -1j [7^ 2^ 4 1]
1j [4^ 1^ 6 3] + -1j [6^ 3^ 4 1]
1j [5^ 0^ 7 2] + -1j [7^ 2^ 5 0]
1j [1^ 0^ 3 2] + -1j [3^ 2^ 1 0]
1j [5^ 4^ 7 6] + -1j [7^ 6^ 5 4]
with max gradients
[0.27769035, 0.27769032, 0.12462932, 0.12259029, 0.036553204, 0.035851486]

iter: 110 | loss: -2.030551 | norm:  0.433050 | fidelity:  0.959996 | Sz:  0.000000 | S^2:  0.065707
iter: 111 | loss: -2.034576 | norm:  0.519663 | fidelity:  0.960435 | Sz: -0.000000 | S^2:  0.053334
iter: 112 | loss: -2.042040 | norm:  0.403800 | fidelity:  0.961429 | Sz: -0.000000 | S^2:  0.049119
iter: 113 | loss: -2.047849 | norm:  0.372831 | fidelity:  0.963725 | Sz:  0.000000 | S^2:  0.050230
iter: 114 | loss: -2.053005 | norm:  0.371403 | fidelity:  0.966471 | Sz:  0.000000 | S^2:  0.048733
iter: 115 | loss: -2.057839 | norm:  0.357408 | fidelity:  0.969125 | Sz:  0.000000 | S^2:  0.045967
iter: 116 | loss: -2.062553 | norm:  0.337179 | fidelity:  0.971824 | Sz:  0.000000 | S^2:  0.041311
iter: 117 | loss: -2.067335 | norm:  0.315086 | fidelity:  0.974677 | Sz:  0.000000 | S^2:  0.035539
iter: 118 | loss: -2.072061 | norm:  0.293750 | fidelity:  0.977650 | Sz: -0.000000 | S^2:  0.029766
iter: 119 | loss: -2.076546 | norm:  0.277305 | fidelity:  0.980659 | Sz: -0.000000 | S^2:  0.024423
iter: 120 | loss: -2.080631 | norm:  0.267589 | fidelity:  0.983590 | Sz:  0.000000 | S^2:  0.019557
iter: 121 | loss: -2.084289 | norm:  0.260131 | fidelity:  0.986341 | Sz:  0.000000 | S^2:  0.015152
iter: 122 | loss: -2.087610 | norm:  0.246498 | fidelity:  0.988839 | Sz:  0.000000 | S^2:  0.011264
iter: 123 | loss: -2.090659 | norm:  0.221581 | fidelity:  0.991043 | Sz:  0.000000 | S^2:  0.007979
iter: 124 | loss: -2.093385 | norm:  0.188936 | fidelity:  0.992947 | Sz:  0.000000 | S^2:  0.005348
iter: 125 | loss: -2.095689 | norm:  0.158985 | fidelity:  0.994576 | Sz:  0.000000 | S^2:  0.003365
iter: 126 | loss: -2.097565 | norm:  0.138635 | fidelity:  0.995969 | Sz: -0.000000 | S^2:  0.001971
iter: 127 | loss: -2.099106 | norm:  0.122089 | fidelity:  0.997156 | Sz: -0.000000 | S^2:  0.001060
iter: 128 | loss: -2.100390 | norm:  0.099426 | fidelity:  0.998146 | Sz:  0.000000 | S^2:  0.000507
iter: 129 | loss: -2.101374 | norm:  0.069816 | fidelity:  0.998916 | Sz:  0.000000 | S^2:  0.000196
iter: 130 | loss: -2.102000 | norm:  0.046315 | fidelity:  0.999454 | Sz: -0.000000 | S^2:  0.000045
iter: 131 | loss: -2.102276 | norm:  0.048230 | fidelity:  0.999769 | Sz: -0.000000 | S^2:  0.000003
iter: 132 | loss: -2.102311 | norm:  0.061739 | fidelity:  0.999906 | Sz: -0.000000 | S^2:  0.000054
iter: 133 | loss: -2.102211 | norm:  0.070796 | fidelity:  0.999915 | Sz: -0.000000 | S^2:  0.000202
iter: 134 | loss: -2.102025 | norm:  0.076840 | fidelity:  0.999833 | Sz: -0.000000 | S^2:  0.000461
iter: 135 | loss: -2.101777 | norm:  0.084310 | fidelity:  0.999692 | Sz:  0.000000 | S^2:  0.000829
iter: 136 | loss: -2.101491 | norm:  0.092262 | fidelity:  0.999504 | Sz:  0.000000 | S^2:  0.001281
iter: 137 | loss: -2.101236 | norm:  0.097424 | fidelity:  0.999303 | Sz: -0.000000 | S^2:  0.001763
iter: 138 | loss: -2.101023 | norm:  0.099526 | fidelity:  0.999106 | Sz:  0.000000 | S^2:  0.002211
iter: 139 | loss: -2.100845 | norm:  0.100393 | fidelity:  0.998930 | Sz:  0.000000 | S^2:  0.002572
iter: 140 | loss: -2.100732 | norm:  0.100318 | fidelity:  0.998808 | Sz: -0.000000 | S^2:  0.002813
iter: 141 | loss: -2.100691 | norm:  0.098243 | fidelity:  0.998747 | Sz:  0.000000 | S^2:  0.002925
iter: 142 | loss: -2.100736 | norm:  0.095139 | fidelity:  0.998753 | Sz: -0.000000 | S^2:  0.002913
iter: 143 | loss: -2.100832 | norm:  0.093788 | fidelity:  0.998809 | Sz:  0.000000 | S^2:  0.002789
iter: 144 | loss: -2.100967 | norm:  0.093987 | fidelity:  0.998900 | Sz: -0.000000 | S^2:  0.002568
iter: 145 | loss: -2.101142 | norm:  0.091390 | fidelity:  0.999011 | Sz: -0.000000 | S^2:  0.002264
iter: 146 | loss: -2.101358 | norm:  0.082741 | fidelity:  0.999134 | Sz:  0.000000 | S^2:  0.001901
iter: 147 | loss: -2.101587 | norm:  0.069756 | fidelity:  0.999261 | Sz:  0.000000 | S^2:  0.001507
iter: 148 | loss: -2.101799 | norm:  0.057894 | fidelity:  0.999388 | Sz:  0.000000 | S^2:  0.001118
iter: 149 | loss: -2.101977 | norm:  0.050823 | fidelity:  0.999511 | Sz:  0.000000 | S^2:  0.000768
iter: 150 | loss: -2.102129 | norm:  0.046407 | fidelity:  0.999626 | Sz:  0.000000 | S^2:  0.000482
iter: 151 | loss: -2.102263 | norm:  0.041245 | fidelity:  0.999730 | Sz:  0.000000 | S^2:  0.000268
iter: 152 | loss: -2.102366 | norm:  0.035033 | fidelity:  0.999812 | Sz: -0.000000 | S^2:  0.000124
iter: 153 | loss: -2.102446 | norm:  0.028866 | fidelity:  0.999873 | Sz: -0.000000 | S^2:  0.000040
iter: 154 | loss: -2.102512 | norm:  0.023462 | fidelity:  0.999917 | Sz:  0.000000 | S^2:  0.000004
iter: 155 | loss: -2.102548 | norm:  0.020561 | fidelity:  0.999940 | Sz:  0.000000 | S^2:  0.000004
iter: 156 | loss: -2.102574 | norm:  0.021564 | fidelity:  0.999954 | Sz:  0.000000 | S^2:  0.000030
iter: 157 | loss: -2.102581 | norm:  0.023693 | fidelity:  0.999959 | Sz: -0.000000 | S^2:  0.000071
iter: 158 | loss: -2.102588 | norm:  0.024659 | fidelity:  0.999962 | Sz: -0.000000 | S^2:  0.000119
iter: 159 | loss: -2.102582 | norm:  0.026086 | fidelity:  0.999959 | Sz:  0.000000 | S^2:  0.000167
iter: 160 | loss: -2.102575 | norm:  0.029518 | fidelity:  0.999954 | Sz: -0.000000 | S^2:  0.000210
iter: 161 | loss: -2.102566 | norm:  0.032746 | fidelity:  0.999947 | Sz:  0.000000 | S^2:  0.000247
iter: 162 | loss: -2.102566 | norm:  0.033424 | fidelity:  0.999943 | Sz: -0.000000 | S^2:  0.000279
iter: 163 | loss: -2.102572 | norm:  0.032181 | fidelity:  0.999939 | Sz:  0.000000 | S^2:  0.000305
iter: 164 | loss: -2.102579 | norm:  0.031124 | fidelity:  0.999936 | Sz:  0.000000 | S^2:  0.000324
iter: 165 | loss: -2.102587 | norm:  0.030454 | fidelity:  0.999935 | Sz: -0.000000 | S^2:  0.000333
iter: 166 | loss: -2.102600 | norm:  0.028635 | fidelity:  0.999937 | Sz: -0.000000 | S^2:  0.000326
iter: 167 | loss: -2.102614 | norm:  0.025313 | fidelity:  0.999939 | Sz: -0.000000 | S^2:  0.000301
iter: 168 | loss: -2.102632 | norm:  0.021741 | fidelity:  0.999944 | Sz:  0.000000 | S^2:  0.000261
iter: 169 | loss: -2.102645 | norm:  0.018938 | fidelity:  0.999948 | Sz:  0.000000 | S^2:  0.000209
iter: 170 | loss: -2.102666 | norm:  0.016948 | fidelity:  0.999958 | Sz:  0.000000 | S^2:  0.000153
iter: 171 | loss: -2.102680 | norm:  0.015684 | fidelity:  0.999965 | Sz:  0.000000 | S^2:  0.000100
iter: 172 | loss: -2.102693 | norm:  0.014569 | fidelity:  0.999971 | Sz:  0.000000 | S^2:  0.000057
iter: 173 | loss: -2.102709 | norm:  0.012464 | fidelity:  0.999978 | Sz:  0.000000 | S^2:  0.000026
iter: 174 | loss: -2.102715 | norm:  0.009553 | fidelity:  0.999979 | Sz:  0.000000 | S^2:  0.000007


convergence criterion has satisfied, break the loop!
total run time:  2237.763504266739
