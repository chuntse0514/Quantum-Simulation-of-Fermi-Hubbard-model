nohup: ignoring input
spin up orbital energies: {0: -3.0, 2: -1.0, 4: 0, 6: 2.0, 8: 0, 10: 2.0}
spin down orbital energies:  {1: -3.0, 3: -1.0, 5: 0, 7: 2.0, 9: 0, 11: 2.0}
spin up indices:  [0, 2, 4, 8]    spin down indices:  [1, 3] 

ground state energy:  -3.789823071667746
particle number:  6

learning rate =  0.06666665858756636
Find operators
1j [3^ 0^ 9 6] + -1j [9^ 6^ 3 0]
-1j [2^ 1^ 9 6] + 1j [9^ 6^ 2 1]
1j [3^ 2^ 11 6] + -1j [11^ 6^ 3 2]
-1j [4^ 1^ 11 10] + 1j [11^ 10^ 4 1]
1j [6^ 5^ 8 3] + -1j [8^ 3^ 6 5]
-1j [3^ 0^ 10 5] + 1j [10^ 5^ 3 0]
-1j [7^ 6^ 8 1] + 1j [8^ 1^ 7 6]
-1j [3^ 2^ 10 7] + 1j [10^ 7^ 3 2]
1j [2^ 1^ 10 5] + -1j [10^ 5^ 2 1]
-1j [1^ 0^ 10 7] + 1j [10^ 7^ 1 0]
1j [4^ 3^ 10 9] + -1j [10^ 9^ 4 3]
1j [1^ 0^ 11 6] + -1j [11^ 6^ 1 0]
with max gradients
[1.3333333, 1.3333333, 1.3333333, 1.3333333, 1.3333333, 1.3333333, 1.3333333, 1.3333333, 1.3333333, 1.3333333, 1.3333333, 1.3333333]

iter: 1 | loss: -2.666667 | norm:  4.618802 | fidelity:  0.737228 | Sz:  1.000000 | S^2:  2.000000
iter: 2 | loss: -3.394303 | norm:  1.929367 | fidelity:  0.868995 | Sz:  0.999995 | S^2:  2.000030
iter: 3 | loss: -3.482568 | norm:  1.795597 | fidelity:  0.921296 | Sz:  1.000000 | S^2:  2.000558
iter: 4 | loss: -3.371622 | norm:  2.538828 | fidelity:  0.931500 | Sz:  0.999999 | S^2:  2.001848
iter: 5 | loss: -3.355486 | norm:  2.513105 | fidelity:  0.939263 | Sz:  1.000000 | S^2:  2.003170
iter: 6 | loss: -3.414267 | norm:  2.056642 | fidelity:  0.948355 | Sz:  1.000002 | S^2:  2.003788
iter: 7 | loss: -3.471687 | norm:  1.570590 | fidelity:  0.953341 | Sz:  0.999999 | S^2:  2.003628
iter: 8 | loss: -3.491637 | norm:  1.415019 | fidelity:  0.952007 | Sz:  0.999999 | S^2:  2.003205
iter: 9 | loss: -3.478977 | norm:  1.594501 | fidelity:  0.946048 | Sz:  0.999999 | S^2:  2.003058
iter: 10 | loss: -3.462946 | norm:  1.794332 | fidelity:  0.939920 | Sz:  1.000001 | S^2:  2.003363
iter: 11 | loss: -3.471833 | norm:  1.808473 | fidelity:  0.937605 | Sz:  1.000001 | S^2:  2.003864
iter: 12 | loss: -3.508461 | norm:  1.599193 | fidelity:  0.939280 | Sz:  0.999999 | S^2:  2.004195
iter: 13 | loss: -3.552887 | norm:  1.225731 | fidelity:  0.941983 | Sz:  1.000000 | S^2:  2.004111
iter: 14 | loss: -3.581524 | norm:  0.832943 | fidelity:  0.942568 | Sz:  0.999999 | S^2:  2.003505
iter: 15 | loss: -3.582291 | norm:  0.728248 | fidelity:  0.939863 | Sz:  1.000001 | S^2:  2.002501
iter: 16 | loss: -3.561004 | norm:  0.982387 | fidelity:  0.935156 | Sz:  1.000001 | S^2:  2.001458
iter: 17 | loss: -3.536491 | norm:  1.246399 | fidelity:  0.931097 | Sz:  0.999999 | S^2:  2.000813
iter: 18 | loss: -3.526897 | norm:  1.345071 | fidelity:  0.929860 | Sz:  1.000002 | S^2:  2.000750
iter: 19 | loss: -3.537851 | norm:  1.241794 | fidelity:  0.931880 | Sz:  0.999999 | S^2:  2.001051
iter: 20 | loss: -3.560919 | norm:  0.972973 | fidelity:  0.935942 | Sz:  1.000000 | S^2:  2.001350
iter: 21 | loss: -3.581487 | norm:  0.652803 | fidelity:  0.940186 | Sz:  0.999999 | S^2:  2.001331
iter: 22 | loss: -3.589810 | norm:  0.523712 | fidelity:  0.943346 | Sz:  1.000000 | S^2:  2.000989
iter: 23 | loss: -3.586840 | norm:  0.672439 | fidelity:  0.945326 | Sz:  1.000000 | S^2:  2.000669
iter: 24 | loss: -3.580976 | norm:  0.816300 | fidelity:  0.946848 | Sz:  1.000001 | S^2:  2.000854
iter: 25 | loss: -3.579339 | norm:  0.822328 | fidelity:  0.948577 | Sz:  1.000000 | S^2:  2.001755
iter: 26 | loss: -3.582185 | norm:  0.709207 | fidelity:  0.950551 | Sz:  0.999998 | S^2:  2.003132
iter: 27 | loss: -3.585139 | norm:  0.582935 | fidelity:  0.952358 | Sz:  1.000002 | S^2:  2.004442
iter: 28 | loss: -3.585244 | norm:  0.560334 | fidelity:  0.953675 | Sz:  0.999999 | S^2:  2.005103
iter: 29 | loss: -3.584045 | norm:  0.613923 | fidelity:  0.954550 | Sz:  1.000000 | S^2:  2.004880
iter: 30 | loss: -3.584892 | norm:  0.633630 | fidelity:  0.955124 | Sz:  0.999998 | S^2:  2.003949
iter: 31 | loss: -3.588974 | norm:  0.573923 | fidelity:  0.955298 | Sz:  1.000001 | S^2:  2.002781
iter: 32 | loss: -3.594188 | norm:  0.459242 | fidelity:  0.954711 | Sz:  1.000000 | S^2:  2.001807
iter: 33 | loss: -3.597459 | norm:  0.364539 | fidelity:  0.953073 | Sz:  1.000000 | S^2:  2.001232
iter: 34 | loss: -3.597506 | norm:  0.361485 | fidelity:  0.950492 | Sz:  0.999999 | S^2:  2.000985
iter: 35 | loss: -3.595580 | norm:  0.412036 | fidelity:  0.947532 | Sz:  0.999999 | S^2:  2.000874
iter: 36 | loss: -3.593885 | norm:  0.443247 | fidelity:  0.944939 | Sz:  1.000000 | S^2:  2.000753
iter: 37 | loss: -3.593713 | norm:  0.433717 | fidelity:  0.943285 | Sz:  0.999999 | S^2:  2.000643
iter: 38 | loss: -3.594920 | norm:  0.395397 | fidelity:  0.942794 | Sz:  1.000000 | S^2:  2.000695
iter: 39 | loss: -3.596576 | norm:  0.349877 | fidelity:  0.943371 | Sz:  1.000000 | S^2:  2.001027
iter: 40 | loss: -3.597838 | norm:  0.317760 | fidelity:  0.944753 | Sz:  0.999997 | S^2:  2.001589
iter: 41 | loss: -3.598497 | norm:  0.307803 | fidelity:  0.946652 | Sz:  1.000001 | S^2:  2.002176
iter: 42 | loss: -3.598877 | norm:  0.305450 | fidelity:  0.948784 | Sz:  1.000001 | S^2:  2.002505
iter: 43 | loss: -3.599422 | norm:  0.286890 | fidelity:  0.950874 | Sz:  0.999999 | S^2:  2.002457
iter: 44 | loss: -3.600089 | norm:  0.246011 | fidelity:  0.952628 | Sz:  1.000001 | S^2:  2.002134
iter: 45 | loss: -3.600309 | norm:  0.211612 | fidelity:  0.953777 | Sz:  1.000001 | S^2:  2.001730
iter: 46 | loss: -3.599750 | norm:  0.226990 | fidelity:  0.954205 | Sz:  1.000000 | S^2:  2.001411
iter: 47 | loss: -3.598913 | norm:  0.271168 | fidelity:  0.954012 | Sz:  1.000000 | S^2:  2.001217
iter: 48 | loss: -3.598789 | norm:  0.288291 | fidelity:  0.953419 | Sz:  1.000001 | S^2:  2.001102
iter: 49 | loss: -3.599803 | norm:  0.251050 | fidelity:  0.952614 | Sz:  1.000000 | S^2:  2.001044
iter: 50 | loss: -3.601272 | norm:  0.167600 | fidelity:  0.951671 | Sz:  1.000000 | S^2:  2.001080
iter: 51 | loss: -3.602063 | norm:  0.094664 | fidelity:  0.950613 | Sz:  1.000000 | S^2:  2.001248
iter: 52 | loss: -3.601759 | norm:  0.132645 | fidelity:  0.949544 | Sz:  1.000002 | S^2:  2.001509
iter: 53 | loss: -3.600960 | norm:  0.191861 | fidelity:  0.948657 | Sz:  1.000000 | S^2:  2.001737
iter: 54 | loss: -3.600573 | norm:  0.208874 | fidelity:  0.948148 | Sz:  1.000002 | S^2:  2.001832
iter: 55 | loss: -3.600831 | norm:  0.184025 | fidelity:  0.948072 | Sz:  1.000001 | S^2:  2.001743
iter: 56 | loss: -3.601346 | norm:  0.142605 | fidelity:  0.948355 | Sz:  0.999999 | S^2:  2.001529
iter: 57 | loss: -3.601679 | norm:  0.119511 | fidelity:  0.948868 | Sz:  1.000000 | S^2:  2.001297
iter: 58 | loss: -3.601726 | norm:  0.124435 | fidelity:  0.949497 | Sz:  1.000000 | S^2:  2.001118
iter: 59 | loss: -3.601685 | norm:  0.132948 | fidelity:  0.950167 | Sz:  1.000000 | S^2:  2.001022
iter: 60 | loss: -3.601733 | norm:  0.129424 | fidelity:  0.950808 | Sz:  0.999999 | S^2:  2.001003
iter: 61 | loss: -3.601887 | norm:  0.113549 | fidelity:  0.951347 | Sz:  1.000001 | S^2:  2.001065
iter: 62 | loss: -3.601992 | norm:  0.094836 | fidelity:  0.951702 | Sz:  1.000000 | S^2:  2.001199
iter: 63 | loss: -3.601951 | norm:  0.090860 | fidelity:  0.951840 | Sz:  0.999999 | S^2:  2.001410
iter: 64 | loss: -3.601822 | norm:  0.104597 | fidelity:  0.951782 | Sz:  1.000000 | S^2:  2.001652
iter: 65 | loss: -3.601772 | norm:  0.114688 | fidelity:  0.951581 | Sz:  1.000002 | S^2:  2.001831
iter: 66 | loss: -3.601910 | norm:  0.104703 | fidelity:  0.951292 | Sz:  1.000001 | S^2:  2.001862
iter: 67 | loss: -3.602146 | norm:  0.075189 | fidelity:  0.950950 | Sz:  0.999998 | S^2:  2.001736
iter: 68 | loss: -3.602293 | norm:  0.049276 | fidelity:  0.950584 | Sz:  1.000000 | S^2:  2.001528
iter: 69 | loss: -3.602240 | norm:  0.060763 | fidelity:  0.950229 | Sz:  1.000000 | S^2:  2.001311
iter: 70 | loss: -3.602113 | norm:  0.079970 | fidelity:  0.949945 | Sz:  1.000000 | S^2:  2.001147
iter: 71 | loss: -3.602062 | norm:  0.082763 | fidelity:  0.949783 | Sz:  1.000000 | S^2:  2.001057
iter: 72 | loss: -3.602112 | norm:  0.072695 | fidelity:  0.949761 | Sz:  1.000001 | S^2:  2.001042
iter: 73 | loss: -3.602184 | norm:  0.063275 | fidelity:  0.949860 | Sz:  1.000000 | S^2:  2.001095
iter: 74 | loss: -3.602236 | norm:  0.059629 | fidelity:  0.950049 | Sz:  1.000000 | S^2:  2.001212
iter: 75 | loss: -3.602273 | norm:  0.054589 | fidelity:  0.950292 | Sz:  1.000001 | S^2:  2.001367
iter: 76 | loss: -3.602291 | norm:  0.047509 | fidelity:  0.950549 | Sz:  1.000000 | S^2:  2.001508
iter: 77 | loss: -3.602284 | norm:  0.047103 | fidelity:  0.950789 | Sz:  1.000000 | S^2:  2.001593
iter: 78 | loss: -3.602261 | norm:  0.052358 | fidelity:  0.950983 | Sz:  1.000000 | S^2:  2.001592
iter: 79 | loss: -3.602257 | norm:  0.053377 | fidelity:  0.951112 | Sz:  1.000001 | S^2:  2.001520
iter: 80 | loss: -3.602272 | norm:  0.048061 | fidelity:  0.951162 | Sz:  1.000001 | S^2:  2.001412
iter: 81 | loss: -3.602291 | norm:  0.042215 | fidelity:  0.951131 | Sz:  1.000000 | S^2:  2.001310
iter: 82 | loss: -3.602312 | norm:  0.039967 | fidelity:  0.951025 | Sz:  1.000001 | S^2:  2.001247
iter: 83 | loss: -3.602328 | norm:  0.038334 | fidelity:  0.950860 | Sz:  1.000001 | S^2:  2.001226
iter: 84 | loss: -3.602330 | norm:  0.035249 | fidelity:  0.950657 | Sz:  0.999999 | S^2:  2.001239
iter: 85 | loss: -3.602339 | norm:  0.032882 | fidelity:  0.950454 | Sz:  1.000001 | S^2:  2.001291
iter: 86 | loss: -3.602330 | norm:  0.032298 | fidelity:  0.950278 | Sz:  1.000000 | S^2:  2.001348
iter: 87 | loss: -3.602324 | norm:  0.032363 | fidelity:  0.950165 | Sz:  1.000000 | S^2:  2.001395
iter: 88 | loss: -3.602320 | norm:  0.032944 | fidelity:  0.950135 | Sz:  0.999999 | S^2:  2.001411
iter: 89 | loss: -3.602330 | norm:  0.032777 | fidelity:  0.950198 | Sz:  1.000000 | S^2:  2.001399
iter: 90 | loss: -3.602343 | norm:  0.028512 | fidelity:  0.950336 | Sz:  1.000000 | S^2:  2.001362
iter: 91 | loss: -3.602356 | norm:  0.019814 | fidelity:  0.950522 | Sz:  0.999999 | S^2:  2.001321
iter: 92 | loss: -3.602372 | norm:  0.015839 | fidelity:  0.950718 | Sz:  1.000002 | S^2:  2.001300
iter: 93 | loss: -3.602358 | norm:  0.022883 | fidelity:  0.950875 | Sz:  1.000001 | S^2:  2.001293
iter: 94 | loss: -3.602344 | norm:  0.027830 | fidelity:  0.950968 | Sz:  1.000000 | S^2:  2.001307
iter: 95 | loss: -3.602349 | norm:  0.025297 | fidelity:  0.950982 | Sz:  1.000001 | S^2:  2.001338
iter: 96 | loss: -3.602354 | norm:  0.018064 | fidelity:  0.950918 | Sz:  0.999999 | S^2:  2.001368
iter: 97 | loss: -3.602364 | norm:  0.014367 | fidelity:  0.950800 | Sz:  0.999999 | S^2:  2.001394
iter: 98 | loss: -3.602365 | norm:  0.016982 | fidelity:  0.950656 | Sz:  1.000000 | S^2:  2.001402
iter: 99 | loss: -3.602362 | norm:  0.018557 | fidelity:  0.950521 | Sz:  1.000000 | S^2:  2.001387
iter: 100 | loss: -3.602361 | norm:  0.017049 | fidelity:  0.950423 | Sz:  0.999999 | S^2:  2.001358
iter: 101 | loss: -3.602361 | norm:  0.014719 | fidelity:  0.950378 | Sz:  0.999999 | S^2:  2.001325
iter: 102 | loss: -3.602368 | norm:  0.014128 | fidelity:  0.950391 | Sz:  1.000001 | S^2:  2.001304
iter: 103 | loss: -3.602362 | norm:  0.015139 | fidelity:  0.950444 | Sz:  0.999999 | S^2:  2.001291
iter: 104 | loss: -3.602364 | norm:  0.015395 | fidelity:  0.950523 | Sz:  1.000000 | S^2:  2.001298
iter: 105 | loss: -3.602372 | norm:  0.013119 | fidelity:  0.950608 | Sz:  1.000001 | S^2:  2.001319
iter: 106 | loss: -3.602372 | norm:  0.009202 | fidelity:  0.950676 | Sz:  1.000000 | S^2:  2.001342

learning rate =  0.0036946363183431464
Find operators
1j [6^ 5^ 10 1] + -1j [10^ 1^ 6 5]
1j [6^ 1^ 10 9] + -1j [10^ 9^ 6 1]
1j [2^ 1^ 8 7] + -1j [8^ 7^ 2 1]
-1j [2^ 1^ 11 4] + 1j [11^ 4^ 2 1]
-1j [5^ 4^ 10 3] + 1j [10^ 3^ 5 4]
-1j [6^ 3^ 9 8] + 1j [9^ 8^ 6 3]
-1j [4^ 1^ 9 8] + 1j [9^ 8^ 4 1]
-1j [5^ 4^ 8 1] + 1j [8^ 1^ 5 4]
-1j [6^ 3^ 11 10] + 1j [11^ 10^ 6 3]
-1j [7^ 6^ 10 3] + 1j [10^ 3^ 7 6]
-1j [5^ 2^ 10 9] + 1j [10^ 9^ 5 2]
1j [6^ 5^ 9 2] + -1j [9^ 2^ 6 5]
1j [8^ 5^ 11 6] + -1j [11^ 6^ 8 5]
-1j [9^ 4^ 10 7] + 1j [10^ 7^ 9 4]
1j [8^ 7^ 9 6] + -1j [9^ 6^ 8 7]
1j [4^ 1^ 6 3] + -1j [6^ 3^ 4 1]
1j [10^ 5^ 11 4] + -1j [11^ 4^ 10 5]
1j [8^ 1^ 10 3] + -1j [10^ 3^ 8 1]
1j [8^ 3^ 10 1] + -1j [10^ 1^ 8 3]
1j [4^ 3^ 6 1] + -1j [6^ 1^ 4 3]
1j [3^ 2^ 9 4] + -1j [9^ 4^ 3 2]
-1j [3^ 2^ 8 5] + 1j [8^ 5^ 3 2]
1j [6^ 5^ 7 4] + -1j [7^ 4^ 6 5]
1j [10^ 9^ 11 8] + -1j [11^ 8^ 10 9]
1j [9^ 8^ 11 10] + -1j [11^ 10^ 9 8]
1j [5^ 4^ 7 6] + -1j [7^ 6^ 5 4]
1j [5^ 0^ 11 10] + -1j [11^ 10^ 5 0]
-1j [7^ 6^ 9 0] + 1j [9^ 0^ 7 6]
1j [4^ 1^ 5 0] + -1j [5^ 0^ 4 1]
1j [8^ 1^ 9 0] + -1j [9^ 0^ 8 1]
1j [4^ 3^ 5 2] + -1j [5^ 2^ 4 3]
1j [8^ 3^ 9 2] + -1j [9^ 2^ 8 3]
1j [6^ 1^ 7 0] + -1j [7^ 0^ 6 1]
1j [10^ 1^ 11 0] + -1j [11^ 0^ 10 1]
-1j [5^ 2^ 6 1] + 1j [6^ 1^ 5 2]
-1j [9^ 2^ 10 1] + 1j [10^ 1^ 9 2]
1j [6^ 3^ 7 2] + -1j [7^ 2^ 6 3]
1j [10^ 3^ 11 2] + -1j [11^ 2^ 10 3]
-1j [7^ 6^ 11 2] + 1j [11^ 2^ 7 6]
1j [7^ 2^ 11 10] + -1j [11^ 10^ 7 2]
1j [8^ 1^ 11 2] + -1j [11^ 2^ 8 1]
1j [4^ 1^ 7 2] + -1j [7^ 2^ 4 1]
-1j [7^ 4^ 8 3] + 1j [8^ 3^ 7 4]
-1j [4^ 3^ 11 8] + 1j [11^ 8^ 4 3]
-1j [9^ 0^ 10 3] + 1j [10^ 3^ 9 0]
-1j [5^ 0^ 6 3] + 1j [6^ 3^ 5 0]
with max gradients
[0.17685866, 0.17656094, 0.13078918, 0.13075386, 0.1210388, 0.12095122, 0.09810029, 0.0976206, 0.09108018, 0.09096308, 0.08566375, 0.08541804, 0.064517744, 0.064501196, 0.061870582, 0.06182033, 0.061808225, 0.061741944, 0.059384324, 0.059302274, 0.058645107, 0.058526095, 0.055205103, 0.05502413, 0.054064773, 0.053585324, 0.05091626, 0.05081257, 0.048614755, 0.04801435, 0.04070838, 0.040169477, 0.036735922, 0.0367001, 0.03641877, 0.036371704, 0.030739333, 0.030715272, 0.028772708, 0.0286188, 0.02633908, 0.025863547, 0.024967106, 0.02470716, 0.021259187, 0.021164596]

iter: 107 | loss: -3.602372 | norm:  0.501241 | fidelity:  0.950720 | Sz:  1.000000 | S^2:  2.001364
iter: 108 | loss: -3.611689 | norm:  0.511317 | fidelity:  0.951566 | Sz:  0.999990 | S^2:  2.000806
iter: 109 | loss: -3.622786 | norm:  0.466084 | fidelity:  0.954343 | Sz:  1.000005 | S^2:  2.000936
iter: 110 | loss: -3.632535 | norm:  0.456857 | fidelity:  0.957149 | Sz:  1.000001 | S^2:  2.001046
iter: 111 | loss: -3.641949 | norm:  0.453576 | fidelity:  0.959996 | Sz:  1.000009 | S^2:  2.001027
iter: 112 | loss: -3.651250 | norm:  0.439054 | fidelity:  0.962722 | Sz:  1.000005 | S^2:  2.000841
iter: 113 | loss: -3.660253 | norm:  0.418596 | fidelity:  0.965280 | Sz:  1.000001 | S^2:  2.000629
iter: 114 | loss: -3.668664 | norm:  0.402080 | fidelity:  0.967652 | Sz:  0.999997 | S^2:  2.000484
iter: 115 | loss: -3.676412 | norm:  0.392619 | fidelity:  0.969849 | Sz:  1.000000 | S^2:  2.000437
iter: 116 | loss: -3.683611 | norm:  0.384285 | fidelity:  0.971902 | Sz:  1.000003 | S^2:  2.000441
iter: 117 | loss: -3.690381 | norm:  0.370601 | fidelity:  0.973838 | Sz:  1.000002 | S^2:  2.000442
iter: 118 | loss: -3.696731 | norm:  0.351765 | fidelity:  0.975668 | Sz:  1.000002 | S^2:  2.000436
iter: 119 | loss: -3.702550 | norm:  0.332787 | fidelity:  0.977375 | Sz:  1.000000 | S^2:  2.000426
iter: 120 | loss: -3.707792 | norm:  0.318289 | fidelity:  0.978953 | Sz:  1.000001 | S^2:  2.000437
iter: 121 | loss: -3.712497 | norm:  0.308576 | fidelity:  0.980393 | Sz:  1.000004 | S^2:  2.000481
iter: 122 | loss: -3.716740 | norm:  0.300009 | fidelity:  0.981690 | Sz:  1.000001 | S^2:  2.000554
iter: 123 | loss: -3.720653 | norm:  0.289341 | fidelity:  0.982859 | Sz:  1.000005 | S^2:  2.000686
iter: 124 | loss: -3.724189 | norm:  0.276743 | fidelity:  0.983885 | Sz:  0.999996 | S^2:  2.000842
iter: 125 | loss: -3.727438 | norm:  0.265029 | fidelity:  0.984805 | Sz:  1.000001 | S^2:  2.001069
iter: 126 | loss: -3.730325 | norm:  0.256746 | fidelity:  0.985613 | Sz:  1.000000 | S^2:  2.001298
iter: 127 | loss: -3.732932 | norm:  0.251776 | fidelity:  0.986340 | Sz:  1.000000 | S^2:  2.001515
iter: 128 | loss: -3.735322 | norm:  0.247681 | fidelity:  0.987005 | Sz:  0.999999 | S^2:  2.001678
iter: 129 | loss: -3.737568 | norm:  0.242439 | fidelity:  0.987627 | Sz:  0.999998 | S^2:  2.001777
iter: 130 | loss: -3.739715 | norm:  0.236289 | fidelity:  0.988220 | Sz:  1.000000 | S^2:  2.001830
iter: 131 | loss: -3.741742 | norm:  0.231043 | fidelity:  0.988777 | Sz:  0.999999 | S^2:  2.001845
iter: 132 | loss: -3.743684 | norm:  0.227998 | fidelity:  0.989306 | Sz:  1.000002 | S^2:  2.001857
iter: 133 | loss: -3.745537 | norm:  0.226526 | fidelity:  0.989800 | Sz:  1.000000 | S^2:  2.001866
iter: 134 | loss: -3.747366 | norm:  0.224767 | fidelity:  0.990270 | Sz:  0.999999 | S^2:  2.001886
iter: 135 | loss: -3.749200 | norm:  0.221469 | fidelity:  0.990722 | Sz:  0.999998 | S^2:  2.001914
iter: 136 | loss: -3.751050 | norm:  0.216925 | fidelity:  0.991164 | Sz:  1.000002 | S^2:  2.001940
iter: 137 | loss: -3.752878 | norm:  0.212307 | fidelity:  0.991594 | Sz:  1.000002 | S^2:  2.001936
iter: 138 | loss: -3.754677 | norm:  0.208281 | fidelity:  0.992017 | Sz:  1.000000 | S^2:  2.001891
iter: 139 | loss: -3.756455 | norm:  0.204348 | fidelity:  0.992438 | Sz:  0.999998 | S^2:  2.001802
iter: 140 | loss: -3.758236 | norm:  0.199527 | fidelity:  0.992863 | Sz:  1.000002 | S^2:  2.001682
iter: 141 | loss: -3.759971 | norm:  0.193476 | fidelity:  0.993277 | Sz:  1.000000 | S^2:  2.001522
iter: 142 | loss: -3.761666 | norm:  0.186811 | fidelity:  0.993683 | Sz:  0.999999 | S^2:  2.001351
iter: 143 | loss: -3.763306 | norm:  0.180393 | fidelity:  0.994075 | Sz:  1.000000 | S^2:  2.001189
iter: 144 | loss: -3.764873 | norm:  0.174464 | fidelity:  0.994448 | Sz:  1.000003 | S^2:  2.001045
iter: 145 | loss: -3.766336 | norm:  0.168595 | fidelity:  0.994792 | Sz:  1.000000 | S^2:  2.000908
iter: 146 | loss: -3.767747 | norm:  0.162417 | fidelity:  0.995122 | Sz:  1.000004 | S^2:  2.000808
iter: 147 | loss: -3.769042 | norm:  0.156162 | fidelity:  0.995425 | Sz:  1.000001 | S^2:  2.000711
iter: 148 | loss: -3.770248 | norm:  0.150418 | fidelity:  0.995710 | Sz:  1.000000 | S^2:  2.000629
iter: 149 | loss: -3.771365 | norm:  0.145460 | fidelity:  0.995981 | Sz:  0.999999 | S^2:  2.000560
iter: 150 | loss: -3.772393 | norm:  0.141003 | fidelity:  0.996235 | Sz:  0.999997 | S^2:  2.000497
iter: 151 | loss: -3.773374 | norm:  0.136622 | fidelity:  0.996483 | Sz:  1.000003 | S^2:  2.000457
iter: 152 | loss: -3.774252 | norm:  0.132225 | fidelity:  0.996707 | Sz:  1.000000 | S^2:  2.000408
iter: 153 | loss: -3.775077 | norm:  0.128015 | fidelity:  0.996918 | Sz:  1.000000 | S^2:  2.000374
iter: 154 | loss: -3.775848 | norm:  0.124083 | fidelity:  0.997113 | Sz:  1.000000 | S^2:  2.000353
iter: 155 | loss: -3.776576 | norm:  0.120228 | fidelity:  0.997294 | Sz:  1.000003 | S^2:  2.000344
iter: 156 | loss: -3.777243 | norm:  0.116197 | fidelity:  0.997456 | Sz:  1.000000 | S^2:  2.000335
iter: 157 | loss: -3.777890 | norm:  0.111972 | fidelity:  0.997612 | Sz:  1.000002 | S^2:  2.000341
iter: 158 | loss: -3.778488 | norm:  0.107730 | fidelity:  0.997757 | Sz:  1.000000 | S^2:  2.000344
iter: 159 | loss: -3.779040 | norm:  0.103581 | fidelity:  0.997892 | Sz:  0.999995 | S^2:  2.000344
iter: 160 | loss: -3.779599 | norm:  0.099425 | fidelity:  0.998032 | Sz:  1.000000 | S^2:  2.000365
iter: 161 | loss: -3.780115 | norm:  0.095093 | fidelity:  0.998165 | Sz:  1.000001 | S^2:  2.000381
iter: 162 | loss: -3.780598 | norm:  0.090562 | fidelity:  0.998290 | Sz:  1.000001 | S^2:  2.000394
iter: 163 | loss: -3.781039 | norm:  0.085963 | fidelity:  0.998404 | Sz:  0.999998 | S^2:  2.000398
iter: 164 | loss: -3.781470 | norm:  0.081410 | fidelity:  0.998516 | Sz:  1.000000 | S^2:  2.000411
iter: 165 | loss: -3.781877 | norm:  0.076890 | fidelity:  0.998621 | Sz:  1.000002 | S^2:  2.000423
iter: 166 | loss: -3.782242 | norm:  0.072359 | fidelity:  0.998714 | Sz:  1.000001 | S^2:  2.000426
iter: 167 | loss: -3.782573 | norm:  0.067889 | fidelity:  0.998798 | Sz:  0.999998 | S^2:  2.000422
iter: 168 | loss: -3.782904 | norm:  0.063643 | fidelity:  0.998881 | Sz:  1.000002 | S^2:  2.000430
iter: 169 | loss: -3.783182 | norm:  0.059704 | fidelity:  0.998952 | Sz:  0.999998 | S^2:  2.000422
iter: 170 | loss: -3.783446 | norm:  0.055982 | fidelity:  0.999019 | Sz:  0.999997 | S^2:  2.000417
iter: 171 | loss: -3.783710 | norm:  0.052363 | fidelity:  0.999087 | Sz:  1.000001 | S^2:  2.000421
iter: 172 | loss: -3.783942 | norm:  0.048874 | fidelity:  0.999146 | Sz:  1.000001 | S^2:  2.000415
iter: 173 | loss: -3.784146 | norm:  0.045638 | fidelity:  0.999197 | Sz:  1.000000 | S^2:  2.000403
iter: 174 | loss: -3.784348 | norm:  0.042688 | fidelity:  0.999247 | Sz:  1.000003 | S^2:  2.000396
iter: 175 | loss: -3.784509 | norm:  0.039929 | fidelity:  0.999285 | Sz:  0.999999 | S^2:  2.000375
iter: 176 | loss: -3.784685 | norm:  0.037303 | fidelity:  0.999326 | Sz:  1.000002 | S^2:  2.000368
iter: 177 | loss: -3.784843 | norm:  0.034886 | fidelity:  0.999362 | Sz:  1.000004 | S^2:  2.000360
iter: 178 | loss: -3.784974 | norm:  0.032755 | fidelity:  0.999392 | Sz:  1.000001 | S^2:  2.000344
iter: 179 | loss: -3.785103 | norm:  0.030840 | fidelity:  0.999421 | Sz:  1.000001 | S^2:  2.000333
iter: 180 | loss: -3.785211 | norm:  0.029009 | fidelity:  0.999445 | Sz:  0.999998 | S^2:  2.000315
iter: 181 | loss: -3.785337 | norm:  0.027238 | fidelity:  0.999474 | Sz:  1.000001 | S^2:  2.000313
iter: 182 | loss: -3.785457 | norm:  0.025603 | fidelity:  0.999502 | Sz:  1.000005 | S^2:  2.000311
iter: 183 | loss: -3.785547 | norm:  0.024129 | fidelity:  0.999521 | Sz:  1.000003 | S^2:  2.000298
iter: 184 | loss: -3.785645 | norm:  0.022756 | fidelity:  0.999541 | Sz:  1.000004 | S^2:  2.000293
iter: 185 | loss: -3.785719 | norm:  0.021453 | fidelity:  0.999555 | Sz:  1.000001 | S^2:  2.000279
iter: 186 | loss: -3.785794 | norm:  0.020280 | fidelity:  0.999569 | Sz:  0.999999 | S^2:  2.000269
iter: 187 | loss: -3.785883 | norm:  0.019295 | fidelity:  0.999587 | Sz:  1.000002 | S^2:  2.000271
iter: 188 | loss: -3.785945 | norm:  0.018469 | fidelity:  0.999597 | Sz:  0.999999 | S^2:  2.000262
iter: 189 | loss: -3.786017 | norm:  0.017741 | fidelity:  0.999610 | Sz:  1.000000 | S^2:  2.000260
iter: 190 | loss: -3.786085 | norm:  0.017102 | fidelity:  0.999622 | Sz:  1.000001 | S^2:  2.000258
iter: 191 | loss: -3.786143 | norm:  0.016576 | fidelity:  0.999631 | Sz:  1.000000 | S^2:  2.000253
iter: 192 | loss: -3.786211 | norm:  0.016148 | fidelity:  0.999643 | Sz:  1.000002 | S^2:  2.000255
iter: 193 | loss: -3.786275 | norm:  0.015765 | fidelity:  0.999654 | Sz:  1.000004 | S^2:  2.000256
iter: 194 | loss: -3.786316 | norm:  0.015409 | fidelity:  0.999659 | Sz:  1.000001 | S^2:  2.000246
iter: 195 | loss: -3.786378 | norm:  0.015102 | fidelity:  0.999669 | Sz:  1.000003 | S^2:  2.000248
iter: 196 | loss: -3.786420 | norm:  0.014855 | fidelity:  0.999674 | Sz:  1.000001 | S^2:  2.000241
iter: 197 | loss: -3.786460 | norm:  0.014640 | fidelity:  0.999679 | Sz:  0.999999 | S^2:  2.000233
iter: 198 | loss: -3.786501 | norm:  0.014436 | fidelity:  0.999685 | Sz:  0.999997 | S^2:  2.000227
iter: 199 | loss: -3.786556 | norm:  0.014253 | fidelity:  0.999694 | Sz:  0.999999 | S^2:  2.000228
iter: 200 | loss: -3.786612 | norm:  0.014097 | fidelity:  0.999703 | Sz:  1.000002 | S^2:  2.000230
iter: 201 | loss: -3.786640 | norm:  0.013943 | fidelity:  0.999705 | Sz:  0.999998 | S^2:  2.000218
iter: 202 | loss: -3.786695 | norm:  0.013776 | fidelity:  0.999714 | Sz:  1.000001 | S^2:  2.000221
iter: 203 | loss: -3.786735 | norm:  0.013610 | fidelity:  0.999719 | Sz:  1.000001 | S^2:  2.000216
iter: 204 | loss: -3.786759 | norm:  0.013461 | fidelity:  0.999720 | Sz:  0.999996 | S^2:  2.000202
iter: 205 | loss: -3.786810 | norm:  0.013314 | fidelity:  0.999728 | Sz:  0.999999 | S^2:  2.000203
iter: 206 | loss: -3.786840 | norm:  0.013158 | fidelity:  0.999730 | Sz:  0.999997 | S^2:  2.000193
iter: 207 | loss: -3.786894 | norm:  0.012998 | fidelity:  0.999739 | Sz:  1.000001 | S^2:  2.000197
iter: 208 | loss: -3.786925 | norm:  0.012845 | fidelity:  0.999741 | Sz:  0.999999 | S^2:  2.000188
iter: 209 | loss: -3.786969 | norm:  0.012693 | fidelity:  0.999747 | Sz:  1.000000 | S^2:  2.000186
iter: 210 | loss: -3.787007 | norm:  0.012533 | fidelity:  0.999752 | Sz:  1.000000 | S^2:  2.000182
iter: 211 | loss: -3.787034 | norm:  0.012374 | fidelity:  0.999753 | Sz:  0.999998 | S^2:  2.000172
iter: 212 | loss: -3.787085 | norm:  0.012225 | fidelity:  0.999761 | Sz:  1.000002 | S^2:  2.000175
iter: 213 | loss: -3.787106 | norm:  0.012083 | fidelity:  0.999761 | Sz:  0.999998 | S^2:  2.000162
iter: 214 | loss: -3.787144 | norm:  0.011942 | fidelity:  0.999766 | Sz:  0.999999 | S^2:  2.000159
iter: 215 | loss: -3.787183 | norm:  0.011805 | fidelity:  0.999771 | Sz:  1.000000 | S^2:  2.000156
iter: 216 | loss: -3.787231 | norm:  0.011677 | fidelity:  0.999778 | Sz:  1.000004 | S^2:  2.000159
iter: 217 | loss: -3.787239 | norm:  0.011556 | fidelity:  0.999775 | Sz:  0.999997 | S^2:  2.000140
iter: 218 | loss: -3.787275 | norm:  0.011438 | fidelity:  0.999779 | Sz:  0.999997 | S^2:  2.000137
iter: 219 | loss: -3.787330 | norm:  0.011323 | fidelity:  0.999788 | Sz:  1.000003 | S^2:  2.000145
iter: 220 | loss: -3.787348 | norm:  0.011220 | fidelity:  0.999788 | Sz:  0.999999 | S^2:  2.000133
iter: 221 | loss: -3.787379 | norm:  0.011128 | fidelity:  0.999791 | Sz:  0.999999 | S^2:  2.000129
iter: 222 | loss: -3.787398 | norm:  0.011044 | fidelity:  0.999790 | Sz:  0.999996 | S^2:  2.000118
iter: 223 | loss: -3.787453 | norm:  0.010967 | fidelity:  0.999800 | Sz:  1.000002 | S^2:  2.000128
iter: 224 | loss: -3.787481 | norm:  0.010898 | fidelity:  0.999802 | Sz:  1.000001 | S^2:  2.000122
iter: 225 | loss: -3.787521 | norm:  0.010834 | fidelity:  0.999807 | Sz:  1.000004 | S^2:  2.000124
iter: 226 | loss: -3.787536 | norm:  0.010768 | fidelity:  0.999806 | Sz:  1.000000 | S^2:  2.000113
iter: 227 | loss: -3.787564 | norm:  0.010701 | fidelity:  0.999809 | Sz:  0.999999 | S^2:  2.000110
iter: 228 | loss: -3.787587 | norm:  0.010638 | fidelity:  0.999810 | Sz:  0.999998 | S^2:  2.000103
iter: 229 | loss: -3.787624 | norm:  0.010577 | fidelity:  0.999815 | Sz:  1.000000 | S^2:  2.000105
iter: 230 | loss: -3.787650 | norm:  0.010514 | fidelity:  0.999816 | Sz:  0.999999 | S^2:  2.000101
iter: 231 | loss: -3.787678 | norm:  0.010452 | fidelity:  0.999819 | Sz:  0.999999 | S^2:  2.000099
iter: 232 | loss: -3.787703 | norm:  0.010391 | fidelity:  0.999821 | Sz:  0.999998 | S^2:  2.000095
iter: 233 | loss: -3.787733 | norm:  0.010328 | fidelity:  0.999824 | Sz:  0.999999 | S^2:  2.000094
iter: 234 | loss: -3.787771 | norm:  0.010260 | fidelity:  0.999830 | Sz:  1.000002 | S^2:  2.000097
iter: 235 | loss: -3.787802 | norm:  0.010191 | fidelity:  0.999833 | Sz:  1.000003 | S^2:  2.000097
iter: 236 | loss: -3.787818 | norm:  0.010123 | fidelity:  0.999833 | Sz:  1.000000 | S^2:  2.000090
iter: 237 | loss: -3.787852 | norm:  0.010057 | fidelity:  0.999837 | Sz:  1.000002 | S^2:  2.000091
iter: 238 | loss: -3.787873 | norm:  0.009992 | fidelity:  0.999838 | Sz:  1.000001 | S^2:  2.000086

learning rate =  0.0006451462395489216
Find operators
-1j [1^ 0^ 8 5] + 1j [8^ 5^ 1 0]
1j [6^ 5^ 11 0] + -1j [11^ 0^ 6 5]
1j [1^ 0^ 9 4] + -1j [9^ 4^ 1 0]
-1j [7^ 0^ 10 9] + 1j [10^ 9^ 7 0]
with max gradients
[0.013477764, 0.0134184, 0.012707887, 0.011947715]

iter: 239 | loss: -3.787901 | norm:  0.027650 | fidelity:  0.999841 | Sz:  1.000002 | S^2:  2.000085
iter: 240 | loss: -3.787930 | norm:  0.042895 | fidelity:  0.999846 | Sz:  1.000001 | S^2:  2.000082
iter: 241 | loss: -3.788018 | norm:  0.026006 | fidelity:  0.999853 | Sz:  1.000000 | S^2:  2.000075
iter: 242 | loss: -3.788070 | norm:  0.031241 | fidelity:  0.999856 | Sz:  1.000001 | S^2:  2.000076
iter: 243 | loss: -3.788103 | norm:  0.035261 | fidelity:  0.999856 | Sz:  0.999998 | S^2:  2.000066
iter: 244 | loss: -3.788184 | norm:  0.030702 | fidelity:  0.999868 | Sz:  1.000003 | S^2:  2.000073
iter: 245 | loss: -3.788224 | norm:  0.023843 | fidelity:  0.999869 | Sz:  0.999997 | S^2:  2.000057
iter: 246 | loss: -3.788295 | norm:  0.021747 | fidelity:  0.999880 | Sz:  1.000002 | S^2:  2.000062
iter: 247 | loss: -3.788333 | norm:  0.024864 | fidelity:  0.999882 | Sz:  1.000000 | S^2:  2.000055
iter: 248 | loss: -3.788393 | norm:  0.026816 | fidelity:  0.999891 | Sz:  1.000004 | S^2:  2.000060
iter: 249 | loss: -3.788444 | norm:  0.025058 | fidelity:  0.999895 | Sz:  1.000005 | S^2:  2.000057
iter: 250 | loss: -3.788487 | norm:  0.021130 | fidelity:  0.999897 | Sz:  1.000003 | S^2:  2.000050
iter: 251 | loss: -3.788532 | norm:  0.018397 | fidelity:  0.999901 | Sz:  1.000003 | S^2:  2.000046
iter: 252 | loss: -3.788567 | norm:  0.018956 | fidelity:  0.999902 | Sz:  1.000001 | S^2:  2.000040
iter: 253 | loss: -3.788604 | norm:  0.020705 | fidelity:  0.999904 | Sz:  1.000001 | S^2:  2.000037
iter: 254 | loss: -3.788653 | norm:  0.020971 | fidelity:  0.999910 | Sz:  1.000003 | S^2:  2.000040
iter: 255 | loss: -3.788677 | norm:  0.019278 | fidelity:  0.999909 | Sz:  0.999999 | S^2:  2.000030
iter: 256 | loss: -3.788725 | norm:  0.016879 | fidelity:  0.999915 | Sz:  1.000001 | S^2:  2.000033
iter: 257 | loss: -3.788755 | norm:  0.015639 | fidelity:  0.999916 | Sz:  0.999999 | S^2:  2.000027
iter: 258 | loss: -3.788795 | norm:  0.016131 | fidelity:  0.999921 | Sz:  1.000000 | S^2:  2.000029
iter: 259 | loss: -3.788830 | norm:  0.016979 | fidelity:  0.999924 | Sz:  1.000001 | S^2:  2.000028
iter: 260 | loss: -3.788867 | norm:  0.016869 | fidelity:  0.999927 | Sz:  1.000001 | S^2:  2.000028
iter: 261 | loss: -3.788904 | norm:  0.015700 | fidelity:  0.999931 | Sz:  1.000002 | S^2:  2.000028
iter: 262 | loss: -3.788922 | norm:  0.014354 | fidelity:  0.999929 | Sz:  0.999998 | S^2:  2.000019
iter: 263 | loss: -3.788961 | norm:  0.013830 | fidelity:  0.999934 | Sz:  1.000000 | S^2:  2.000022
iter: 264 | loss: -3.788985 | norm:  0.014131 | fidelity:  0.999935 | Sz:  0.999999 | S^2:  2.000019
iter: 265 | loss: -3.789029 | norm:  0.014368 | fidelity:  0.999941 | Sz:  1.000003 | S^2:  2.000026
iter: 266 | loss: -3.789046 | norm:  0.013929 | fidelity:  0.999941 | Sz:  1.000001 | S^2:  2.000020
iter: 267 | loss: -3.789073 | norm:  0.012983 | fidelity:  0.999943 | Sz:  1.000000 | S^2:  2.000019
iter: 268 | loss: -3.789094 | norm:  0.012205 | fidelity:  0.999944 | Sz:  0.999999 | S^2:  2.000016
iter: 269 | loss: -3.789130 | norm:  0.012036 | fidelity:  0.999949 | Sz:  1.000002 | S^2:  2.000022
iter: 270 | loss: -3.789134 | norm:  0.012185 | fidelity:  0.999946 | Sz:  0.999997 | S^2:  2.000011
iter: 271 | loss: -3.789161 | norm:  0.012084 | fidelity:  0.999949 | Sz:  0.999998 | S^2:  2.000013
iter: 272 | loss: -3.789190 | norm:  0.011555 | fidelity:  0.999952 | Sz:  1.000000 | S^2:  2.000016
iter: 273 | loss: -3.789212 | norm:  0.010915 | fidelity:  0.999954 | Sz:  1.000000 | S^2:  2.000015
iter: 274 | loss: -3.789224 | norm:  0.010582 | fidelity:  0.999954 | Sz:  0.999998 | S^2:  2.000010
iter: 275 | loss: -3.789250 | norm:  0.010565 | fidelity:  0.999957 | Sz:  1.000000 | S^2:  2.000013
iter: 276 | loss: -3.789269 | norm:  0.010495 | fidelity:  0.999959 | Sz:  1.000000 | S^2:  2.000013
iter: 277 | loss: -3.789289 | norm:  0.010129 | fidelity:  0.999961 | Sz:  1.000001 | S^2:  2.000013
iter: 278 | loss: -3.789305 | norm:  0.009604 | fidelity:  0.999962 | Sz:  1.000000 | S^2:  2.000011


convergence criterion has satisfied, break the loop!
total run time:  11888.821498632431
