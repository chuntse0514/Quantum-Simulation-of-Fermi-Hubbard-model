nohup: ignoring input
spin up orbital energies: {0: -3.0, 2: -1.0, 4: -1.0, 6: 1.0, 8: 1.0, 10: 3.0, 12: -1.0, 14: 1.0}
spin down orbital energies:  {1: -3.0, 3: -1.0, 5: -1.0, 7: 1.0, 9: 1.0, 11: 3.0, 13: -1.0, 15: 1.0}
spin up indices:  [0, 2, 4, 12]    spin down indices:  [1, 3, 5, 13] 

ground state energy:  -5.95423668105734
particle number:  8

learning rate =  0.05000000060634249
Find operators
1j [3^ 2^ 15 6] + -1j [15^ 6^ 3 2]
1j [5^ 2^ 15 8] + -1j [15^ 8^ 5 2]
1j [4^ 3^ 14 9] + -1j [14^ 9^ 4 3]
-1j [5^ 0^ 14 11] + 1j [14^ 11^ 5 0]
1j [5^ 4^ 7 6] + -1j [7^ 6^ 5 4]
-1j [3^ 2^ 14 7] + 1j [14^ 7^ 3 2]
-1j [9^ 6^ 13 2] + 1j [13^ 2^ 9 6]
1j [7^ 6^ 13 12] + -1j [13^ 12^ 7 6]
1j [5^ 4^ 15 14] + -1j [15^ 14^ 5 4]
-1j [9^ 6^ 12 3] + 1j [12^ 3^ 9 6]
-1j [5^ 2^ 14 9] + 1j [14^ 9^ 5 2]
1j [13^ 4^ 15 6] + -1j [15^ 6^ 13 4]
-1j [11^ 6^ 12 1] + 1j [12^ 1^ 11 6]
-1j [9^ 8^ 12 5] + 1j [12^ 5^ 9 8]
-1j [13^ 4^ 14 7] + 1j [14^ 7^ 13 4]
1j [10^ 7^ 13 0] + -1j [13^ 0^ 10 7]
1j [8^ 7^ 12 3] + -1j [12^ 3^ 8 7]
-1j [11^ 6^ 13 0] + 1j [13^ 0^ 11 6]
-1j [11^ 10^ 13 4] + 1j [13^ 4^ 11 10]
-1j [9^ 8^ 13 4] + 1j [13^ 4^ 9 8]
1j [5^ 0^ 15 10] + -1j [15^ 10^ 5 0]
1j [3^ 2^ 9 8] + -1j [9^ 8^ 3 2]
1j [13^ 12^ 15 14] + -1j [15^ 14^ 13 12]
-1j [2^ 1^ 11 8] + 1j [11^ 8^ 2 1]
1j [1^ 0^ 15 6] + -1j [15^ 6^ 1 0]
1j [1^ 0^ 9 8] + -1j [9^ 8^ 1 0]
1j [12^ 5^ 14 7] + -1j [14^ 7^ 12 5]
1j [1^ 0^ 11 10] + -1j [11^ 10^ 1 0]
1j [3^ 2^ 11 10] + -1j [11^ 10^ 3 2]
-1j [1^ 0^ 14 7] + 1j [14^ 7^ 1 0]
-1j [4^ 3^ 15 8] + 1j [15^ 8^ 4 3]
-1j [4^ 1^ 15 10] + 1j [15^ 10^ 4 1]
-1j [11^ 10^ 12 5] + 1j [12^ 5^ 11 10]
1j [3^ 0^ 11 8] + -1j [11^ 8^ 3 0]
-1j [3^ 0^ 10 9] + 1j [10^ 9^ 3 0]
1j [4^ 1^ 14 11] + -1j [14^ 11^ 4 1]
1j [10^ 7^ 12 1] + -1j [12^ 1^ 10 7]
1j [2^ 1^ 10 9] + -1j [10^ 9^ 2 1]
1j [8^ 7^ 13 2] + -1j [13^ 2^ 8 7]
1j [12^ 5^ 15 6] + -1j [15^ 6^ 12 5]
with max gradients
[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

iter: 1 | loss: -4.000000 | norm:  6.324555 | fidelity:  0.635416 | Sz:  0.000000 | S^2:  0.000000
iter: 2 | loss: -5.358603 | norm:  2.737114 | fidelity:  0.841583 | Sz:  0.000000 | S^2:  0.000018
iter: 3 | loss: -5.560617 | norm:  2.617673 | fidelity:  0.921647 | Sz:  0.000000 | S^2:  0.000775
iter: 4 | loss: -5.433980 | norm:  3.317221 | fidelity:  0.929462 | Sz:  0.000000 | S^2:  0.006029
iter: 5 | loss: -5.400576 | norm:  3.245389 | fidelity:  0.926212 | Sz:  0.000000 | S^2:  0.018705
iter: 6 | loss: -5.462763 | norm:  2.805125 | fidelity:  0.927549 | Sz:  0.000000 | S^2:  0.039762
iter: 7 | loss: -5.542135 | norm:  2.391699 | fidelity:  0.931560 | Sz:  0.000000 | S^2:  0.068801
iter: 8 | loss: -5.590930 | norm:  2.265479 | fidelity:  0.934381 | Sz: -0.000000 | S^2:  0.104235
iter: 9 | loss: -5.615486 | norm:  2.346716 | fidelity:  0.935568 | Sz: -0.000000 | S^2:  0.143797
iter: 10 | loss: -5.649003 | norm:  2.319663 | fidelity:  0.936944 | Sz:  0.000000 | S^2:  0.183921
iter: 11 | loss: -5.697051 | norm:  2.062455 | fidelity:  0.938235 | Sz: -0.000000 | S^2:  0.219402
iter: 12 | loss: -5.735903 | norm:  1.705189 | fidelity:  0.937654 | Sz:  0.000000 | S^2:  0.244222
iter: 13 | loss: -5.744183 | norm:  1.529202 | fidelity:  0.934814 | Sz: -0.000000 | S^2:  0.253607
iter: 14 | loss: -5.723987 | norm:  1.673400 | fidelity:  0.931692 | Sz:  0.000000 | S^2:  0.246432
iter: 15 | loss: -5.700845 | norm:  1.899569 | fidelity:  0.931517 | Sz: -0.000000 | S^2:  0.225973
iter: 16 | loss: -5.702777 | norm:  1.956019 | fidelity:  0.936491 | Sz: -0.000000 | S^2:  0.197923
iter: 17 | loss: -5.736785 | norm:  1.760699 | fidelity:  0.945994 | Sz:  0.000000 | S^2:  0.167313
iter: 18 | loss: -5.784825 | norm:  1.368382 | fidelity:  0.956824 | Sz: -0.000000 | S^2:  0.137240
iter: 19 | loss: -5.819988 | norm:  0.968485 | fidelity:  0.965249 | Sz: -0.000000 | S^2:  0.109492
iter: 20 | loss: -5.827475 | norm:  0.876555 | fidelity:  0.969333 | Sz: -0.000000 | S^2:  0.085527
iter: 21 | loss: -5.813414 | norm:  1.087158 | fidelity:  0.969818 | Sz: -0.000000 | S^2:  0.067012
iter: 22 | loss: -5.795854 | norm:  1.276558 | fidelity:  0.968974 | Sz: -0.000000 | S^2:  0.055593
iter: 23 | loss: -5.789099 | norm:  1.307562 | fidelity:  0.968726 | Sz: -0.000000 | S^2:  0.051950
iter: 24 | loss: -5.795641 | norm:  1.190326 | fidelity:  0.969666 | Sz: -0.000000 | S^2:  0.055005
iter: 25 | loss: -5.808400 | norm:  1.013277 | fidelity:  0.971198 | Sz: -0.000000 | S^2:  0.062035
iter: 26 | loss: -5.819711 | norm:  0.889372 | fidelity:  0.972480 | Sz:  0.000000 | S^2:  0.069761
iter: 27 | loss: -5.827274 | norm:  0.854756 | fidelity:  0.973070 | Sz: -0.000000 | S^2:  0.076061
iter: 28 | loss: -5.833032 | norm:  0.839878 | fidelity:  0.972926 | Sz:  0.000000 | S^2:  0.081233
iter: 29 | loss: -5.838262 | norm:  0.785132 | fidelity:  0.972048 | Sz:  0.000000 | S^2:  0.087448
iter: 30 | loss: -5.841722 | norm:  0.705675 | fidelity:  0.970423 | Sz: -0.000000 | S^2:  0.096767
iter: 31 | loss: -5.841519 | norm:  0.668230 | fidelity:  0.968204 | Sz:  0.000000 | S^2:  0.109400
iter: 32 | loss: -5.838339 | norm:  0.701784 | fidelity:  0.965922 | Sz:  0.000000 | S^2:  0.123378
iter: 33 | loss: -5.835763 | norm:  0.744237 | fidelity:  0.964326 | Sz:  0.000000 | S^2:  0.135697
iter: 34 | loss: -5.837336 | norm:  0.724569 | fidelity:  0.963945 | Sz:  0.000000 | S^2:  0.144068
iter: 35 | loss: -5.842821 | norm:  0.625565 | fidelity:  0.964661 | Sz:  0.000000 | S^2:  0.147921
iter: 36 | loss: -5.848770 | norm:  0.490687 | fidelity:  0.965900 | Sz:  0.000000 | S^2:  0.148016
iter: 37 | loss: -5.851472 | norm:  0.418061 | fidelity:  0.967081 | Sz:  0.000000 | S^2:  0.145201
iter: 38 | loss: -5.850401 | norm:  0.462694 | fidelity:  0.968083 | Sz: -0.000000 | S^2:  0.139566
iter: 39 | loss: -5.848236 | norm:  0.533881 | fidelity:  0.969192 | Sz:  0.000000 | S^2:  0.130684
iter: 40 | loss: -5.848252 | norm:  0.544260 | fidelity:  0.970717 | Sz: -0.000000 | S^2:  0.118607
iter: 41 | loss: -5.851096 | norm:  0.474094 | fidelity:  0.972555 | Sz:  0.000000 | S^2:  0.104570
iter: 42 | loss: -5.854685 | norm:  0.357921 | fidelity:  0.974234 | Sz: -0.000000 | S^2:  0.090821
iter: 43 | loss: -5.856391 | norm:  0.283768 | fidelity:  0.975246 | Sz:  0.000000 | S^2:  0.079744
iter: 44 | loss: -5.855517 | norm:  0.320231 | fidelity:  0.975420 | Sz:  0.000000 | S^2:  0.072922
iter: 45 | loss: -5.853670 | norm:  0.386734 | fidelity:  0.974979 | Sz:  0.000000 | S^2:  0.070722
iter: 46 | loss: -5.853033 | norm:  0.404281 | fidelity:  0.974293 | Sz: -0.000000 | S^2:  0.072612
iter: 47 | loss: -5.854320 | norm:  0.358816 | fidelity:  0.973587 | Sz:  0.000000 | S^2:  0.077792
iter: 48 | loss: -5.856429 | norm:  0.280137 | fidelity:  0.972861 | Sz: -0.000000 | S^2:  0.085528
iter: 49 | loss: -5.857822 | norm:  0.229890 | fidelity:  0.972057 | Sz:  0.000000 | S^2:  0.094975
iter: 50 | loss: -5.858005 | norm:  0.244329 | fidelity:  0.971244 | Sz: -0.000000 | S^2:  0.104853
iter: 51 | loss: -5.857644 | norm:  0.274119 | fidelity:  0.970618 | Sz: -0.000000 | S^2:  0.113470
iter: 52 | loss: -5.857539 | norm:  0.274495 | fidelity:  0.970357 | Sz:  0.000000 | S^2:  0.119207
iter: 53 | loss: -5.857913 | norm:  0.244051 | fidelity:  0.970513 | Sz: -0.000000 | S^2:  0.121185
iter: 54 | loss: -5.858363 | norm:  0.208517 | fidelity:  0.970986 | Sz: -0.000000 | S^2:  0.119602
iter: 55 | loss: -5.858534 | norm:  0.196779 | fidelity:  0.971622 | Sz: -0.000000 | S^2:  0.115557
iter: 56 | loss: -5.858457 | norm:  0.207156 | fidelity:  0.972277 | Sz: -0.000000 | S^2:  0.110483
iter: 57 | loss: -5.858497 | norm:  0.214184 | fidelity:  0.972853 | Sz: -0.000000 | S^2:  0.105617
iter: 58 | loss: -5.858792 | norm:  0.202569 | fidelity:  0.973249 | Sz:  0.000000 | S^2:  0.101745
iter: 59 | loss: -5.859297 | norm:  0.175553 | fidelity:  0.973407 | Sz: -0.000000 | S^2:  0.099233
iter: 60 | loss: -5.859660 | norm:  0.150684 | fidelity:  0.973299 | Sz:  0.000000 | S^2:  0.098100
iter: 61 | loss: -5.859782 | norm:  0.144633 | fidelity:  0.972998 | Sz:  0.000000 | S^2:  0.098068
iter: 62 | loss: -5.859685 | norm:  0.150835 | fidelity:  0.972633 | Sz:  0.000000 | S^2:  0.098611
iter: 63 | loss: -5.859559 | norm:  0.152299 | fidelity:  0.972353 | Sz:  0.000000 | S^2:  0.099132
iter: 64 | loss: -5.859571 | norm:  0.145193 | fidelity:  0.972273 | Sz:  0.000000 | S^2:  0.099214
iter: 65 | loss: -5.859672 | norm:  0.136746 | fidelity:  0.972408 | Sz: -0.000000 | S^2:  0.098778
iter: 66 | loss: -5.859821 | norm:  0.130791 | fidelity:  0.972703 | Sz:  0.000000 | S^2:  0.098071
iter: 67 | loss: -5.860002 | norm:  0.122410 | fidelity:  0.973055 | Sz: -0.000000 | S^2:  0.097496
iter: 68 | loss: -5.860160 | norm:  0.109105 | fidelity:  0.973348 | Sz:  0.000000 | S^2:  0.097412
iter: 69 | loss: -5.860219 | norm:  0.098395 | fidelity:  0.973487 | Sz:  0.000000 | S^2:  0.098020
iter: 70 | loss: -5.860218 | norm:  0.098013 | fidelity:  0.973442 | Sz: -0.000000 | S^2:  0.099329
iter: 71 | loss: -5.860160 | norm:  0.101877 | fidelity:  0.973225 | Sz:  0.000000 | S^2:  0.101171
iter: 72 | loss: -5.860166 | norm:  0.099794 | fidelity:  0.972909 | Sz:  0.000000 | S^2:  0.103236
iter: 73 | loss: -5.860234 | norm:  0.090652 | fidelity:  0.972574 | Sz:  0.000000 | S^2:  0.105134
iter: 74 | loss: -5.860293 | norm:  0.081653 | fidelity:  0.972292 | Sz:  0.000000 | S^2:  0.106488
iter: 75 | loss: -5.860331 | norm:  0.078934 | fidelity:  0.972127 | Sz:  0.000000 | S^2:  0.107042
iter: 76 | loss: -5.860327 | norm:  0.079156 | fidelity:  0.972103 | Sz: -0.000000 | S^2:  0.106716
iter: 77 | loss: -5.860390 | norm:  0.075359 | fidelity:  0.972229 | Sz: -0.000000 | S^2:  0.105618
iter: 78 | loss: -5.860424 | norm:  0.066291 | fidelity:  0.972451 | Sz: -0.000000 | S^2:  0.103990
iter: 79 | loss: -5.860463 | norm:  0.058622 | fidelity:  0.972724 | Sz:  0.000000 | S^2:  0.102131
iter: 80 | loss: -5.860456 | norm:  0.059693 | fidelity:  0.972983 | Sz: -0.000000 | S^2:  0.100332
iter: 81 | loss: -5.860439 | norm:  0.064319 | fidelity:  0.973187 | Sz:  0.000000 | S^2:  0.098838
iter: 82 | loss: -5.860438 | norm:  0.062318 | fidelity:  0.973310 | Sz: -0.000000 | S^2:  0.097824
iter: 83 | loss: -5.860488 | norm:  0.051938 | fidelity:  0.973348 | Sz: -0.000000 | S^2:  0.097393
iter: 84 | loss: -5.860512 | norm:  0.042931 | fidelity:  0.973298 | Sz: -0.000000 | S^2:  0.097567
iter: 85 | loss: -5.860525 | norm:  0.045787 | fidelity:  0.973186 | Sz:  0.000000 | S^2:  0.098294
iter: 86 | loss: -5.860512 | norm:  0.051217 | fidelity:  0.973034 | Sz:  0.000000 | S^2:  0.099449
iter: 87 | loss: -5.860536 | norm:  0.047971 | fidelity:  0.972878 | Sz: -0.000000 | S^2:  0.100850
iter: 88 | loss: -5.860555 | norm:  0.036933 | fidelity:  0.972735 | Sz: -0.000000 | S^2:  0.102278
iter: 89 | loss: -5.860589 | norm:  0.030084 | fidelity:  0.972629 | Sz: -0.000000 | S^2:  0.103509
iter: 90 | loss: -5.860567 | norm:  0.035317 | fidelity:  0.972563 | Sz:  0.000000 | S^2:  0.104344
iter: 91 | loss: -5.860524 | norm:  0.040622 | fidelity:  0.972547 | Sz:  0.000000 | S^2:  0.104660
iter: 92 | loss: -5.860549 | norm:  0.038340 | fidelity:  0.972591 | Sz:  0.000000 | S^2:  0.104435
iter: 93 | loss: -5.860563 | norm:  0.030391 | fidelity:  0.972670 | Sz: -0.000000 | S^2:  0.103748
iter: 94 | loss: -5.860602 | norm:  0.024644 | fidelity:  0.972773 | Sz:  0.000000 | S^2:  0.102769
iter: 95 | loss: -5.860574 | norm:  0.026246 | fidelity:  0.972868 | Sz:  0.000000 | S^2:  0.101703
iter: 96 | loss: -5.860564 | norm:  0.028732 | fidelity:  0.972950 | Sz:  0.000000 | S^2:  0.100746
iter: 97 | loss: -5.860580 | norm:  0.027079 | fidelity:  0.973010 | Sz:  0.000000 | S^2:  0.100046
iter: 98 | loss: -5.860581 | norm:  0.023271 | fidelity:  0.973037 | Sz: -0.000000 | S^2:  0.099676
iter: 99 | loss: -5.860587 | norm:  0.022239 | fidelity:  0.973037 | Sz: -0.000000 | S^2:  0.099638
iter: 100 | loss: -5.860575 | norm:  0.023410 | fidelity:  0.973010 | Sz: -0.000000 | S^2:  0.099882
iter: 101 | loss: -5.860597 | norm:  0.022336 | fidelity:  0.972973 | Sz:  0.000000 | S^2:  0.100324
iter: 102 | loss: -5.860606 | norm:  0.018829 | fidelity:  0.972923 | Sz: -0.000000 | S^2:  0.100873
iter: 103 | loss: -5.860594 | norm:  0.016993 | fidelity:  0.972867 | Sz: -0.000000 | S^2:  0.101445
iter: 104 | loss: -5.860590 | norm:  0.017966 | fidelity:  0.972816 | Sz:  0.000000 | S^2:  0.101965
iter: 105 | loss: -5.860594 | norm:  0.017917 | fidelity:  0.972777 | Sz: -0.000000 | S^2:  0.102370
iter: 106 | loss: -5.860619 | norm:  0.015824 | fidelity:  0.972757 | Sz:  0.000000 | S^2:  0.102610
iter: 107 | loss: -5.860603 | norm:  0.014485 | fidelity:  0.972752 | Sz: -0.000000 | S^2:  0.102657
iter: 108 | loss: -5.860582 | norm:  0.015159 | fidelity:  0.972767 | Sz: -0.000000 | S^2:  0.102514
iter: 109 | loss: -5.860610 | norm:  0.015191 | fidelity:  0.972807 | Sz: -0.000000 | S^2:  0.102218
iter: 110 | loss: -5.860621 | norm:  0.013183 | fidelity:  0.972853 | Sz:  0.000000 | S^2:  0.101836
iter: 111 | loss: -5.860621 | norm:  0.010879 | fidelity:  0.972896 | Sz:  0.000000 | S^2:  0.101449
iter: 112 | loss: -5.860631 | norm:  0.010852 | fidelity:  0.972928 | Sz: -0.000000 | S^2:  0.101133
iter: 113 | loss: -5.860605 | norm:  0.011912 | fidelity:  0.972936 | Sz:  0.000000 | S^2:  0.100939
iter: 114 | loss: -5.860607 | norm:  0.011542 | fidelity:  0.972931 | Sz: -0.000000 | S^2:  0.100882
iter: 115 | loss: -5.860600 | norm:  0.009768 | fidelity:  0.972912 | Sz:  0.000000 | S^2:  0.100941

learning rate =  0.001812430076109931
Find operators
1j [6^ 1^ 12 11] + -1j [12^ 11^ 6 1]
1j [7^ 0^ 13 10] + -1j [13^ 10^ 7 0]
-1j [9^ 0^ 10 3] + 1j [10^ 3^ 9 0]
-1j [11^ 4^ 14 1] + 1j [14^ 1^ 11 4]
1j [10^ 5^ 15 0] + -1j [15^ 0^ 10 5]
1j [8^ 1^ 11 2] + -1j [11^ 2^ 8 1]
-1j [11^ 4^ 15 0] + 1j [15^ 0^ 11 4]
1j [9^ 0^ 11 2] + -1j [11^ 2^ 9 0]
1j [8^ 1^ 10 3] + -1j [10^ 3^ 8 1]
-1j [7^ 0^ 12 11] + 1j [12^ 11^ 7 0]
-1j [6^ 1^ 13 10] + 1j [13^ 10^ 6 1]
1j [10^ 5^ 14 1] + -1j [14^ 1^ 10 5]
1j [4^ 3^ 12 11] + -1j [12^ 11^ 4 3]
-1j [9^ 6^ 15 0] + 1j [15^ 0^ 9 6]
with max gradients
[0.053688727, 0.053658698, 0.053650126, 0.053636502, 0.053617284, 0.05361037, 0.015561827, 0.013745288, 0.012293092, 0.010911919, 0.010547667, 0.010542486, 0.010200471, 0.010093792]

iter: 116 | loss: -5.860602 | norm:  0.135921 | fidelity:  0.972890 | Sz:  0.000000 | S^2:  0.101074
iter: 117 | loss: -5.860625 | norm:  0.199743 | fidelity:  0.972630 | Sz:  0.000000 | S^2:  0.103860
iter: 118 | loss: -5.861840 | norm:  0.146074 | fidelity:  0.972909 | Sz:  0.000000 | S^2:  0.101970
iter: 119 | loss: -5.862484 | norm:  0.140772 | fidelity:  0.973126 | Sz:  0.000000 | S^2:  0.100347
iter: 120 | loss: -5.862991 | norm:  0.150785 | fidelity:  0.973297 | Sz: -0.000000 | S^2:  0.099496
iter: 121 | loss: -5.863637 | norm:  0.144251 | fidelity:  0.973399 | Sz: -0.000000 | S^2:  0.099403
iter: 122 | loss: -5.864395 | norm:  0.126509 | fidelity:  0.973454 | Sz:  0.000000 | S^2:  0.099732
iter: 123 | loss: -5.865013 | norm:  0.111860 | fidelity:  0.973463 | Sz: -0.000000 | S^2:  0.100121
iter: 124 | loss: -5.865539 | norm:  0.110158 | fidelity:  0.973475 | Sz: -0.000000 | S^2:  0.100286
iter: 125 | loss: -5.865995 | norm:  0.113838 | fidelity:  0.973515 | Sz:  0.000000 | S^2:  0.100071
iter: 126 | loss: -5.866481 | norm:  0.111441 | fidelity:  0.973599 | Sz: -0.000000 | S^2:  0.099525
iter: 127 | loss: -5.867002 | norm:  0.101181 | fidelity:  0.973711 | Sz:  0.000000 | S^2:  0.098817
iter: 128 | loss: -5.867480 | norm:  0.088676 | fidelity:  0.973823 | Sz:  0.000000 | S^2:  0.098096
iter: 129 | loss: -5.867917 | norm:  0.081194 | fidelity:  0.973925 | Sz:  0.000000 | S^2:  0.097462
iter: 130 | loss: -5.868312 | norm:  0.080020 | fidelity:  0.974006 | Sz:  0.000000 | S^2:  0.096986
iter: 131 | loss: -5.868626 | norm:  0.079551 | fidelity:  0.974053 | Sz:  0.000000 | S^2:  0.096723
iter: 132 | loss: -5.868971 | norm:  0.075139 | fidelity:  0.974083 | Sz:  0.000000 | S^2:  0.096699
iter: 133 | loss: -5.869294 | norm:  0.066632 | fidelity:  0.974089 | Sz:  0.000000 | S^2:  0.096898
iter: 134 | loss: -5.869624 | norm:  0.057137 | fidelity:  0.974083 | Sz:  0.000000 | S^2:  0.097264
iter: 135 | loss: -5.869853 | norm:  0.050778 | fidelity:  0.974058 | Sz: -0.000000 | S^2:  0.097691
iter: 136 | loss: -5.870048 | norm:  0.048926 | fidelity:  0.974040 | Sz: -0.000000 | S^2:  0.098034
iter: 137 | loss: -5.870268 | norm:  0.048488 | fidelity:  0.974048 | Sz:  0.000000 | S^2:  0.098163
iter: 138 | loss: -5.870443 | norm:  0.045896 | fidelity:  0.974071 | Sz: -0.000000 | S^2:  0.098019
iter: 139 | loss: -5.870613 | norm:  0.040181 | fidelity:  0.974111 | Sz: -0.000000 | S^2:  0.097640
iter: 140 | loss: -5.870751 | norm:  0.033074 | fidelity:  0.974154 | Sz: -0.000000 | S^2:  0.097136
iter: 141 | loss: -5.870860 | norm:  0.028009 | fidelity:  0.974190 | Sz: -0.000000 | S^2:  0.096647
iter: 142 | loss: -5.870926 | norm:  0.026883 | fidelity:  0.974212 | Sz: -0.000000 | S^2:  0.096293
iter: 143 | loss: -5.871043 | norm:  0.027305 | fidelity:  0.974231 | Sz: -0.000000 | S^2:  0.096144
iter: 144 | loss: -5.871080 | norm:  0.026324 | fidelity:  0.974224 | Sz:  0.000000 | S^2:  0.096198
iter: 145 | loss: -5.871128 | norm:  0.023507 | fidelity:  0.974210 | Sz:  0.000000 | S^2:  0.096406
iter: 146 | loss: -5.871190 | norm:  0.020453 | fidelity:  0.974193 | Sz:  0.000000 | S^2:  0.096686
iter: 147 | loss: -5.871197 | norm:  0.019251 | fidelity:  0.974169 | Sz:  0.000000 | S^2:  0.096947
iter: 148 | loss: -5.871223 | norm:  0.020315 | fidelity:  0.974157 | Sz:  0.000000 | S^2:  0.097128
iter: 149 | loss: -5.871227 | norm:  0.022167 | fidelity:  0.974150 | Sz:  0.000000 | S^2:  0.097206
iter: 150 | loss: -5.871251 | norm:  0.023361 | fidelity:  0.974153 | Sz:  0.000000 | S^2:  0.097200
iter: 151 | loss: -5.871274 | norm:  0.023304 | fidelity:  0.974157 | Sz: -0.000000 | S^2:  0.097147
iter: 152 | loss: -5.871272 | norm:  0.022384 | fidelity:  0.974156 | Sz: -0.000000 | S^2:  0.097077
iter: 153 | loss: -5.871289 | norm:  0.021697 | fidelity:  0.974159 | Sz: -0.000000 | S^2:  0.097007
iter: 154 | loss: -5.871325 | norm:  0.021962 | fidelity:  0.974166 | Sz:  0.000000 | S^2:  0.096943
iter: 155 | loss: -5.871321 | norm:  0.022688 | fidelity:  0.974169 | Sz:  0.000000 | S^2:  0.096885
iter: 156 | loss: -5.871312 | norm:  0.022889 | fidelity:  0.974172 | Sz: -0.000000 | S^2:  0.096837
iter: 157 | loss: -5.871321 | norm:  0.022197 | fidelity:  0.974178 | Sz: -0.000000 | S^2:  0.096805
iter: 158 | loss: -5.871349 | norm:  0.021096 | fidelity:  0.974189 | Sz:  0.000000 | S^2:  0.096796
iter: 159 | loss: -5.871342 | norm:  0.020348 | fidelity:  0.974193 | Sz:  0.000000 | S^2:  0.096812
iter: 160 | loss: -5.871358 | norm:  0.020133 | fidelity:  0.974201 | Sz:  0.000000 | S^2:  0.096852
iter: 161 | loss: -5.871383 | norm:  0.019823 | fidelity:  0.974207 | Sz: -0.000000 | S^2:  0.096906
iter: 162 | loss: -5.871393 | norm:  0.018794 | fidelity:  0.974209 | Sz: -0.000000 | S^2:  0.096956
iter: 163 | loss: -5.871411 | norm:  0.017171 | fidelity:  0.974210 | Sz:  0.000000 | S^2:  0.096988
iter: 164 | loss: -5.871409 | norm:  0.015681 | fidelity:  0.974208 | Sz:  0.000000 | S^2:  0.096999
iter: 165 | loss: -5.871448 | norm:  0.014798 | fidelity:  0.974215 | Sz: -0.000000 | S^2:  0.097005
iter: 166 | loss: -5.871436 | norm:  0.014099 | fidelity:  0.974213 | Sz: -0.000000 | S^2:  0.097020
iter: 167 | loss: -5.871456 | norm:  0.012885 | fidelity:  0.974218 | Sz:  0.000000 | S^2:  0.097048
iter: 168 | loss: -5.871464 | norm:  0.011144 | fidelity:  0.974223 | Sz:  0.000000 | S^2:  0.097073
iter: 169 | loss: -5.871466 | norm:  0.009585 | fidelity:  0.974231 | Sz: -0.000000 | S^2:  0.097073

learning rate =  0.0008028325165597424
Find operators
1j [5^ 0^ 15 10] + -1j [15^ 10^ 5 0]
1j [10^ 7^ 13 0] + -1j [13^ 0^ 10 7]
-1j [11^ 6^ 12 1] + 1j [12^ 1^ 11 6]
-1j [2^ 1^ 11 8] + 1j [11^ 8^ 2 1]
-1j [3^ 0^ 10 9] + 1j [10^ 9^ 3 0]
1j [4^ 1^ 14 11] + -1j [14^ 11^ 4 1]
-1j [5^ 0^ 6 3] + 1j [6^ 3^ 5 0]
-1j [7^ 0^ 14 9] + 1j [14^ 9^ 7 0]
-1j [9^ 6^ 11 4] + 1j [11^ 4^ 9 6]
1j [4^ 3^ 7 0] + -1j [7^ 0^ 4 3]
1j [7^ 0^ 15 8] + -1j [15^ 8^ 7 0]
-1j [11^ 4^ 13 2] + 1j [13^ 2^ 11 4]
1j [1^ 0^ 11 10] + -1j [11^ 10^ 1 0]
-1j [11^ 6^ 14 3] + 1j [14^ 3^ 11 6]
1j [6^ 3^ 14 11] + -1j [14^ 11^ 6 3]
-1j [5^ 4^ 11 2] + 1j [11^ 2^ 5 4]
-1j [5^ 0^ 12 9] + 1j [12^ 9^ 5 0]
-1j [6^ 3^ 15 10] + 1j [15^ 10^ 6 3]
1j [12^ 1^ 14 3] + -1j [14^ 3^ 12 1]
with max gradients
[0.025495678, 0.025153687, 0.024585042, 0.023580983, 0.02308435, 0.021985415, 0.011516547, 0.011049763, 0.010858038, 0.010807365, 0.010603223, 0.0105743045, 0.0104424255, 0.010428814, 0.010199813, 0.010075051, 0.010044654, 0.010029484, 0.010026573]

iter: 170 | loss: -5.871467 | norm:  0.070534 | fidelity:  0.974241 | Sz:  0.000000 | S^2:  0.097042
iter: 171 | loss: -5.871524 | norm:  0.085045 | fidelity:  0.974452 | Sz: -0.000000 | S^2:  0.095147
iter: 172 | loss: -5.871801 | norm:  0.068192 | fidelity:  0.974476 | Sz:  0.000000 | S^2:  0.095986
iter: 173 | loss: -5.871941 | norm:  0.064051 | fidelity:  0.974486 | Sz:  0.000000 | S^2:  0.096475
iter: 174 | loss: -5.872090 | norm:  0.061922 | fidelity:  0.974505 | Sz:  0.000000 | S^2:  0.096513
iter: 175 | loss: -5.872239 | norm:  0.055791 | fidelity:  0.974535 | Sz: -0.000000 | S^2:  0.096242
iter: 176 | loss: -5.872413 | norm:  0.052601 | fidelity:  0.974584 | Sz: -0.000000 | S^2:  0.095772
iter: 177 | loss: -5.872543 | norm:  0.053717 | fidelity:  0.974633 | Sz:  0.000000 | S^2:  0.095284
iter: 178 | loss: -5.872681 | norm:  0.055036 | fidelity:  0.974683 | Sz: -0.000000 | S^2:  0.094896
iter: 179 | loss: -5.872790 | norm:  0.054359 | fidelity:  0.974724 | Sz: -0.000000 | S^2:  0.094646
iter: 180 | loss: -5.872943 | norm:  0.052796 | fidelity:  0.974769 | Sz: -0.000000 | S^2:  0.094528
iter: 181 | loss: -5.873086 | norm:  0.051938 | fidelity:  0.974812 | Sz: -0.000000 | S^2:  0.094481
iter: 182 | loss: -5.873209 | norm:  0.051214 | fidelity:  0.974855 | Sz: -0.000000 | S^2:  0.094431
iter: 183 | loss: -5.873348 | norm:  0.050034 | fidelity:  0.974907 | Sz:  0.000000 | S^2:  0.094318
iter: 184 | loss: -5.873459 | norm:  0.049157 | fidelity:  0.974964 | Sz: -0.000000 | S^2:  0.094099
iter: 185 | loss: -5.873572 | norm:  0.049194 | fidelity:  0.975026 | Sz: -0.000000 | S^2:  0.093769
iter: 186 | loss: -5.873728 | norm:  0.049587 | fidelity:  0.975097 | Sz: -0.000000 | S^2:  0.093367
iter: 187 | loss: -5.873833 | norm:  0.049405 | fidelity:  0.975155 | Sz:  0.000000 | S^2:  0.092949
iter: 188 | loss: -5.873970 | norm:  0.048390 | fidelity:  0.975212 | Sz:  0.000000 | S^2:  0.092578
iter: 189 | loss: -5.874098 | norm:  0.047089 | fidelity:  0.975257 | Sz: -0.000000 | S^2:  0.092297
iter: 190 | loss: -5.874261 | norm:  0.046367 | fidelity:  0.975300 | Sz:  0.000000 | S^2:  0.092117
iter: 191 | loss: -5.874353 | norm:  0.046616 | fidelity:  0.975324 | Sz:  0.000000 | S^2:  0.092013
iter: 192 | loss: -5.874473 | norm:  0.047366 | fidelity:  0.975353 | Sz: -0.000000 | S^2:  0.091935
iter: 193 | loss: -5.874613 | norm:  0.047835 | fidelity:  0.975389 | Sz: -0.000000 | S^2:  0.091834
iter: 194 | loss: -5.874741 | norm:  0.047712 | fidelity:  0.975432 | Sz: -0.000000 | S^2:  0.091678
iter: 195 | loss: -5.874899 | norm:  0.047369 | fidelity:  0.975488 | Sz:  0.000000 | S^2:  0.091456
iter: 196 | loss: -5.875035 | norm:  0.047387 | fidelity:  0.975548 | Sz:  0.000000 | S^2:  0.091177
iter: 197 | loss: -5.875171 | norm:  0.047839 | fidelity:  0.975612 | Sz:  0.000000 | S^2:  0.090866
iter: 198 | loss: -5.875277 | norm:  0.048201 | fidelity:  0.975670 | Sz:  0.000000 | S^2:  0.090546
iter: 199 | loss: -5.875434 | norm:  0.048006 | fidelity:  0.975732 | Sz: -0.000000 | S^2:  0.090239
iter: 200 | loss: -5.875561 | norm:  0.047363 | fidelity:  0.975785 | Sz: -0.000000 | S^2:  0.089956
iter: 201 | loss: -5.875713 | norm:  0.046819 | fidelity:  0.975837 | Sz: -0.000000 | S^2:  0.089699
iter: 202 | loss: -5.875820 | norm:  0.046721 | fidelity:  0.975879 | Sz: -0.000000 | S^2:  0.089458
iter: 203 | loss: -5.875977 | norm:  0.046897 | fidelity:  0.975931 | Sz:  0.000000 | S^2:  0.089218
iter: 204 | loss: -5.876108 | norm:  0.047026 | fidelity:  0.975982 | Sz:  0.000000 | S^2:  0.088958
iter: 205 | loss: -5.876229 | norm:  0.046998 | fidelity:  0.976036 | Sz:  0.000000 | S^2:  0.088670
iter: 206 | loss: -5.876407 | norm:  0.046944 | fidelity:  0.976103 | Sz:  0.000000 | S^2:  0.088355
iter: 207 | loss: -5.876498 | norm:  0.047073 | fidelity:  0.976158 | Sz:  0.000000 | S^2:  0.088027
iter: 208 | loss: -5.876650 | norm:  0.047388 | fidelity:  0.976221 | Sz: -0.000000 | S^2:  0.087712
iter: 209 | loss: -5.876815 | norm:  0.047655 | fidelity:  0.976283 | Sz:  0.000000 | S^2:  0.087427
iter: 210 | loss: -5.876922 | norm:  0.047716 | fidelity:  0.976330 | Sz: -0.000000 | S^2:  0.087180
iter: 211 | loss: -5.877074 | norm:  0.047622 | fidelity:  0.976382 | Sz:  0.000000 | S^2:  0.086965
iter: 212 | loss: -5.877185 | norm:  0.047495 | fidelity:  0.976425 | Sz:  0.000000 | S^2:  0.086763
iter: 213 | loss: -5.877322 | norm:  0.047423 | fidelity:  0.976473 | Sz:  0.000000 | S^2:  0.086553
iter: 214 | loss: -5.877477 | norm:  0.047401 | fidelity:  0.976528 | Sz:  0.000000 | S^2:  0.086316
iter: 215 | loss: -5.877612 | norm:  0.047382 | fidelity:  0.976584 | Sz: -0.000000 | S^2:  0.086044
iter: 216 | loss: -5.877755 | norm:  0.047383 | fidelity:  0.976645 | Sz:  0.000000 | S^2:  0.085739
iter: 217 | loss: -5.877900 | norm:  0.047453 | fidelity:  0.976709 | Sz:  0.000000 | S^2:  0.085411
iter: 218 | loss: -5.878025 | norm:  0.047585 | fidelity:  0.976769 | Sz:  0.000000 | S^2:  0.085079
iter: 219 | loss: -5.878153 | norm:  0.047735 | fidelity:  0.976829 | Sz: -0.000000 | S^2:  0.084758
iter: 220 | loss: -5.878285 | norm:  0.047850 | fidelity:  0.976886 | Sz: -0.000000 | S^2:  0.084459
iter: 221 | loss: -5.878436 | norm:  0.047915 | fidelity:  0.976944 | Sz: -0.000000 | S^2:  0.084186
iter: 222 | loss: -5.878570 | norm:  0.047962 | fidelity:  0.976998 | Sz:  0.000000 | S^2:  0.083931
iter: 223 | loss: -5.878712 | norm:  0.048010 | fidelity:  0.977053 | Sz:  0.000000 | S^2:  0.083681
iter: 224 | loss: -5.878864 | norm:  0.048053 | fidelity:  0.977110 | Sz:  0.000000 | S^2:  0.083426
iter: 225 | loss: -5.878988 | norm:  0.048088 | fidelity:  0.977165 | Sz: -0.000000 | S^2:  0.083159
iter: 226 | loss: -5.879118 | norm:  0.048127 | fidelity:  0.977221 | Sz: -0.000000 | S^2:  0.082881
iter: 227 | loss: -5.879274 | norm:  0.048183 | fidelity:  0.977282 | Sz: -0.000000 | S^2:  0.082596
iter: 228 | loss: -5.879390 | norm:  0.048263 | fidelity:  0.977338 | Sz: -0.000000 | S^2:  0.082306
iter: 229 | loss: -5.879553 | norm:  0.048351 | fidelity:  0.977402 | Sz:  0.000000 | S^2:  0.082012
iter: 230 | loss: -5.879654 | norm:  0.048432 | fidelity:  0.977457 | Sz: -0.000000 | S^2:  0.081712
iter: 231 | loss: -5.879834 | norm:  0.048509 | fidelity:  0.977524 | Sz: -0.000000 | S^2:  0.081408
iter: 232 | loss: -5.879948 | norm:  0.048592 | fidelity:  0.977582 | Sz:  0.000000 | S^2:  0.081098
iter: 233 | loss: -5.880146 | norm:  0.048688 | fidelity:  0.977653 | Sz: -0.000000 | S^2:  0.080786
iter: 234 | loss: -5.880271 | norm:  0.048785 | fidelity:  0.977713 | Sz: -0.000000 | S^2:  0.080473
iter: 235 | loss: -5.880399 | norm:  0.048867 | fidelity:  0.977772 | Sz:  0.000000 | S^2:  0.080166
iter: 236 | loss: -5.880537 | norm:  0.048927 | fidelity:  0.977832 | Sz: -0.000000 | S^2:  0.079870
iter: 237 | loss: -5.880674 | norm:  0.048978 | fidelity:  0.977891 | Sz: -0.000000 | S^2:  0.079584
iter: 238 | loss: -5.880811 | norm:  0.049041 | fidelity:  0.977951 | Sz: -0.000000 | S^2:  0.079302
iter: 239 | loss: -5.880959 | norm:  0.049124 | fidelity:  0.978013 | Sz: -0.000000 | S^2:  0.079018
iter: 240 | loss: -5.881087 | norm:  0.049221 | fidelity:  0.978072 | Sz: -0.000000 | S^2:  0.078724
iter: 241 | loss: -5.881243 | norm:  0.049328 | fidelity:  0.978137 | Sz:  0.000000 | S^2:  0.078420
iter: 242 | loss: -5.881410 | norm:  0.049450 | fidelity:  0.978204 | Sz: -0.000000 | S^2:  0.078113
iter: 243 | loss: -5.881543 | norm:  0.049583 | fidelity:  0.978265 | Sz: -0.000000 | S^2:  0.077804
iter: 244 | loss: -5.881666 | norm:  0.049709 | fidelity:  0.978324 | Sz: -0.000000 | S^2:  0.077496
iter: 245 | loss: -5.881832 | norm:  0.049815 | fidelity:  0.978391 | Sz: -0.000000 | S^2:  0.077189
iter: 246 | loss: -5.881959 | norm:  0.049906 | fidelity:  0.978451 | Sz:  0.000000 | S^2:  0.076880
iter: 247 | loss: -5.882104 | norm:  0.049995 | fidelity:  0.978515 | Sz:  0.000000 | S^2:  0.076569
iter: 248 | loss: -5.882253 | norm:  0.050091 | fidelity:  0.978580 | Sz: -0.000000 | S^2:  0.076255
iter: 249 | loss: -5.882395 | norm:  0.050191 | fidelity:  0.978645 | Sz:  0.000000 | S^2:  0.075937
iter: 250 | loss: -5.882535 | norm:  0.050294 | fidelity:  0.978710 | Sz: -0.000000 | S^2:  0.075616
iter: 251 | loss: -5.882686 | norm:  0.050400 | fidelity:  0.978776 | Sz:  0.000000 | S^2:  0.075297
iter: 252 | loss: -5.882830 | norm:  0.050512 | fidelity:  0.978841 | Sz:  0.000000 | S^2:  0.074983
iter: 253 | loss: -5.882989 | norm:  0.050628 | fidelity:  0.978907 | Sz: -0.000000 | S^2:  0.074675
iter: 254 | loss: -5.883105 | norm:  0.050749 | fidelity:  0.978967 | Sz: -0.000000 | S^2:  0.074365
iter: 255 | loss: -5.883253 | norm:  0.050875 | fidelity:  0.979032 | Sz: -0.000000 | S^2:  0.074049
iter: 256 | loss: -5.883414 | norm:  0.051008 | fidelity:  0.979101 | Sz:  0.000000 | S^2:  0.073723
iter: 257 | loss: -5.883556 | norm:  0.051147 | fidelity:  0.979168 | Sz:  0.000000 | S^2:  0.073389
iter: 258 | loss: -5.883695 | norm:  0.051287 | fidelity:  0.979235 | Sz:  0.000000 | S^2:  0.073051
iter: 259 | loss: -5.883882 | norm:  0.051422 | fidelity:  0.979309 | Sz: -0.000000 | S^2:  0.072714
iter: 260 | loss: -5.884034 | norm:  0.051550 | fidelity:  0.979378 | Sz: -0.000000 | S^2:  0.072382
iter: 261 | loss: -5.884183 | norm:  0.051673 | fidelity:  0.979445 | Sz:  0.000000 | S^2:  0.072054
iter: 262 | loss: -5.884317 | norm:  0.051795 | fidelity:  0.979510 | Sz:  0.000000 | S^2:  0.071730
iter: 263 | loss: -5.884474 | norm:  0.051920 | fidelity:  0.979579 | Sz:  0.000000 | S^2:  0.071405
iter: 264 | loss: -5.884634 | norm:  0.052051 | fidelity:  0.979649 | Sz:  0.000000 | S^2:  0.071073
iter: 265 | loss: -5.884791 | norm:  0.052190 | fidelity:  0.979720 | Sz:  0.000000 | S^2:  0.070732
iter: 266 | loss: -5.884903 | norm:  0.052337 | fidelity:  0.979784 | Sz: -0.000000 | S^2:  0.070386
iter: 267 | loss: -5.885086 | norm:  0.052488 | fidelity:  0.979860 | Sz: -0.000000 | S^2:  0.070037
iter: 268 | loss: -5.885218 | norm:  0.052639 | fidelity:  0.979928 | Sz:  0.000000 | S^2:  0.069687
iter: 269 | loss: -5.885417 | norm:  0.052788 | fidelity:  0.980006 | Sz:  0.000000 | S^2:  0.069339
iter: 270 | loss: -5.885529 | norm:  0.052934 | fidelity:  0.980071 | Sz:  0.000000 | S^2:  0.068990
iter: 271 | loss: -5.885707 | norm:  0.053077 | fidelity:  0.980146 | Sz:  0.000000 | S^2:  0.068641
iter: 272 | loss: -5.885862 | norm:  0.053220 | fidelity:  0.980218 | Sz: -0.000000 | S^2:  0.068288
iter: 273 | loss: -5.886010 | norm:  0.053363 | fidelity:  0.980290 | Sz: -0.000000 | S^2:  0.067932
iter: 274 | loss: -5.886178 | norm:  0.053508 | fidelity:  0.980366 | Sz:  0.000000 | S^2:  0.067573
iter: 275 | loss: -5.886340 | norm:  0.053654 | fidelity:  0.980441 | Sz: -0.000000 | S^2:  0.067209
iter: 276 | loss: -5.886492 | norm:  0.053800 | fidelity:  0.980515 | Sz: -0.000000 | S^2:  0.066844
iter: 277 | loss: -5.886657 | norm:  0.053947 | fidelity:  0.980590 | Sz:  0.000000 | S^2:  0.066478
iter: 278 | loss: -5.886836 | norm:  0.054094 | fidelity:  0.980669 | Sz:  0.000000 | S^2:  0.066112
iter: 279 | loss: -5.887018 | norm:  0.054243 | fidelity:  0.980748 | Sz:  0.000000 | S^2:  0.065742
iter: 280 | loss: -5.887175 | norm:  0.054393 | fidelity:  0.980824 | Sz: -0.000000 | S^2:  0.065369
iter: 281 | loss: -5.887354 | norm:  0.054542 | fidelity:  0.980904 | Sz: -0.000000 | S^2:  0.064992
iter: 282 | loss: -5.887479 | norm:  0.054688 | fidelity:  0.980976 | Sz:  0.000000 | S^2:  0.064612
iter: 283 | loss: -5.887658 | norm:  0.054831 | fidelity:  0.981057 | Sz: -0.000000 | S^2:  0.064229
iter: 284 | loss: -5.887857 | norm:  0.054970 | fidelity:  0.981141 | Sz:  0.000000 | S^2:  0.063846
iter: 285 | loss: -5.887986 | norm:  0.055105 | fidelity:  0.981214 | Sz:  0.000000 | S^2:  0.063460
iter: 286 | loss: -5.888179 | norm:  0.055240 | fidelity:  0.981298 | Sz: -0.000000 | S^2:  0.063074
iter: 287 | loss: -5.888346 | norm:  0.055376 | fidelity:  0.981378 | Sz: -0.000000 | S^2:  0.062684
iter: 288 | loss: -5.888482 | norm:  0.055512 | fidelity:  0.981453 | Sz:  0.000000 | S^2:  0.062292
iter: 289 | loss: -5.888695 | norm:  0.055647 | fidelity:  0.981542 | Sz:  0.000000 | S^2:  0.061897
iter: 290 | loss: -5.888855 | norm:  0.055779 | fidelity:  0.981623 | Sz: -0.000000 | S^2:  0.061497
iter: 291 | loss: -5.889014 | norm:  0.055907 | fidelity:  0.981703 | Sz:  0.000000 | S^2:  0.061095
iter: 292 | loss: -5.889198 | norm:  0.056032 | fidelity:  0.981788 | Sz:  0.000000 | S^2:  0.060691
iter: 293 | loss: -5.889385 | norm:  0.056151 | fidelity:  0.981875 | Sz:  0.000000 | S^2:  0.060284
iter: 294 | loss: -5.889574 | norm:  0.056267 | fidelity:  0.981961 | Sz: -0.000000 | S^2:  0.059875
iter: 295 | loss: -5.889715 | norm:  0.056377 | fidelity:  0.982041 | Sz:  0.000000 | S^2:  0.059464
iter: 296 | loss: -5.889920 | norm:  0.056483 | fidelity:  0.982131 | Sz: -0.000000 | S^2:  0.059052
iter: 297 | loss: -5.890095 | norm:  0.056585 | fidelity:  0.982216 | Sz:  0.000000 | S^2:  0.058637
iter: 298 | loss: -5.890267 | norm:  0.056682 | fidelity:  0.982302 | Sz:  0.000000 | S^2:  0.058220
iter: 299 | loss: -5.890453 | norm:  0.056775 | fidelity:  0.982390 | Sz: -0.000000 | S^2:  0.057800
iter: 300 | loss: -5.890620 | norm:  0.056863 | fidelity:  0.982476 | Sz:  0.000000 | S^2:  0.057377
iter: 301 | loss: -5.890794 | norm:  0.056946 | fidelity:  0.982563 | Sz:  0.000000 | S^2:  0.056952
iter: 302 | loss: -5.890993 | norm:  0.057024 | fidelity:  0.982654 | Sz: -0.000000 | S^2:  0.056526
iter: 303 | loss: -5.891159 | norm:  0.057095 | fidelity:  0.982741 | Sz:  0.000000 | S^2:  0.056098
iter: 304 | loss: -5.891361 | norm:  0.057160 | fidelity:  0.982834 | Sz: -0.000000 | S^2:  0.055668
iter: 305 | loss: -5.891531 | norm:  0.057217 | fidelity:  0.982921 | Sz: -0.000000 | S^2:  0.055236
iter: 306 | loss: -5.891708 | norm:  0.057266 | fidelity:  0.983011 | Sz:  0.000000 | S^2:  0.054802
iter: 307 | loss: -5.891903 | norm:  0.057306 | fidelity:  0.983103 | Sz:  0.000000 | S^2:  0.054367
iter: 308 | loss: -5.892106 | norm:  0.057339 | fidelity:  0.983198 | Sz:  0.000000 | S^2:  0.053929
iter: 309 | loss: -5.892276 | norm:  0.057362 | fidelity:  0.983287 | Sz: -0.000000 | S^2:  0.053491
iter: 310 | loss: -5.892446 | norm:  0.057377 | fidelity:  0.983376 | Sz:  0.000000 | S^2:  0.053050
iter: 311 | loss: -5.892639 | norm:  0.057383 | fidelity:  0.983470 | Sz: -0.000000 | S^2:  0.052609
iter: 312 | loss: -5.892814 | norm:  0.057379 | fidelity:  0.983561 | Sz: -0.000000 | S^2:  0.052167
iter: 313 | loss: -5.893022 | norm:  0.057367 | fidelity:  0.983658 | Sz: -0.000000 | S^2:  0.051723
iter: 314 | loss: -5.893197 | norm:  0.057344 | fidelity:  0.983749 | Sz: -0.000000 | S^2:  0.051279
iter: 315 | loss: -5.893388 | norm:  0.057311 | fidelity:  0.983843 | Sz: -0.000000 | S^2:  0.050833
iter: 316 | loss: -5.893539 | norm:  0.057266 | fidelity:  0.983931 | Sz: -0.000000 | S^2:  0.050386
iter: 317 | loss: -5.893739 | norm:  0.057209 | fidelity:  0.984027 | Sz: -0.000000 | S^2:  0.049940
iter: 318 | loss: -5.893943 | norm:  0.057140 | fidelity:  0.984124 | Sz:  0.000000 | S^2:  0.049494
iter: 319 | loss: -5.894121 | norm:  0.057058 | fidelity:  0.984217 | Sz:  0.000000 | S^2:  0.049047
iter: 320 | loss: -5.894308 | norm:  0.056963 | fidelity:  0.984312 | Sz: -0.000000 | S^2:  0.048600
iter: 321 | loss: -5.894475 | norm:  0.056855 | fidelity:  0.984403 | Sz: -0.000000 | S^2:  0.048153
iter: 322 | loss: -5.894689 | norm:  0.056734 | fidelity:  0.984502 | Sz: -0.000000 | S^2:  0.047706
iter: 323 | loss: -5.894854 | norm:  0.056600 | fidelity:  0.984593 | Sz: -0.000000 | S^2:  0.047260
iter: 324 | loss: -5.895021 | norm:  0.056451 | fidelity:  0.984685 | Sz: -0.000000 | S^2:  0.046814
iter: 325 | loss: -5.895233 | norm:  0.056287 | fidelity:  0.984784 | Sz:  0.000000 | S^2:  0.046369
iter: 326 | loss: -5.895389 | norm:  0.056107 | fidelity:  0.984874 | Sz:  0.000000 | S^2:  0.045925
iter: 327 | loss: -5.895551 | norm:  0.055913 | fidelity:  0.984965 | Sz:  0.000000 | S^2:  0.045483
iter: 328 | loss: -5.895767 | norm:  0.055702 | fidelity:  0.985064 | Sz:  0.000000 | S^2:  0.045042
iter: 329 | loss: -5.895938 | norm:  0.055475 | fidelity:  0.985157 | Sz: -0.000000 | S^2:  0.044602
iter: 330 | loss: -5.896089 | norm:  0.055232 | fidelity:  0.985245 | Sz: -0.000000 | S^2:  0.044164
iter: 331 | loss: -5.896277 | norm:  0.054971 | fidelity:  0.985340 | Sz: -0.000000 | S^2:  0.043729
iter: 332 | loss: -5.896445 | norm:  0.054693 | fidelity:  0.985431 | Sz:  0.000000 | S^2:  0.043295
iter: 333 | loss: -5.896649 | norm:  0.054399 | fidelity:  0.985528 | Sz: -0.000000 | S^2:  0.042864
iter: 334 | loss: -5.896814 | norm:  0.054086 | fidelity:  0.985619 | Sz: -0.000000 | S^2:  0.042436
iter: 335 | loss: -5.897001 | norm:  0.053756 | fidelity:  0.985713 | Sz:  0.000000 | S^2:  0.042011
iter: 336 | loss: -5.897149 | norm:  0.053408 | fidelity:  0.985800 | Sz:  0.000000 | S^2:  0.041588
iter: 337 | loss: -5.897329 | norm:  0.053042 | fidelity:  0.985892 | Sz: -0.000000 | S^2:  0.041170
iter: 338 | loss: -5.897473 | norm:  0.052658 | fidelity:  0.985978 | Sz: -0.000000 | S^2:  0.040754
iter: 339 | loss: -5.897659 | norm:  0.052255 | fidelity:  0.986070 | Sz:  0.000000 | S^2:  0.040343
iter: 340 | loss: -5.897808 | norm:  0.051834 | fidelity:  0.986156 | Sz: -0.000000 | S^2:  0.039935
iter: 341 | loss: -5.898003 | norm:  0.051395 | fidelity:  0.986249 | Sz: -0.000000 | S^2:  0.039532
iter: 342 | loss: -5.898135 | norm:  0.050938 | fidelity:  0.986332 | Sz:  0.000000 | S^2:  0.039133
iter: 343 | loss: -5.898295 | norm:  0.050463 | fidelity:  0.986418 | Sz: -0.000000 | S^2:  0.038739
iter: 344 | loss: -5.898442 | norm:  0.049970 | fidelity:  0.986501 | Sz: -0.000000 | S^2:  0.038350
iter: 345 | loss: -5.898597 | norm:  0.049460 | fidelity:  0.986586 | Sz:  0.000000 | S^2:  0.037966
iter: 346 | loss: -5.898748 | norm:  0.048932 | fidelity:  0.986669 | Sz:  0.000000 | S^2:  0.037587
iter: 347 | loss: -5.898900 | norm:  0.048388 | fidelity:  0.986752 | Sz: -0.000000 | S^2:  0.037214
iter: 348 | loss: -5.899023 | norm:  0.047827 | fidelity:  0.986829 | Sz:  0.000000 | S^2:  0.036846
iter: 349 | loss: -5.899189 | norm:  0.047251 | fidelity:  0.986913 | Sz: -0.000000 | S^2:  0.036484
iter: 350 | loss: -5.899303 | norm:  0.046659 | fidelity:  0.986988 | Sz: -0.000000 | S^2:  0.036128
iter: 351 | loss: -5.899457 | norm:  0.046053 | fidelity:  0.987068 | Sz: -0.000000 | S^2:  0.035778
iter: 352 | loss: -5.899579 | norm:  0.045433 | fidelity:  0.987143 | Sz: -0.000000 | S^2:  0.035435
iter: 353 | loss: -5.899683 | norm:  0.044799 | fidelity:  0.987213 | Sz: -0.000000 | S^2:  0.035098
iter: 354 | loss: -5.899887 | norm:  0.044154 | fidelity:  0.987300 | Sz:  0.000000 | S^2:  0.034768
iter: 355 | loss: -5.899959 | norm:  0.043496 | fidelity:  0.987363 | Sz: -0.000000 | S^2:  0.034444
iter: 356 | loss: -5.900077 | norm:  0.042827 | fidelity:  0.987434 | Sz: -0.000000 | S^2:  0.034127
iter: 357 | loss: -5.900196 | norm:  0.042150 | fidelity:  0.987503 | Sz:  0.000000 | S^2:  0.033817
iter: 358 | loss: -5.900348 | norm:  0.041463 | fidelity:  0.987578 | Sz:  0.000000 | S^2:  0.033514
iter: 359 | loss: -5.900442 | norm:  0.040769 | fidelity:  0.987642 | Sz: -0.000000 | S^2:  0.033218
iter: 360 | loss: -5.900555 | norm:  0.040069 | fidelity:  0.987708 | Sz:  0.000000 | S^2:  0.032930
iter: 361 | loss: -5.900658 | norm:  0.039363 | fidelity:  0.987771 | Sz: -0.000000 | S^2:  0.032648
iter: 362 | loss: -5.900773 | norm:  0.038652 | fidelity:  0.987836 | Sz:  0.000000 | S^2:  0.032374
iter: 363 | loss: -5.900842 | norm:  0.037939 | fidelity:  0.987892 | Sz:  0.000000 | S^2:  0.032106
iter: 364 | loss: -5.900953 | norm:  0.037224 | fidelity:  0.987954 | Sz: -0.000000 | S^2:  0.031846
iter: 365 | loss: -5.901045 | norm:  0.036509 | fidelity:  0.988011 | Sz:  0.000000 | S^2:  0.031593
iter: 366 | loss: -5.901104 | norm:  0.035794 | fidelity:  0.988063 | Sz: -0.000000 | S^2:  0.031347
iter: 367 | loss: -5.901243 | norm:  0.035081 | fidelity:  0.988126 | Sz: -0.000000 | S^2:  0.031109
iter: 368 | loss: -5.901285 | norm:  0.034371 | fidelity:  0.988173 | Sz:  0.000000 | S^2:  0.030877
iter: 369 | loss: -5.901394 | norm:  0.033665 | fidelity:  0.988230 | Sz:  0.000000 | S^2:  0.030652
iter: 370 | loss: -5.901454 | norm:  0.032965 | fidelity:  0.988277 | Sz:  0.000000 | S^2:  0.030434
iter: 371 | loss: -5.901546 | norm:  0.032272 | fidelity:  0.988329 | Sz: -0.000000 | S^2:  0.030223
iter: 372 | loss: -5.901622 | norm:  0.031587 | fidelity:  0.988377 | Sz: -0.000000 | S^2:  0.030019
iter: 373 | loss: -5.901670 | norm:  0.030910 | fidelity:  0.988420 | Sz:  0.000000 | S^2:  0.029821
iter: 374 | loss: -5.901736 | norm:  0.030243 | fidelity:  0.988464 | Sz:  0.000000 | S^2:  0.029630
iter: 375 | loss: -5.901829 | norm:  0.029587 | fidelity:  0.988512 | Sz: -0.000000 | S^2:  0.029446
iter: 376 | loss: -5.901871 | norm:  0.028943 | fidelity:  0.988551 | Sz: -0.000000 | S^2:  0.029267
iter: 377 | loss: -5.901968 | norm:  0.028312 | fidelity:  0.988598 | Sz: -0.000000 | S^2:  0.029095
iter: 378 | loss: -5.902006 | norm:  0.027694 | fidelity:  0.988634 | Sz: -0.000000 | S^2:  0.028929
iter: 379 | loss: -5.902054 | norm:  0.027089 | fidelity:  0.988670 | Sz:  0.000000 | S^2:  0.028768
iter: 380 | loss: -5.902088 | norm:  0.026500 | fidelity:  0.988704 | Sz: -0.000000 | S^2:  0.028613
iter: 381 | loss: -5.902148 | norm:  0.025926 | fidelity:  0.988741 | Sz: -0.000000 | S^2:  0.028464
iter: 382 | loss: -5.902182 | norm:  0.025368 | fidelity:  0.988772 | Sz: -0.000000 | S^2:  0.028321
iter: 383 | loss: -5.902243 | norm:  0.024825 | fidelity:  0.988808 | Sz: -0.000000 | S^2:  0.028182
iter: 384 | loss: -5.902295 | norm:  0.024299 | fidelity:  0.988841 | Sz:  0.000000 | S^2:  0.028049
iter: 385 | loss: -5.902323 | norm:  0.023790 | fidelity:  0.988868 | Sz: -0.000000 | S^2:  0.027921
iter: 386 | loss: -5.902416 | norm:  0.023297 | fidelity:  0.988907 | Sz:  0.000000 | S^2:  0.027798
iter: 387 | loss: -5.902418 | norm:  0.022820 | fidelity:  0.988928 | Sz: -0.000000 | S^2:  0.027679
iter: 388 | loss: -5.902441 | norm:  0.022361 | fidelity:  0.988953 | Sz:  0.000000 | S^2:  0.027564
iter: 389 | loss: -5.902486 | norm:  0.021918 | fidelity:  0.988981 | Sz:  0.000000 | S^2:  0.027454
iter: 390 | loss: -5.902502 | norm:  0.021491 | fidelity:  0.989003 | Sz: -0.000000 | S^2:  0.027349
iter: 391 | loss: -5.902559 | norm:  0.021080 | fidelity:  0.989031 | Sz: -0.000000 | S^2:  0.027247
iter: 392 | loss: -5.902577 | norm:  0.020685 | fidelity:  0.989052 | Sz:  0.000000 | S^2:  0.027149
iter: 393 | loss: -5.902614 | norm:  0.020306 | fidelity:  0.989075 | Sz:  0.000000 | S^2:  0.027055
iter: 394 | loss: -5.902626 | norm:  0.019941 | fidelity:  0.989093 | Sz:  0.000000 | S^2:  0.026965
iter: 395 | loss: -5.902674 | norm:  0.019592 | fidelity:  0.989117 | Sz:  0.000000 | S^2:  0.026878
iter: 396 | loss: -5.902722 | norm:  0.019256 | fidelity:  0.989140 | Sz:  0.000000 | S^2:  0.026795
iter: 397 | loss: -5.902741 | norm:  0.018934 | fidelity:  0.989158 | Sz:  0.000000 | S^2:  0.026715
iter: 398 | loss: -5.902766 | norm:  0.018624 | fidelity:  0.989176 | Sz:  0.000000 | S^2:  0.026638
iter: 399 | loss: -5.902770 | norm:  0.018328 | fidelity:  0.989190 | Sz:  0.000000 | S^2:  0.026564
iter: 400 | loss: -5.902833 | norm:  0.018044 | fidelity:  0.989213 | Sz: -0.000000 | S^2:  0.026493
iter: 401 | loss: -5.902826 | norm:  0.017771 | fidelity:  0.989224 | Sz: -0.000000 | S^2:  0.026425
iter: 402 | loss: -5.902851 | norm:  0.017509 | fidelity:  0.989240 | Sz: -0.000000 | S^2:  0.026359
iter: 403 | loss: -5.902893 | norm:  0.017257 | fidelity:  0.989259 | Sz: -0.000000 | S^2:  0.026296
iter: 404 | loss: -5.902891 | norm:  0.017015 | fidelity:  0.989269 | Sz:  0.000000 | S^2:  0.026235
iter: 405 | loss: -5.902912 | norm:  0.016783 | fidelity:  0.989283 | Sz: -0.000000 | S^2:  0.026176
iter: 406 | loss: -5.902942 | norm:  0.016560 | fidelity:  0.989298 | Sz: -0.000000 | S^2:  0.026120
iter: 407 | loss: -5.902953 | norm:  0.016345 | fidelity:  0.989309 | Sz:  0.000000 | S^2:  0.026065
iter: 408 | loss: -5.902956 | norm:  0.016137 | fidelity:  0.989319 | Sz: -0.000000 | S^2:  0.026013
iter: 409 | loss: -5.903022 | norm:  0.015938 | fidelity:  0.989338 | Sz: -0.000000 | S^2:  0.025963
iter: 410 | loss: -5.903003 | norm:  0.015745 | fidelity:  0.989344 | Sz: -0.000000 | S^2:  0.025914
iter: 411 | loss: -5.903048 | norm:  0.015558 | fidelity:  0.989359 | Sz: -0.000000 | S^2:  0.025867
iter: 412 | loss: -5.903032 | norm:  0.015378 | fidelity:  0.989364 | Sz:  0.000000 | S^2:  0.025822
iter: 413 | loss: -5.903071 | norm:  0.015204 | fidelity:  0.989378 | Sz: -0.000000 | S^2:  0.025778
iter: 414 | loss: -5.903091 | norm:  0.015035 | fidelity:  0.989389 | Sz: -0.000000 | S^2:  0.025736
iter: 415 | loss: -5.903087 | norm:  0.014872 | fidelity:  0.989395 | Sz: -0.000000 | S^2:  0.025695
iter: 416 | loss: -5.903099 | norm:  0.014713 | fidelity:  0.989404 | Sz: -0.000000 | S^2:  0.025655
iter: 417 | loss: -5.903123 | norm:  0.014558 | fidelity:  0.989414 | Sz:  0.000000 | S^2:  0.025617
iter: 418 | loss: -5.903154 | norm:  0.014408 | fidelity:  0.989425 | Sz:  0.000000 | S^2:  0.025579
iter: 419 | loss: -5.903164 | norm:  0.014261 | fidelity:  0.989433 | Sz:  0.000000 | S^2:  0.025543
iter: 420 | loss: -5.903170 | norm:  0.014118 | fidelity:  0.989440 | Sz: -0.000000 | S^2:  0.025508
iter: 421 | loss: -5.903202 | norm:  0.013979 | fidelity:  0.989451 | Sz: -0.000000 | S^2:  0.025474
iter: 422 | loss: -5.903226 | norm:  0.013843 | fidelity:  0.989460 | Sz: -0.000000 | S^2:  0.025441
iter: 423 | loss: -5.903225 | norm:  0.013710 | fidelity:  0.989465 | Sz: -0.000000 | S^2:  0.025408
iter: 424 | loss: -5.903234 | norm:  0.013579 | fidelity:  0.989472 | Sz:  0.000000 | S^2:  0.025377
iter: 425 | loss: -5.903265 | norm:  0.013452 | fidelity:  0.989482 | Sz: -0.000000 | S^2:  0.025346
iter: 426 | loss: -5.903245 | norm:  0.013326 | fidelity:  0.989484 | Sz:  0.000000 | S^2:  0.025316
iter: 427 | loss: -5.903248 | norm:  0.013203 | fidelity:  0.989489 | Sz:  0.000000 | S^2:  0.025287
iter: 428 | loss: -5.903273 | norm:  0.013083 | fidelity:  0.989498 | Sz: -0.000000 | S^2:  0.025259
iter: 429 | loss: -5.903294 | norm:  0.012964 | fidelity:  0.989506 | Sz:  0.000000 | S^2:  0.025231
iter: 430 | loss: -5.903327 | norm:  0.012847 | fidelity:  0.989516 | Sz:  0.000000 | S^2:  0.025204
iter: 431 | loss: -5.903310 | norm:  0.012732 | fidelity:  0.989517 | Sz:  0.000000 | S^2:  0.025177
iter: 432 | loss: -5.903329 | norm:  0.012618 | fidelity:  0.989525 | Sz: -0.000000 | S^2:  0.025151
iter: 433 | loss: -5.903339 | norm:  0.012506 | fidelity:  0.989530 | Sz:  0.000000 | S^2:  0.025125
iter: 434 | loss: -5.903351 | norm:  0.012396 | fidelity:  0.989536 | Sz:  0.000000 | S^2:  0.025100
iter: 435 | loss: -5.903371 | norm:  0.012287 | fidelity:  0.989544 | Sz: -0.000000 | S^2:  0.025075
iter: 436 | loss: -5.903382 | norm:  0.012179 | fidelity:  0.989549 | Sz:  0.000000 | S^2:  0.025051
iter: 437 | loss: -5.903408 | norm:  0.012073 | fidelity:  0.989558 | Sz: -0.000000 | S^2:  0.025028
iter: 438 | loss: -5.903391 | norm:  0.011967 | fidelity:  0.989559 | Sz:  0.000000 | S^2:  0.025004
iter: 439 | loss: -5.903428 | norm:  0.011863 | fidelity:  0.989568 | Sz: -0.000000 | S^2:  0.024982
iter: 440 | loss: -5.903434 | norm:  0.011760 | fidelity:  0.989573 | Sz:  0.000000 | S^2:  0.024959
iter: 441 | loss: -5.903427 | norm:  0.011658 | fidelity:  0.989576 | Sz:  0.000000 | S^2:  0.024937
iter: 442 | loss: -5.903452 | norm:  0.011557 | fidelity:  0.989583 | Sz:  0.000000 | S^2:  0.024915
iter: 443 | loss: -5.903474 | norm:  0.011457 | fidelity:  0.989591 | Sz: -0.000000 | S^2:  0.024894
iter: 444 | loss: -5.903472 | norm:  0.011357 | fidelity:  0.989594 | Sz:  0.000000 | S^2:  0.024873
iter: 445 | loss: -5.903468 | norm:  0.011259 | fidelity:  0.989597 | Sz:  0.000000 | S^2:  0.024852
iter: 446 | loss: -5.903485 | norm:  0.011162 | fidelity:  0.989603 | Sz: -0.000000 | S^2:  0.024832
iter: 447 | loss: -5.903472 | norm:  0.011065 | fidelity:  0.989604 | Sz: -0.000000 | S^2:  0.024812
iter: 448 | loss: -5.903502 | norm:  0.010969 | fidelity:  0.989612 | Sz:  0.000000 | S^2:  0.024792
iter: 449 | loss: -5.903519 | norm:  0.010873 | fidelity:  0.989618 | Sz: -0.000000 | S^2:  0.024773
iter: 450 | loss: -5.903528 | norm:  0.010779 | fidelity:  0.989623 | Sz:  0.000000 | S^2:  0.024754
iter: 451 | loss: -5.903514 | norm:  0.010685 | fidelity:  0.989624 | Sz:  0.000000 | S^2:  0.024735
iter: 452 | loss: -5.903526 | norm:  0.010592 | fidelity:  0.989629 | Sz:  0.000000 | S^2:  0.024716
iter: 453 | loss: -5.903530 | norm:  0.010500 | fidelity:  0.989633 | Sz:  0.000000 | S^2:  0.024698
iter: 454 | loss: -5.903561 | norm:  0.010409 | fidelity:  0.989641 | Sz:  0.000000 | S^2:  0.024680
iter: 455 | loss: -5.903585 | norm:  0.010318 | fidelity:  0.989648 | Sz:  0.000000 | S^2:  0.024662
iter: 456 | loss: -5.903579 | norm:  0.010228 | fidelity:  0.989650 | Sz:  0.000000 | S^2:  0.024644
iter: 457 | loss: -5.903589 | norm:  0.010138 | fidelity:  0.989655 | Sz:  0.000000 | S^2:  0.024627
iter: 458 | loss: -5.903568 | norm:  0.010049 | fidelity:  0.989654 | Sz: -0.000000 | S^2:  0.024610
iter: 459 | loss: -5.903602 | norm:  0.009961 | fidelity:  0.989663 | Sz: -0.000000 | S^2:  0.024593

learning rate =  0.0012114219337057018
Find operators
1j [6^ 1^ 12 11] + -1j [12^ 11^ 6 1]
1j [10^ 5^ 15 0] + -1j [15^ 0^ 10 5]
1j [8^ 1^ 11 2] + -1j [11^ 2^ 8 1]
1j [7^ 0^ 13 10] + -1j [13^ 10^ 7 0]
-1j [9^ 0^ 10 3] + 1j [10^ 3^ 9 0]
-1j [11^ 4^ 14 1] + 1j [14^ 1^ 11 4]
1j [4^ 3^ 14 9] + -1j [14^ 9^ 4 3]
1j [5^ 4^ 15 14] + -1j [15^ 14^ 5 4]
-1j [13^ 4^ 14 7] + 1j [14^ 7^ 13 4]
-1j [9^ 6^ 12 3] + 1j [12^ 3^ 9 6]
1j [7^ 6^ 13 12] + -1j [13^ 12^ 7 6]
1j [3^ 2^ 9 8] + -1j [9^ 8^ 3 2]
1j [8^ 7^ 13 2] + -1j [13^ 2^ 8 7]
1j [8^ 5^ 11 6] + -1j [11^ 6^ 8 5]
1j [5^ 0^ 13 8] + -1j [13^ 8^ 5 0]
1j [5^ 2^ 15 8] + -1j [15^ 8^ 5 2]
1j [8^ 5^ 12 1] + -1j [12^ 1^ 8 5]
1j [13^ 8^ 15 10] + -1j [15^ 10^ 13 8]
-1j [13^ 8^ 14 11] + 1j [14^ 11^ 13 8]
1j [5^ 0^ 7 2] + -1j [7^ 2^ 5 0]
1j [8^ 7^ 12 3] + -1j [12^ 3^ 8 7]
1j [10^ 7^ 14 3] + -1j [14^ 3^ 10 7]
1j [2^ 1^ 14 5] + -1j [14^ 5^ 2 1]
1j [12^ 5^ 15 6] + -1j [15^ 6^ 12 5]
-1j [9^ 4^ 13 0] + 1j [13^ 0^ 9 4]
1j [12^ 11^ 14 9] + -1j [14^ 9^ 12 11]
-1j [11^ 4^ 12 3] + 1j [12^ 3^ 11 4]
-1j [7^ 2^ 14 11] + 1j [14^ 11^ 7 2]
1j [8^ 5^ 13 0] + -1j [13^ 0^ 8 5]
with max gradients
[0.042512517, 0.04148206, 0.041014522, 0.04088404, 0.03997703, 0.03980212, 0.027311157, 0.025911184, 0.024467213, 0.0244385, 0.023358058, 0.021910174, 0.01822566, 0.016584635, 0.016459081, 0.016322935, 0.016091874, 0.015411559, 0.014978825, 0.014653593, 0.014410349, 0.0131085655, 0.0116543975, 0.011631418, 0.011389166, 0.011233459, 0.011120687, 0.010389975, 0.010113109]

iter: 460 | loss: -5.903584 | norm:  0.130847 | fidelity:  0.989663 | Sz:  0.000000 | S^2:  0.024577
iter: 461 | loss: -5.904107 | norm:  0.139042 | fidelity:  0.990027 | Sz:  0.000000 | S^2:  0.022661
iter: 462 | loss: -5.904872 | norm:  0.120701 | fidelity:  0.990203 | Sz:  0.000000 | S^2:  0.022263
iter: 463 | loss: -5.905528 | norm:  0.109378 | fidelity:  0.990313 | Sz: -0.000000 | S^2:  0.022070
iter: 464 | loss: -5.906143 | norm:  0.111109 | fidelity:  0.990452 | Sz: -0.000000 | S^2:  0.021635
iter: 465 | loss: -5.906770 | norm:  0.110705 | fidelity:  0.990642 | Sz: -0.000000 | S^2:  0.021013
iter: 466 | loss: -5.907411 | norm:  0.101271 | fidelity:  0.990860 | Sz: -0.000000 | S^2:  0.020297
iter: 467 | loss: -5.908016 | norm:  0.091441 | fidelity:  0.991085 | Sz:  0.000000 | S^2:  0.019565
iter: 468 | loss: -5.908513 | norm:  0.090597 | fidelity:  0.991292 | Sz: -0.000000 | S^2:  0.018865
iter: 469 | loss: -5.909018 | norm:  0.091765 | fidelity:  0.991488 | Sz:  0.000000 | S^2:  0.018206
iter: 470 | loss: -5.909543 | norm:  0.089040 | fidelity:  0.991673 | Sz: -0.000000 | S^2:  0.017580
iter: 471 | loss: -5.910034 | norm:  0.084512 | fidelity:  0.991835 | Sz:  0.000000 | S^2:  0.016987
iter: 472 | loss: -5.910501 | norm:  0.080221 | fidelity:  0.991976 | Sz:  0.000000 | S^2:  0.016432
iter: 473 | loss: -5.910965 | norm:  0.077287 | fidelity:  0.992112 | Sz: -0.000000 | S^2:  0.015909
iter: 474 | loss: -5.911408 | norm:  0.075544 | fidelity:  0.992247 | Sz: -0.000000 | S^2:  0.015407
iter: 475 | loss: -5.911832 | norm:  0.075176 | fidelity:  0.992382 | Sz:  0.000000 | S^2:  0.014918
iter: 476 | loss: -5.912228 | norm:  0.074496 | fidelity:  0.992513 | Sz:  0.000000 | S^2:  0.014437
iter: 477 | loss: -5.912648 | norm:  0.072129 | fidelity:  0.992647 | Sz:  0.000000 | S^2:  0.013961
iter: 478 | loss: -5.913066 | norm:  0.069201 | fidelity:  0.992777 | Sz: -0.000000 | S^2:  0.013498
iter: 479 | loss: -5.913434 | norm:  0.067373 | fidelity:  0.992893 | Sz: -0.000000 | S^2:  0.013063
iter: 480 | loss: -5.913796 | norm:  0.066653 | fidelity:  0.992998 | Sz:  0.000000 | S^2:  0.012675
iter: 481 | loss: -5.914157 | norm:  0.065899 | fidelity:  0.993090 | Sz: -0.000000 | S^2:  0.012350
iter: 482 | loss: -5.914545 | norm:  0.064428 | fidelity:  0.993175 | Sz:  0.000000 | S^2:  0.012091
iter: 483 | loss: -5.914905 | norm:  0.062813 | fidelity:  0.993248 | Sz: -0.000000 | S^2:  0.011885
iter: 484 | loss: -5.915236 | norm:  0.061597 | fidelity:  0.993313 | Sz:  0.000000 | S^2:  0.011708
iter: 485 | loss: -5.915578 | norm:  0.060296 | fidelity:  0.993381 | Sz: -0.000000 | S^2:  0.011529
iter: 486 | loss: -5.915866 | norm:  0.058789 | fidelity:  0.993444 | Sz:  0.000000 | S^2:  0.011323
iter: 487 | loss: -5.916175 | norm:  0.057530 | fidelity:  0.993515 | Sz:  0.000000 | S^2:  0.011081
iter: 488 | loss: -5.916490 | norm:  0.056617 | fidelity:  0.993589 | Sz:  0.000000 | S^2:  0.010811
iter: 489 | loss: -5.916774 | norm:  0.055881 | fidelity:  0.993659 | Sz:  0.000000 | S^2:  0.010533
iter: 490 | loss: -5.917051 | norm:  0.055272 | fidelity:  0.993725 | Sz: -0.000000 | S^2:  0.010269
iter: 491 | loss: -5.917342 | norm:  0.054762 | fidelity:  0.993789 | Sz:  0.000000 | S^2:  0.010041
iter: 492 | loss: -5.917594 | norm:  0.054046 | fidelity:  0.993841 | Sz: -0.000000 | S^2:  0.009859
iter: 493 | loss: -5.917852 | norm:  0.052806 | fidelity:  0.993891 | Sz:  0.000000 | S^2:  0.009719
iter: 494 | loss: -5.918092 | norm:  0.051271 | fidelity:  0.993935 | Sz: -0.000000 | S^2:  0.009607
iter: 495 | loss: -5.918342 | norm:  0.050045 | fidelity:  0.993980 | Sz: -0.000000 | S^2:  0.009503
iter: 496 | loss: -5.918560 | norm:  0.049291 | fidelity:  0.994022 | Sz: -0.000000 | S^2:  0.009387
iter: 497 | loss: -5.918790 | norm:  0.048580 | fidelity:  0.994069 | Sz: -0.000000 | S^2:  0.009250
iter: 498 | loss: -5.918947 | norm:  0.047756 | fidelity:  0.994107 | Sz: -0.000000 | S^2:  0.009088
iter: 499 | loss: -5.919154 | norm:  0.047056 | fidelity:  0.994157 | Sz:  0.000000 | S^2:  0.008912
iter: 500 | loss: -5.919367 | norm:  0.046523 | fidelity:  0.994209 | Sz: -0.000000 | S^2:  0.008731
iter: 501 | loss: -5.919546 | norm:  0.045949 | fidelity:  0.994256 | Sz: -0.000000 | S^2:  0.008556
iter: 502 | loss: -5.919760 | norm:  0.045147 | fidelity:  0.994309 | Sz: -0.000000 | S^2:  0.008392
iter: 503 | loss: -5.919909 | norm:  0.044218 | fidelity:  0.994350 | Sz:  0.000000 | S^2:  0.008243
iter: 504 | loss: -5.920080 | norm:  0.043275 | fidelity:  0.994393 | Sz:  0.000000 | S^2:  0.008105
iter: 505 | loss: -5.920267 | norm:  0.042353 | fidelity:  0.994437 | Sz:  0.000000 | S^2:  0.007976
iter: 506 | loss: -5.920375 | norm:  0.041564 | fidelity:  0.994469 | Sz: -0.000000 | S^2:  0.007849
iter: 507 | loss: -5.920553 | norm:  0.040886 | fidelity:  0.994514 | Sz: -0.000000 | S^2:  0.007720
iter: 508 | loss: -5.920716 | norm:  0.040171 | fidelity:  0.994559 | Sz: -0.000000 | S^2:  0.007584
iter: 509 | loss: -5.920838 | norm:  0.039423 | fidelity:  0.994599 | Sz: -0.000000 | S^2:  0.007440
iter: 510 | loss: -5.920986 | norm:  0.038757 | fidelity:  0.994643 | Sz:  0.000000 | S^2:  0.007290
iter: 511 | loss: -5.921121 | norm:  0.038174 | fidelity:  0.994684 | Sz: -0.000000 | S^2:  0.007138
iter: 512 | loss: -5.921265 | norm:  0.037542 | fidelity:  0.994725 | Sz: -0.000000 | S^2:  0.006992
iter: 513 | loss: -5.921374 | norm:  0.036837 | fidelity:  0.994759 | Sz:  0.000000 | S^2:  0.006859
iter: 514 | loss: -5.921519 | norm:  0.036126 | fidelity:  0.994798 | Sz: -0.000000 | S^2:  0.006742
iter: 515 | loss: -5.921612 | norm:  0.035402 | fidelity:  0.994827 | Sz: -0.000000 | S^2:  0.006639
iter: 516 | loss: -5.921723 | norm:  0.034681 | fidelity:  0.994860 | Sz: -0.000000 | S^2:  0.006542
iter: 517 | loss: -5.921833 | norm:  0.034026 | fidelity:  0.994893 | Sz: -0.000000 | S^2:  0.006446
iter: 518 | loss: -5.921913 | norm:  0.033486 | fidelity:  0.994919 | Sz:  0.000000 | S^2:  0.006346
iter: 519 | loss: -5.922022 | norm:  0.033000 | fidelity:  0.994949 | Sz:  0.000000 | S^2:  0.006244
iter: 520 | loss: -5.922140 | norm:  0.032573 | fidelity:  0.994978 | Sz: -0.000000 | S^2:  0.006145
iter: 521 | loss: -5.922220 | norm:  0.032189 | fidelity:  0.995000 | Sz:  0.000000 | S^2:  0.006052
iter: 522 | loss: -5.922320 | norm:  0.031771 | fidelity:  0.995025 | Sz:  0.000000 | S^2:  0.005968
iter: 523 | loss: -5.922388 | norm:  0.031252 | fidelity:  0.995045 | Sz:  0.000000 | S^2:  0.005891
iter: 524 | loss: -5.922505 | norm:  0.030739 | fidelity:  0.995073 | Sz: -0.000000 | S^2:  0.005819
iter: 525 | loss: -5.922556 | norm:  0.030218 | fidelity:  0.995089 | Sz:  0.000000 | S^2:  0.005749
iter: 526 | loss: -5.922625 | norm:  0.029838 | fidelity:  0.995107 | Sz: -0.000000 | S^2:  0.005679
iter: 527 | loss: -5.922707 | norm:  0.029429 | fidelity:  0.995126 | Sz:  0.000000 | S^2:  0.005610
iter: 528 | loss: -5.922780 | norm:  0.029269 | fidelity:  0.995144 | Sz: -0.000000 | S^2:  0.005545
iter: 529 | loss: -5.922871 | norm:  0.028987 | fidelity:  0.995163 | Sz:  0.000000 | S^2:  0.005484
iter: 530 | loss: -5.922945 | norm:  0.028833 | fidelity:  0.995181 | Sz:  0.000000 | S^2:  0.005424
iter: 531 | loss: -5.923038 | norm:  0.028282 | fidelity:  0.995201 | Sz:  0.000000 | S^2:  0.005367
iter: 532 | loss: -5.923054 | norm:  0.027881 | fidelity:  0.995209 | Sz:  0.000000 | S^2:  0.005308
iter: 533 | loss: -5.923186 | norm:  0.027676 | fidelity:  0.995236 | Sz:  0.000000 | S^2:  0.005249
iter: 534 | loss: -5.923230 | norm:  0.027358 | fidelity:  0.995247 | Sz:  0.000000 | S^2:  0.005191
iter: 535 | loss: -5.923296 | norm:  0.027005 | fidelity:  0.995264 | Sz: -0.000000 | S^2:  0.005132
iter: 536 | loss: -5.923335 | norm:  0.026601 | fidelity:  0.995276 | Sz:  0.000000 | S^2:  0.005075
iter: 537 | loss: -5.923410 | norm:  0.026363 | fidelity:  0.995293 | Sz: -0.000000 | S^2:  0.005019
iter: 538 | loss: -5.923479 | norm:  0.026172 | fidelity:  0.995310 | Sz: -0.000000 | S^2:  0.004964
iter: 539 | loss: -5.923551 | norm:  0.025763 | fidelity:  0.995326 | Sz: -0.000000 | S^2:  0.004910
iter: 540 | loss: -5.923599 | norm:  0.025524 | fidelity:  0.995339 | Sz:  0.000000 | S^2:  0.004857
iter: 541 | loss: -5.923636 | norm:  0.025384 | fidelity:  0.995350 | Sz: -0.000000 | S^2:  0.004806
iter: 542 | loss: -5.923695 | norm:  0.024974 | fidelity:  0.995364 | Sz: -0.000000 | S^2:  0.004757
iter: 543 | loss: -5.923756 | norm:  0.024663 | fidelity:  0.995379 | Sz: -0.000000 | S^2:  0.004708
iter: 544 | loss: -5.923790 | norm:  0.024469 | fidelity:  0.995390 | Sz: -0.000000 | S^2:  0.004659
iter: 545 | loss: -5.923848 | norm:  0.024132 | fidelity:  0.995404 | Sz: -0.000000 | S^2:  0.004610
iter: 546 | loss: -5.923907 | norm:  0.023870 | fidelity:  0.995418 | Sz: -0.000000 | S^2:  0.004560
iter: 547 | loss: -5.923941 | norm:  0.023677 | fidelity:  0.995427 | Sz:  0.000000 | S^2:  0.004512
iter: 548 | loss: -5.923998 | norm:  0.023423 | fidelity:  0.995440 | Sz:  0.000000 | S^2:  0.004467
iter: 549 | loss: -5.924049 | norm:  0.023203 | fidelity:  0.995453 | Sz:  0.000000 | S^2:  0.004424
iter: 550 | loss: -5.924129 | norm:  0.022938 | fidelity:  0.995470 | Sz: -0.000000 | S^2:  0.004384
iter: 551 | loss: -5.924168 | norm:  0.022705 | fidelity:  0.995480 | Sz: -0.000000 | S^2:  0.004343
iter: 552 | loss: -5.924211 | norm:  0.022522 | fidelity:  0.995490 | Sz:  0.000000 | S^2:  0.004302
iter: 553 | loss: -5.924236 | norm:  0.022253 | fidelity:  0.995497 | Sz:  0.000000 | S^2:  0.004262
iter: 554 | loss: -5.924316 | norm:  0.022044 | fidelity:  0.995513 | Sz: -0.000000 | S^2:  0.004223
iter: 555 | loss: -5.924319 | norm:  0.021907 | fidelity:  0.995516 | Sz:  0.000000 | S^2:  0.004185
iter: 556 | loss: -5.924396 | norm:  0.021648 | fidelity:  0.995531 | Sz: -0.000000 | S^2:  0.004150
iter: 557 | loss: -5.924428 | norm:  0.021500 | fidelity:  0.995539 | Sz:  0.000000 | S^2:  0.004115
iter: 558 | loss: -5.924482 | norm:  0.021335 | fidelity:  0.995550 | Sz:  0.000000 | S^2:  0.004080
iter: 559 | loss: -5.924511 | norm:  0.021254 | fidelity:  0.995557 | Sz:  0.000000 | S^2:  0.004045
iter: 560 | loss: -5.924546 | norm:  0.021174 | fidelity:  0.995564 | Sz: -0.000000 | S^2:  0.004012
iter: 561 | loss: -5.924591 | norm:  0.021361 | fidelity:  0.995575 | Sz: -0.000000 | S^2:  0.003978
iter: 562 | loss: -5.924604 | norm:  0.021247 | fidelity:  0.995577 | Sz: -0.000000 | S^2:  0.003948
iter: 563 | loss: -5.924659 | norm:  0.020901 | fidelity:  0.995590 | Sz: -0.000000 | S^2:  0.003915
iter: 564 | loss: -5.924708 | norm:  0.020203 | fidelity:  0.995599 | Sz:  0.000000 | S^2:  0.003885
iter: 565 | loss: -5.924741 | norm:  0.020208 | fidelity:  0.995606 | Sz: -0.000000 | S^2:  0.003855
iter: 566 | loss: -5.924769 | norm:  0.020405 | fidelity:  0.995613 | Sz: -0.000000 | S^2:  0.003824
iter: 567 | loss: -5.924828 | norm:  0.019843 | fidelity:  0.995623 | Sz: -0.000000 | S^2:  0.003796
iter: 568 | loss: -5.924852 | norm:  0.019538 | fidelity:  0.995629 | Sz: -0.000000 | S^2:  0.003767
iter: 569 | loss: -5.924888 | norm:  0.019662 | fidelity:  0.995637 | Sz: -0.000000 | S^2:  0.003738
iter: 570 | loss: -5.924930 | norm:  0.019374 | fidelity:  0.995645 | Sz:  0.000000 | S^2:  0.003710
iter: 571 | loss: -5.924947 | norm:  0.019026 | fidelity:  0.995650 | Sz: -0.000000 | S^2:  0.003681
iter: 572 | loss: -5.924984 | norm:  0.019019 | fidelity:  0.995658 | Sz:  0.000000 | S^2:  0.003654
iter: 573 | loss: -5.925071 | norm:  0.018885 | fidelity:  0.995673 | Sz: -0.000000 | S^2:  0.003628
iter: 574 | loss: -5.925098 | norm:  0.018550 | fidelity:  0.995680 | Sz:  0.000000 | S^2:  0.003602
iter: 575 | loss: -5.925091 | norm:  0.018442 | fidelity:  0.995680 | Sz: -0.000000 | S^2:  0.003576
iter: 576 | loss: -5.925120 | norm:  0.018360 | fidelity:  0.995686 | Sz: -0.000000 | S^2:  0.003550
iter: 577 | loss: -5.925155 | norm:  0.018089 | fidelity:  0.995693 | Sz:  0.000000 | S^2:  0.003524
iter: 578 | loss: -5.925183 | norm:  0.017925 | fidelity:  0.995699 | Sz:  0.000000 | S^2:  0.003499
iter: 579 | loss: -5.925245 | norm:  0.017826 | fidelity:  0.995711 | Sz: -0.000000 | S^2:  0.003475
iter: 580 | loss: -5.925229 | norm:  0.017641 | fidelity:  0.995709 | Sz: -0.000000 | S^2:  0.003451
iter: 581 | loss: -5.925308 | norm:  0.017445 | fidelity:  0.995724 | Sz: -0.000000 | S^2:  0.003428
iter: 582 | loss: -5.925321 | norm:  0.017336 | fidelity:  0.995727 | Sz: -0.000000 | S^2:  0.003405
iter: 583 | loss: -5.925342 | norm:  0.017218 | fidelity:  0.995732 | Sz: -0.000000 | S^2:  0.003382
iter: 584 | loss: -5.925405 | norm:  0.016984 | fidelity:  0.995743 | Sz:  0.000000 | S^2:  0.003360
iter: 585 | loss: -5.925399 | norm:  0.016862 | fidelity:  0.995743 | Sz: -0.000000 | S^2:  0.003338
iter: 586 | loss: -5.925438 | norm:  0.016765 | fidelity:  0.995751 | Sz:  0.000000 | S^2:  0.003317
iter: 587 | loss: -5.925479 | norm:  0.016555 | fidelity:  0.995759 | Sz: -0.000000 | S^2:  0.003296
iter: 588 | loss: -5.925526 | norm:  0.016421 | fidelity:  0.995767 | Sz: -0.000000 | S^2:  0.003275
iter: 589 | loss: -5.925517 | norm:  0.016326 | fidelity:  0.995767 | Sz: -0.000000 | S^2:  0.003255
iter: 590 | loss: -5.925538 | norm:  0.016159 | fidelity:  0.995771 | Sz:  0.000000 | S^2:  0.003235
iter: 591 | loss: -5.925587 | norm:  0.015989 | fidelity:  0.995780 | Sz:  0.000000 | S^2:  0.003215
iter: 592 | loss: -5.925591 | norm:  0.015895 | fidelity:  0.995782 | Sz:  0.000000 | S^2:  0.003195
iter: 593 | loss: -5.925615 | norm:  0.015747 | fidelity:  0.995787 | Sz: -0.000000 | S^2:  0.003176
iter: 594 | loss: -5.925665 | norm:  0.015592 | fidelity:  0.995796 | Sz: -0.000000 | S^2:  0.003157
iter: 595 | loss: -5.925650 | norm:  0.015477 | fidelity:  0.995794 | Sz:  0.000000 | S^2:  0.003139
iter: 596 | loss: -5.925697 | norm:  0.015340 | fidelity:  0.995803 | Sz: -0.000000 | S^2:  0.003121
iter: 597 | loss: -5.925730 | norm:  0.015218 | fidelity:  0.995809 | Sz:  0.000000 | S^2:  0.003103
iter: 598 | loss: -5.925735 | norm:  0.015071 | fidelity:  0.995811 | Sz:  0.000000 | S^2:  0.003085
iter: 599 | loss: -5.925779 | norm:  0.014951 | fidelity:  0.995819 | Sz:  0.000000 | S^2:  0.003067
iter: 600 | loss: -5.925764 | norm:  0.014829 | fidelity:  0.995817 | Sz: -0.000000 | S^2:  0.003050
iter: 601 | loss: -5.925812 | norm:  0.014699 | fidelity:  0.995826 | Sz:  0.000000 | S^2:  0.003033
iter: 602 | loss: -5.925861 | norm:  0.014555 | fidelity:  0.995835 | Sz:  0.000000 | S^2:  0.003016
iter: 603 | loss: -5.925867 | norm:  0.014453 | fidelity:  0.995837 | Sz: -0.000000 | S^2:  0.003000
iter: 604 | loss: -5.925896 | norm:  0.014322 | fidelity:  0.995842 | Sz: -0.000000 | S^2:  0.002983
iter: 605 | loss: -5.925906 | norm:  0.014199 | fidelity:  0.995844 | Sz: -0.000000 | S^2:  0.002967
iter: 606 | loss: -5.925934 | norm:  0.014075 | fidelity:  0.995850 | Sz:  0.000000 | S^2:  0.002952
iter: 607 | loss: -5.925969 | norm:  0.013961 | fidelity:  0.995856 | Sz:  0.000000 | S^2:  0.002936
iter: 608 | loss: -5.925983 | norm:  0.013840 | fidelity:  0.995859 | Sz: -0.000000 | S^2:  0.002921
iter: 609 | loss: -5.925996 | norm:  0.013730 | fidelity:  0.995862 | Sz: -0.000000 | S^2:  0.002906
iter: 610 | loss: -5.926042 | norm:  0.013598 | fidelity:  0.995871 | Sz: -0.000000 | S^2:  0.002891
iter: 611 | loss: -5.926056 | norm:  0.013506 | fidelity:  0.995873 | Sz:  0.000000 | S^2:  0.002876
iter: 612 | loss: -5.926070 | norm:  0.013381 | fidelity:  0.995876 | Sz:  0.000000 | S^2:  0.002862
iter: 613 | loss: -5.926086 | norm:  0.013295 | fidelity:  0.995880 | Sz: -0.000000 | S^2:  0.002848
iter: 614 | loss: -5.926099 | norm:  0.013169 | fidelity:  0.995882 | Sz:  0.000000 | S^2:  0.002834
iter: 615 | loss: -5.926159 | norm:  0.013131 | fidelity:  0.995893 | Sz: -0.000000 | S^2:  0.002820
iter: 616 | loss: -5.926135 | norm:  0.013028 | fidelity:  0.995889 | Sz:  0.000000 | S^2:  0.002807
iter: 617 | loss: -5.926187 | norm:  0.013115 | fidelity:  0.995899 | Sz: -0.000000 | S^2:  0.002794
iter: 618 | loss: -5.926198 | norm:  0.013099 | fidelity:  0.995901 | Sz:  0.000000 | S^2:  0.002781
iter: 619 | loss: -5.926191 | norm:  0.013386 | fidelity:  0.995901 | Sz: -0.000000 | S^2:  0.002768
iter: 620 | loss: -5.926188 | norm:  0.013326 | fidelity:  0.995900 | Sz:  0.000000 | S^2:  0.002756
iter: 621 | loss: -5.926240 | norm:  0.013204 | fidelity:  0.995910 | Sz:  0.000000 | S^2:  0.002743
iter: 622 | loss: -5.926269 | norm:  0.012554 | fidelity:  0.995915 | Sz:  0.000000 | S^2:  0.002731
iter: 623 | loss: -5.926271 | norm:  0.012212 | fidelity:  0.995916 | Sz: -0.000000 | S^2:  0.002719
iter: 624 | loss: -5.926247 | norm:  0.012326 | fidelity:  0.995913 | Sz: -0.000000 | S^2:  0.002706
iter: 625 | loss: -5.926285 | norm:  0.012414 | fidelity:  0.995919 | Sz: -0.000000 | S^2:  0.002695
iter: 626 | loss: -5.926310 | norm:  0.012365 | fidelity:  0.995924 | Sz: -0.000000 | S^2:  0.002683
iter: 627 | loss: -5.926356 | norm:  0.011946 | fidelity:  0.995932 | Sz: -0.000000 | S^2:  0.002672
iter: 628 | loss: -5.926362 | norm:  0.011737 | fidelity:  0.995933 | Sz: -0.000000 | S^2:  0.002661
iter: 629 | loss: -5.926372 | norm:  0.011837 | fidelity:  0.995936 | Sz: -0.000000 | S^2:  0.002650
iter: 630 | loss: -5.926426 | norm:  0.011789 | fidelity:  0.995945 | Sz: -0.000000 | S^2:  0.002639
iter: 631 | loss: -5.926421 | norm:  0.011642 | fidelity:  0.995944 | Sz: -0.000000 | S^2:  0.002628
iter: 632 | loss: -5.926430 | norm:  0.011421 | fidelity:  0.995946 | Sz:  0.000000 | S^2:  0.002618
iter: 633 | loss: -5.926463 | norm:  0.011317 | fidelity:  0.995952 | Sz:  0.000000 | S^2:  0.002608
iter: 634 | loss: -5.926475 | norm:  0.011348 | fidelity:  0.995955 | Sz:  0.000000 | S^2:  0.002597
iter: 635 | loss: -5.926482 | norm:  0.011224 | fidelity:  0.995956 | Sz:  0.000000 | S^2:  0.002587
iter: 636 | loss: -5.926499 | norm:  0.011071 | fidelity:  0.995959 | Sz:  0.000000 | S^2:  0.002578
iter: 637 | loss: -5.926544 | norm:  0.010981 | fidelity:  0.995967 | Sz: -0.000000 | S^2:  0.002568
iter: 638 | loss: -5.926526 | norm:  0.010900 | fidelity:  0.995964 | Sz:  0.000000 | S^2:  0.002559
iter: 639 | loss: -5.926547 | norm:  0.010862 | fidelity:  0.995968 | Sz: -0.000000 | S^2:  0.002549
iter: 640 | loss: -5.926534 | norm:  0.010742 | fidelity:  0.995966 | Sz: -0.000000 | S^2:  0.002540
iter: 641 | loss: -5.926574 | norm:  0.010610 | fidelity:  0.995973 | Sz:  0.000000 | S^2:  0.002531
iter: 642 | loss: -5.926563 | norm:  0.010562 | fidelity:  0.995972 | Sz: -0.000000 | S^2:  0.002522
iter: 643 | loss: -5.926602 | norm:  0.010484 | fidelity:  0.995978 | Sz: -0.000000 | S^2:  0.002513
iter: 644 | loss: -5.926627 | norm:  0.010421 | fidelity:  0.995983 | Sz: -0.000000 | S^2:  0.002505
iter: 645 | loss: -5.926638 | norm:  0.010318 | fidelity:  0.995985 | Sz:  0.000000 | S^2:  0.002496
iter: 646 | loss: -5.926650 | norm:  0.010207 | fidelity:  0.995987 | Sz: -0.000000 | S^2:  0.002488
iter: 647 | loss: -5.926646 | norm:  0.010165 | fidelity:  0.995986 | Sz:  0.000000 | S^2:  0.002479
iter: 648 | loss: -5.926662 | norm:  0.010091 | fidelity:  0.995989 | Sz:  0.000000 | S^2:  0.002471
iter: 649 | loss: -5.926672 | norm:  0.010027 | fidelity:  0.995991 | Sz: -0.000000 | S^2:  0.002463
iter: 650 | loss: -5.926714 | norm:  0.009927 | fidelity:  0.995999 | Sz:  0.000000 | S^2:  0.002456

learning rate =  0.0006772044289953743
Find operators
-1j [11^ 6^ 15 2] + 1j [15^ 2^ 11 6]
1j [8^ 7^ 15 0] + -1j [15^ 0^ 8 7]
-1j [2^ 1^ 11 8] + 1j [11^ 8^ 2 1]
-1j [7^ 6^ 9 0] + 1j [9^ 0^ 7 6]
1j [10^ 7^ 12 1] + -1j [12^ 1^ 10 7]
1j [11^ 2^ 13 12] + -1j [13^ 12^ 11 2]
1j [12^ 9^ 14 11] + -1j [14^ 11^ 12 9]
1j [5^ 2^ 13 10] + -1j [13^ 10^ 5 2]
-1j [4^ 3^ 13 10] + 1j [13^ 10^ 4 3]
1j [5^ 0^ 15 10] + -1j [15^ 10^ 5 0]
1j [12^ 1^ 15 2] + -1j [15^ 2^ 12 1]
1j [10^ 7^ 15 2] + -1j [15^ 2^ 10 7]
1j [10^ 7^ 13 0] + -1j [13^ 0^ 10 7]
-1j [13^ 0^ 14 3] + 1j [14^ 3^ 13 0]
-1j [13^ 10^ 14 9] + 1j [14^ 9^ 13 10]
1j [12^ 3^ 15 0] + -1j [15^ 0^ 12 3]
1j [10^ 5^ 13 2] + -1j [13^ 2^ 10 5]
-1j [3^ 0^ 12 7] + 1j [12^ 7^ 3 0]
-1j [5^ 4^ 9 0] + 1j [9^ 0^ 5 4]
1j [8^ 7^ 14 1] + -1j [14^ 1^ 8 7]
-1j [10^ 3^ 13 12] + 1j [13^ 12^ 10 3]
1j [12^ 3^ 14 1] + -1j [14^ 1^ 12 3]
-1j [11^ 8^ 14 5] + 1j [14^ 5^ 11 8]
-1j [3^ 0^ 10 9] + 1j [10^ 9^ 3 0]
1j [8^ 5^ 10 7] + -1j [10^ 7^ 8 5]
1j [4^ 1^ 7 2] + -1j [7^ 2^ 4 1]
1j [10^ 9^ 13 6] + -1j [13^ 6^ 10 9]
with max gradients
[0.02161752, 0.021163572, 0.015537489, 0.0153652, 0.015315935, 0.015116433, 0.014728378, 0.014479503, 0.013778128, 0.0136692375, 0.013167689, 0.012834605, 0.012424505, 0.012153629, 0.012030229, 0.011796155, 0.011717461, 0.011704928, 0.0115517825, 0.01151518, 0.011448792, 0.011396836, 0.011225721, 0.0111350585, 0.010398032, 0.010314883, 0.010196764]

iter: 651 | loss: -5.926720 | norm:  0.071061 | fidelity:  0.996000 | Sz: -0.000000 | S^2:  0.002448
iter: 652 | loss: -5.926821 | norm:  0.106323 | fidelity:  0.996010 | Sz:  0.000000 | S^2:  0.002478
iter: 653 | loss: -5.927200 | norm:  0.077600 | fidelity:  0.996030 | Sz:  0.000000 | S^2:  0.002473
iter: 654 | loss: -5.927276 | norm:  0.082224 | fidelity:  0.996054 | Sz:  0.000000 | S^2:  0.002379
iter: 655 | loss: -5.927558 | norm:  0.082222 | fidelity:  0.996125 | Sz:  0.000000 | S^2:  0.002268
iter: 656 | loss: -5.927816 | norm:  0.072457 | fidelity:  0.996185 | Sz:  0.000000 | S^2:  0.002210
iter: 657 | loss: -5.927980 | norm:  0.064950 | fidelity:  0.996217 | Sz:  0.000000 | S^2:  0.002184
iter: 658 | loss: -5.928139 | norm:  0.062167 | fidelity:  0.996243 | Sz: -0.000000 | S^2:  0.002176
iter: 659 | loss: -5.928310 | norm:  0.061185 | fidelity:  0.996265 | Sz: -0.000000 | S^2:  0.002161
iter: 660 | loss: -5.928479 | norm:  0.060605 | fidelity:  0.996285 | Sz:  0.000000 | S^2:  0.002127
iter: 661 | loss: -5.928649 | norm:  0.058376 | fidelity:  0.996309 | Sz: -0.000000 | S^2:  0.002080
iter: 662 | loss: -5.928807 | norm:  0.054128 | fidelity:  0.996335 | Sz:  0.000000 | S^2:  0.002034
iter: 663 | loss: -5.928975 | norm:  0.050130 | fidelity:  0.996368 | Sz: -0.000000 | S^2:  0.001997
iter: 664 | loss: -5.929087 | norm:  0.047982 | fidelity:  0.996395 | Sz:  0.000000 | S^2:  0.001972
iter: 665 | loss: -5.929282 | norm:  0.046870 | fidelity:  0.996435 | Sz: -0.000000 | S^2:  0.001956
iter: 666 | loss: -5.929372 | norm:  0.046049 | fidelity:  0.996456 | Sz:  0.000000 | S^2:  0.001945
iter: 667 | loss: -5.929487 | norm:  0.045563 | fidelity:  0.996481 | Sz: -0.000000 | S^2:  0.001939
iter: 668 | loss: -5.929619 | norm:  0.044339 | fidelity:  0.996506 | Sz: -0.000000 | S^2:  0.001934
iter: 669 | loss: -5.929753 | norm:  0.041631 | fidelity:  0.996530 | Sz:  0.000000 | S^2:  0.001929
iter: 670 | loss: -5.929837 | norm:  0.038962 | fidelity:  0.996543 | Sz:  0.000000 | S^2:  0.001924
iter: 671 | loss: -5.929946 | norm:  0.038117 | fidelity:  0.996559 | Sz:  0.000000 | S^2:  0.001918
iter: 672 | loss: -5.930036 | norm:  0.038371 | fidelity:  0.996572 | Sz: -0.000000 | S^2:  0.001910
iter: 673 | loss: -5.930155 | norm:  0.037865 | fidelity:  0.996589 | Sz: -0.000000 | S^2:  0.001900
iter: 674 | loss: -5.930227 | norm:  0.036012 | fidelity:  0.996600 | Sz: -0.000000 | S^2:  0.001890
iter: 675 | loss: -5.930310 | norm:  0.033825 | fidelity:  0.996615 | Sz:  0.000000 | S^2:  0.001883
iter: 676 | loss: -5.930430 | norm:  0.032750 | fidelity:  0.996637 | Sz:  0.000000 | S^2:  0.001879
iter: 677 | loss: -5.930529 | norm:  0.032945 | fidelity:  0.996658 | Sz: -0.000000 | S^2:  0.001878
iter: 678 | loss: -5.930595 | norm:  0.033009 | fidelity:  0.996672 | Sz:  0.000000 | S^2:  0.001879
iter: 679 | loss: -5.930658 | norm:  0.031841 | fidelity:  0.996685 | Sz: -0.000000 | S^2:  0.001880
iter: 680 | loss: -5.930736 | norm:  0.029943 | fidelity:  0.996700 | Sz:  0.000000 | S^2:  0.001881
iter: 681 | loss: -5.930829 | norm:  0.028645 | fidelity:  0.996715 | Sz: -0.000000 | S^2:  0.001881
iter: 682 | loss: -5.930902 | norm:  0.028315 | fidelity:  0.996727 | Sz:  0.000000 | S^2:  0.001881
iter: 683 | loss: -5.930971 | norm:  0.028095 | fidelity:  0.996737 | Sz:  0.000000 | S^2:  0.001881
iter: 684 | loss: -5.931040 | norm:  0.027319 | fidelity:  0.996747 | Sz:  0.000000 | S^2:  0.001882
iter: 685 | loss: -5.931144 | norm:  0.026246 | fidelity:  0.996763 | Sz: -0.000000 | S^2:  0.001882
iter: 686 | loss: -5.931172 | norm:  0.025578 | fidelity:  0.996768 | Sz:  0.000000 | S^2:  0.001883
iter: 687 | loss: -5.931233 | norm:  0.025388 | fidelity:  0.996778 | Sz: -0.000000 | S^2:  0.001884
iter: 688 | loss: -5.931273 | norm:  0.025068 | fidelity:  0.996786 | Sz: -0.000000 | S^2:  0.001886
iter: 689 | loss: -5.931378 | norm:  0.024407 | fidelity:  0.996806 | Sz: -0.000000 | S^2:  0.001889
iter: 690 | loss: -5.931421 | norm:  0.023681 | fidelity:  0.996815 | Sz:  0.000000 | S^2:  0.001893
iter: 691 | loss: -5.931441 | norm:  0.022985 | fidelity:  0.996820 | Sz: -0.000000 | S^2:  0.001896
iter: 692 | loss: -5.931511 | norm:  0.022426 | fidelity:  0.996832 | Sz:  0.000000 | S^2:  0.001898
iter: 693 | loss: -5.931525 | norm:  0.022160 | fidelity:  0.996835 | Sz: -0.000000 | S^2:  0.001899
iter: 694 | loss: -5.931595 | norm:  0.021913 | fidelity:  0.996847 | Sz:  0.000000 | S^2:  0.001900
iter: 695 | loss: -5.931633 | norm:  0.021437 | fidelity:  0.996854 | Sz: -0.000000 | S^2:  0.001900
iter: 696 | loss: -5.931688 | norm:  0.020928 | fidelity:  0.996863 | Sz:  0.000000 | S^2:  0.001901
iter: 697 | loss: -5.931754 | norm:  0.020528 | fidelity:  0.996874 | Sz: -0.000000 | S^2:  0.001903
iter: 698 | loss: -5.931767 | norm:  0.020222 | fidelity:  0.996877 | Sz: -0.000000 | S^2:  0.001905
iter: 699 | loss: -5.931822 | norm:  0.019947 | fidelity:  0.996887 | Sz:  0.000000 | S^2:  0.001908
iter: 700 | loss: -5.931858 | norm:  0.019525 | fidelity:  0.996894 | Sz:  0.000000 | S^2:  0.001911
iter: 701 | loss: -5.931873 | norm:  0.018992 | fidelity:  0.996897 | Sz: -0.000000 | S^2:  0.001912
iter: 702 | loss: -5.931896 | norm:  0.018576 | fidelity:  0.996903 | Sz:  0.000000 | S^2:  0.001913
iter: 703 | loss: -5.931957 | norm:  0.018280 | fidelity:  0.996914 | Sz: -0.000000 | S^2:  0.001913
iter: 704 | loss: -5.932022 | norm:  0.018002 | fidelity:  0.996926 | Sz: -0.000000 | S^2:  0.001914
iter: 705 | loss: -5.932043 | norm:  0.017685 | fidelity:  0.996930 | Sz:  0.000000 | S^2:  0.001915
iter: 706 | loss: -5.932085 | norm:  0.017296 | fidelity:  0.996937 | Sz: -0.000000 | S^2:  0.001916
iter: 707 | loss: -5.932127 | norm:  0.016918 | fidelity:  0.996945 | Sz: -0.000000 | S^2:  0.001917
iter: 708 | loss: -5.932152 | norm:  0.016612 | fidelity:  0.996949 | Sz: -0.000000 | S^2:  0.001918
iter: 709 | loss: -5.932192 | norm:  0.016326 | fidelity:  0.996956 | Sz: -0.000000 | S^2:  0.001919
iter: 710 | loss: -5.932210 | norm:  0.016025 | fidelity:  0.996959 | Sz: -0.000000 | S^2:  0.001920
iter: 711 | loss: -5.932259 | norm:  0.015693 | fidelity:  0.996968 | Sz: -0.000000 | S^2:  0.001921
iter: 712 | loss: -5.932269 | norm:  0.015379 | fidelity:  0.996971 | Sz:  0.000000 | S^2:  0.001923
iter: 713 | loss: -5.932296 | norm:  0.015137 | fidelity:  0.996976 | Sz: -0.000000 | S^2:  0.001924
iter: 714 | loss: -5.932312 | norm:  0.014902 | fidelity:  0.996979 | Sz: -0.000000 | S^2:  0.001924
iter: 715 | loss: -5.932355 | norm:  0.014631 | fidelity:  0.996986 | Sz:  0.000000 | S^2:  0.001925
iter: 716 | loss: -5.932411 | norm:  0.014346 | fidelity:  0.996995 | Sz:  0.000000 | S^2:  0.001926
iter: 717 | loss: -5.932443 | norm:  0.014061 | fidelity:  0.997001 | Sz:  0.000000 | S^2:  0.001927
iter: 718 | loss: -5.932399 | norm:  0.013816 | fidelity:  0.996993 | Sz: -0.000000 | S^2:  0.001927
iter: 719 | loss: -5.932456 | norm:  0.013611 | fidelity:  0.997003 | Sz: -0.000000 | S^2:  0.001928
iter: 720 | loss: -5.932464 | norm:  0.013409 | fidelity:  0.997005 | Sz: -0.000000 | S^2:  0.001928
iter: 721 | loss: -5.932521 | norm:  0.013204 | fidelity:  0.997015 | Sz:  0.000000 | S^2:  0.001929
iter: 722 | loss: -5.932515 | norm:  0.012995 | fidelity:  0.997014 | Sz:  0.000000 | S^2:  0.001930
iter: 723 | loss: -5.932548 | norm:  0.012786 | fidelity:  0.997019 | Sz:  0.000000 | S^2:  0.001931
iter: 724 | loss: -5.932565 | norm:  0.012576 | fidelity:  0.997022 | Sz:  0.000000 | S^2:  0.001932
iter: 725 | loss: -5.932574 | norm:  0.012358 | fidelity:  0.997023 | Sz:  0.000000 | S^2:  0.001932
iter: 726 | loss: -5.932635 | norm:  0.012149 | fidelity:  0.997033 | Sz: -0.000000 | S^2:  0.001933
iter: 727 | loss: -5.932625 | norm:  0.011958 | fidelity:  0.997032 | Sz: -0.000000 | S^2:  0.001934
iter: 728 | loss: -5.932655 | norm:  0.011783 | fidelity:  0.997037 | Sz:  0.000000 | S^2:  0.001935
iter: 729 | loss: -5.932709 | norm:  0.011628 | fidelity:  0.997046 | Sz:  0.000000 | S^2:  0.001935
iter: 730 | loss: -5.932679 | norm:  0.011476 | fidelity:  0.997041 | Sz: -0.000000 | S^2:  0.001936
iter: 731 | loss: -5.932726 | norm:  0.011318 | fidelity:  0.997048 | Sz:  0.000000 | S^2:  0.001937
iter: 732 | loss: -5.932763 | norm:  0.011151 | fidelity:  0.997055 | Sz: -0.000000 | S^2:  0.001937
iter: 733 | loss: -5.932767 | norm:  0.010983 | fidelity:  0.997055 | Sz:  0.000000 | S^2:  0.001938
iter: 734 | loss: -5.932846 | norm:  0.010824 | fidelity:  0.997068 | Sz: -0.000000 | S^2:  0.001939
iter: 735 | loss: -5.932798 | norm:  0.010667 | fidelity:  0.997060 | Sz: -0.000000 | S^2:  0.001940
iter: 736 | loss: -5.932831 | norm:  0.010519 | fidelity:  0.997066 | Sz: -0.000000 | S^2:  0.001941
iter: 737 | loss: -5.932858 | norm:  0.010383 | fidelity:  0.997070 | Sz: -0.000000 | S^2:  0.001942
iter: 738 | loss: -5.932877 | norm:  0.010249 | fidelity:  0.997073 | Sz: -0.000000 | S^2:  0.001943
iter: 739 | loss: -5.932877 | norm:  0.010116 | fidelity:  0.997073 | Sz:  0.000000 | S^2:  0.001944
iter: 740 | loss: -5.932926 | norm:  0.009980 | fidelity:  0.997081 | Sz: -0.000000 | S^2:  0.001945

learning rate =  0.0006104156374931336
Find operators
1j [10^ 5^ 12 3] + -1j [12^ 3^ 10 5]
1j [1^ 0^ 11 10] + -1j [11^ 10^ 1 0]
1j [7^ 2^ 15 10] + -1j [15^ 10^ 7 2]
-1j [11^ 8^ 13 6] + 1j [13^ 6^ 11 8]
1j [8^ 7^ 11 4] + -1j [11^ 4^ 8 7]
-1j [3^ 0^ 14 5] + 1j [14^ 5^ 3 0]
-1j [5^ 2^ 6 1] + 1j [6^ 1^ 5 2]
-1j [9^ 0^ 10 3] + 1j [10^ 3^ 9 0]
-1j [5^ 0^ 14 11] + 1j [14^ 11^ 5 0]
-1j [11^ 4^ 14 1] + 1j [14^ 1^ 11 4]
1j [3^ 0^ 13 6] + -1j [13^ 6^ 3 0]
-1j [10^ 3^ 15 14] + 1j [15^ 14^ 10 3]
1j [4^ 3^ 6 1] + -1j [6^ 1^ 4 3]
1j [3^ 2^ 9 8] + -1j [9^ 8^ 3 2]
-1j [6^ 1^ 15 8] + 1j [15^ 8^ 6 1]
1j [8^ 7^ 10 5] + -1j [10^ 5^ 8 7]
with max gradients
[0.017980332, 0.016666297, 0.014241577, 0.012457887, 0.011573214, 0.01121994, 0.011181835, 0.011116617, 0.011068919, 0.011044434, 0.010841807, 0.010828973, 0.010818898, 0.010640504, 0.010341487, 0.010032]

iter: 741 | loss: -5.932897 | norm:  0.049816 | fidelity:  0.997076 | Sz:  0.000000 | S^2:  0.001946
iter: 742 | loss: -5.933023 | norm:  0.068877 | fidelity:  0.997090 | Sz: -0.000000 | S^2:  0.001977
iter: 743 | loss: -5.933193 | norm:  0.069339 | fidelity:  0.997122 | Sz: -0.000000 | S^2:  0.001938
iter: 744 | loss: -5.933293 | norm:  0.058942 | fidelity:  0.997130 | Sz:  0.000000 | S^2:  0.001898
iter: 745 | loss: -5.933380 | norm:  0.055992 | fidelity:  0.997136 | Sz:  0.000000 | S^2:  0.001876
iter: 746 | loss: -5.933544 | norm:  0.059539 | fidelity:  0.997163 | Sz: -0.000000 | S^2:  0.001863
iter: 747 | loss: -5.933636 | norm:  0.052835 | fidelity:  0.997182 | Sz:  0.000000 | S^2:  0.001853
iter: 748 | loss: -5.933810 | norm:  0.044293 | fidelity:  0.997215 | Sz: -0.000000 | S^2:  0.001849
iter: 749 | loss: -5.933865 | norm:  0.046091 | fidelity:  0.997227 | Sz: -0.000000 | S^2:  0.001850
iter: 750 | loss: -5.933994 | norm:  0.049499 | fidelity:  0.997248 | Sz: -0.000000 | S^2:  0.001846
iter: 751 | loss: -5.934051 | norm:  0.046398 | fidelity:  0.997255 | Sz: -0.000000 | S^2:  0.001832
iter: 752 | loss: -5.934139 | norm:  0.041000 | fidelity:  0.997267 | Sz: -0.000000 | S^2:  0.001811
iter: 753 | loss: -5.934314 | norm:  0.039876 | fidelity:  0.997294 | Sz: -0.000000 | S^2:  0.001787
iter: 754 | loss: -5.934382 | norm:  0.040730 | fidelity:  0.997304 | Sz: -0.000000 | S^2:  0.001763
iter: 755 | loss: -5.934511 | norm:  0.039371 | fidelity:  0.997324 | Sz:  0.000000 | S^2:  0.001742
iter: 756 | loss: -5.934556 | norm:  0.037399 | fidelity:  0.997331 | Sz:  0.000000 | S^2:  0.001727
iter: 757 | loss: -5.934658 | norm:  0.037165 | fidelity:  0.997347 | Sz:  0.000000 | S^2:  0.001717
iter: 758 | loss: -5.934745 | norm:  0.036738 | fidelity:  0.997360 | Sz:  0.000000 | S^2:  0.001712
iter: 759 | loss: -5.934835 | norm:  0.034518 | fidelity:  0.997375 | Sz: -0.000000 | S^2:  0.001709
iter: 760 | loss: -5.934890 | norm:  0.032556 | fidelity:  0.997384 | Sz:  0.000000 | S^2:  0.001706
iter: 761 | loss: -5.935014 | norm:  0.032694 | fidelity:  0.997405 | Sz:  0.000000 | S^2:  0.001702
iter: 762 | loss: -5.935090 | norm:  0.033219 | fidelity:  0.997418 | Sz:  0.000000 | S^2:  0.001696
iter: 763 | loss: -5.935147 | norm:  0.032310 | fidelity:  0.997426 | Sz: -0.000000 | S^2:  0.001689
iter: 764 | loss: -5.935255 | norm:  0.030788 | fidelity:  0.997442 | Sz: -0.000000 | S^2:  0.001681
iter: 765 | loss: -5.935296 | norm:  0.030183 | fidelity:  0.997446 | Sz: -0.000000 | S^2:  0.001673
iter: 766 | loss: -5.935366 | norm:  0.030026 | fidelity:  0.997455 | Sz:  0.000000 | S^2:  0.001667
iter: 767 | loss: -5.935408 | norm:  0.029261 | fidelity:  0.997461 | Sz: -0.000000 | S^2:  0.001661
iter: 768 | loss: -5.935488 | norm:  0.028398 | fidelity:  0.997473 | Sz: -0.000000 | S^2:  0.001657
iter: 769 | loss: -5.935570 | norm:  0.028098 | fidelity:  0.997487 | Sz: -0.000000 | S^2:  0.001653
iter: 770 | loss: -5.935584 | norm:  0.027806 | fidelity:  0.997490 | Sz: -0.000000 | S^2:  0.001649
iter: 771 | loss: -5.935691 | norm:  0.027146 | fidelity:  0.997507 | Sz:  0.000000 | S^2:  0.001645
iter: 772 | loss: -5.935777 | norm:  0.026590 | fidelity:  0.997520 | Sz:  0.000000 | S^2:  0.001642
iter: 773 | loss: -5.935783 | norm:  0.026330 | fidelity:  0.997519 | Sz: -0.000000 | S^2:  0.001638
iter: 774 | loss: -5.935869 | norm:  0.025968 | fidelity:  0.997531 | Sz:  0.000000 | S^2:  0.001633
iter: 775 | loss: -5.935975 | norm:  0.025403 | fidelity:  0.997547 | Sz:  0.000000 | S^2:  0.001629
iter: 776 | loss: -5.935979 | norm:  0.024932 | fidelity:  0.997547 | Sz: -0.000000 | S^2:  0.001624
iter: 777 | loss: -5.936048 | norm:  0.024591 | fidelity:  0.997558 | Sz: -0.000000 | S^2:  0.001621
iter: 778 | loss: -5.936120 | norm:  0.024259 | fidelity:  0.997571 | Sz:  0.000000 | S^2:  0.001618
iter: 779 | loss: -5.936174 | norm:  0.023940 | fidelity:  0.997581 | Sz:  0.000000 | S^2:  0.001615
iter: 780 | loss: -5.936256 | norm:  0.023588 | fidelity:  0.997594 | Sz:  0.000000 | S^2:  0.001613
iter: 781 | loss: -5.936273 | norm:  0.023195 | fidelity:  0.997596 | Sz: -0.000000 | S^2:  0.001610
iter: 782 | loss: -5.936335 | norm:  0.022890 | fidelity:  0.997605 | Sz:  0.000000 | S^2:  0.001607
iter: 783 | loss: -5.936386 | norm:  0.022670 | fidelity:  0.997611 | Sz: -0.000000 | S^2:  0.001603
iter: 784 | loss: -5.936416 | norm:  0.022334 | fidelity:  0.997615 | Sz: -0.000000 | S^2:  0.001598
iter: 785 | loss: -5.936448 | norm:  0.021920 | fidelity:  0.997619 | Sz: -0.000000 | S^2:  0.001593
iter: 786 | loss: -5.936535 | norm:  0.021647 | fidelity:  0.997634 | Sz: -0.000000 | S^2:  0.001588
iter: 787 | loss: -5.936592 | norm:  0.021399 | fidelity:  0.997644 | Sz:  0.000000 | S^2:  0.001584
iter: 788 | loss: -5.936632 | norm:  0.021054 | fidelity:  0.997651 | Sz:  0.000000 | S^2:  0.001581
iter: 789 | loss: -5.936717 | norm:  0.020781 | fidelity:  0.997665 | Sz:  0.000000 | S^2:  0.001578
iter: 790 | loss: -5.936733 | norm:  0.020547 | fidelity:  0.997666 | Sz: -0.000000 | S^2:  0.001575
iter: 791 | loss: -5.936812 | norm:  0.020224 | fidelity:  0.997678 | Sz:  0.000000 | S^2:  0.001572
iter: 792 | loss: -5.936837 | norm:  0.019950 | fidelity:  0.997681 | Sz: -0.000000 | S^2:  0.001569
iter: 793 | loss: -5.936839 | norm:  0.019798 | fidelity:  0.997680 | Sz:  0.000000 | S^2:  0.001566
iter: 794 | loss: -5.936923 | norm:  0.019567 | fidelity:  0.997694 | Sz: -0.000000 | S^2:  0.001562
iter: 795 | loss: -5.936908 | norm:  0.019238 | fidelity:  0.997692 | Sz:  0.000000 | S^2:  0.001559
iter: 796 | loss: -5.936958 | norm:  0.018999 | fidelity:  0.997700 | Sz: -0.000000 | S^2:  0.001556
iter: 797 | loss: -5.937015 | norm:  0.018804 | fidelity:  0.997709 | Sz:  0.000000 | S^2:  0.001552
iter: 798 | loss: -5.937065 | norm:  0.018525 | fidelity:  0.997717 | Sz: -0.000000 | S^2:  0.001549
iter: 799 | loss: -5.937067 | norm:  0.018254 | fidelity:  0.997716 | Sz: -0.000000 | S^2:  0.001546
iter: 800 | loss: -5.937116 | norm:  0.018052 | fidelity:  0.997724 | Sz: -0.000000 | S^2:  0.001543
iter: 801 | loss: -5.937181 | norm:  0.017836 | fidelity:  0.997735 | Sz:  0.000000 | S^2:  0.001541
iter: 802 | loss: -5.937225 | norm:  0.017622 | fidelity:  0.997742 | Sz:  0.000000 | S^2:  0.001538
iter: 803 | loss: -5.937246 | norm:  0.017461 | fidelity:  0.997745 | Sz:  0.000000 | S^2:  0.001536
iter: 804 | loss: -5.937298 | norm:  0.017267 | fidelity:  0.997754 | Sz: -0.000000 | S^2:  0.001533
iter: 805 | loss: -5.937296 | norm:  0.017011 | fidelity:  0.997753 | Sz: -0.000000 | S^2:  0.001530
iter: 806 | loss: -5.937334 | norm:  0.016779 | fidelity:  0.997759 | Sz: -0.000000 | S^2:  0.001528
iter: 807 | loss: -5.937365 | norm:  0.016589 | fidelity:  0.997764 | Sz: -0.000000 | S^2:  0.001525
iter: 808 | loss: -5.937429 | norm:  0.016387 | fidelity:  0.997774 | Sz:  0.000000 | S^2:  0.001523
iter: 809 | loss: -5.937459 | norm:  0.016184 | fidelity:  0.997779 | Sz:  0.000000 | S^2:  0.001520
iter: 810 | loss: -5.937470 | norm:  0.016008 | fidelity:  0.997780 | Sz:  0.000000 | S^2:  0.001518
iter: 811 | loss: -5.937529 | norm:  0.015837 | fidelity:  0.997790 | Sz:  0.000000 | S^2:  0.001516
iter: 812 | loss: -5.937561 | norm:  0.015655 | fidelity:  0.997796 | Sz:  0.000000 | S^2:  0.001513
iter: 813 | loss: -5.937593 | norm:  0.015460 | fidelity:  0.997801 | Sz: -0.000000 | S^2:  0.001511
iter: 814 | loss: -5.937589 | norm:  0.015252 | fidelity:  0.997800 | Sz: -0.000000 | S^2:  0.001509
iter: 815 | loss: -5.937625 | norm:  0.015045 | fidelity:  0.997806 | Sz:  0.000000 | S^2:  0.001506
iter: 816 | loss: -5.937658 | norm:  0.014856 | fidelity:  0.997811 | Sz: -0.000000 | S^2:  0.001504
iter: 817 | loss: -5.937649 | norm:  0.014685 | fidelity:  0.997809 | Sz: -0.000000 | S^2:  0.001502
iter: 818 | loss: -5.937708 | norm:  0.014511 | fidelity:  0.997819 | Sz:  0.000000 | S^2:  0.001500
iter: 819 | loss: -5.937765 | norm:  0.014327 | fidelity:  0.997828 | Sz: -0.000000 | S^2:  0.001497
iter: 820 | loss: -5.937751 | norm:  0.014145 | fidelity:  0.997826 | Sz: -0.000000 | S^2:  0.001495
iter: 821 | loss: -5.937792 | norm:  0.013963 | fidelity:  0.997833 | Sz:  0.000000 | S^2:  0.001493
iter: 822 | loss: -5.937763 | norm:  0.013781 | fidelity:  0.997828 | Sz:  0.000000 | S^2:  0.001491
iter: 823 | loss: -5.937788 | norm:  0.013607 | fidelity:  0.997832 | Sz:  0.000000 | S^2:  0.001489
iter: 824 | loss: -5.937845 | norm:  0.013439 | fidelity:  0.997842 | Sz: -0.000000 | S^2:  0.001487
iter: 825 | loss: -5.937879 | norm:  0.013270 | fidelity:  0.997847 | Sz:  0.000000 | S^2:  0.001485
iter: 826 | loss: -5.937906 | norm:  0.013096 | fidelity:  0.997852 | Sz: -0.000000 | S^2:  0.001483
iter: 827 | loss: -5.937930 | norm:  0.012922 | fidelity:  0.997855 | Sz: -0.000000 | S^2:  0.001481
iter: 828 | loss: -5.937958 | norm:  0.012749 | fidelity:  0.997860 | Sz:  0.000000 | S^2:  0.001479
iter: 829 | loss: -5.937936 | norm:  0.012582 | fidelity:  0.997856 | Sz:  0.000000 | S^2:  0.001477
iter: 830 | loss: -5.938000 | norm:  0.012424 | fidelity:  0.997867 | Sz: -0.000000 | S^2:  0.001475
iter: 831 | loss: -5.938007 | norm:  0.012267 | fidelity:  0.997868 | Sz: -0.000000 | S^2:  0.001473
iter: 832 | loss: -5.938022 | norm:  0.012106 | fidelity:  0.997871 | Sz: -0.000000 | S^2:  0.001472
iter: 833 | loss: -5.938043 | norm:  0.011945 | fidelity:  0.997874 | Sz:  0.000000 | S^2:  0.001470
iter: 834 | loss: -5.938045 | norm:  0.011786 | fidelity:  0.997875 | Sz: -0.000000 | S^2:  0.001469
iter: 835 | loss: -5.938098 | norm:  0.011630 | fidelity:  0.997884 | Sz:  0.000000 | S^2:  0.001467
iter: 836 | loss: -5.938113 | norm:  0.011477 | fidelity:  0.997886 | Sz:  0.000000 | S^2:  0.001466
iter: 837 | loss: -5.938111 | norm:  0.011325 | fidelity:  0.997886 | Sz: -0.000000 | S^2:  0.001464
iter: 838 | loss: -5.938136 | norm:  0.011171 | fidelity:  0.997890 | Sz:  0.000000 | S^2:  0.001463
iter: 839 | loss: -5.938203 | norm:  0.011019 | fidelity:  0.997901 | Sz: -0.000000 | S^2:  0.001462
iter: 840 | loss: -5.938216 | norm:  0.010870 | fidelity:  0.997903 | Sz:  0.000000 | S^2:  0.001460
iter: 841 | loss: -5.938168 | norm:  0.010724 | fidelity:  0.997895 | Sz:  0.000000 | S^2:  0.001459
iter: 842 | loss: -5.938229 | norm:  0.010584 | fidelity:  0.997906 | Sz:  0.000000 | S^2:  0.001458
iter: 843 | loss: -5.938231 | norm:  0.010445 | fidelity:  0.997906 | Sz: -0.000000 | S^2:  0.001457
iter: 844 | loss: -5.938247 | norm:  0.010305 | fidelity:  0.997909 | Sz:  0.000000 | S^2:  0.001456
iter: 845 | loss: -5.938281 | norm:  0.010165 | fidelity:  0.997915 | Sz: -0.000000 | S^2:  0.001455
iter: 846 | loss: -5.938283 | norm:  0.010024 | fidelity:  0.997915 | Sz: -0.000000 | S^2:  0.001454
iter: 847 | loss: -5.938298 | norm:  0.009884 | fidelity:  0.997918 | Sz:  0.000000 | S^2:  0.001453

learning rate =  0.0007293046452105046
Find operators
-1j [8^ 1^ 15 14] + 1j [15^ 14^ 8 1]
-1j [5^ 0^ 6 3] + 1j [6^ 3^ 5 0]
-1j [9^ 4^ 12 1] + 1j [12^ 1^ 9 4]
-1j [9^ 4^ 10 7] + 1j [10^ 7^ 9 4]
with max gradients
[0.015805764, 0.015467562, 0.014864959, 0.011873575]

iter: 848 | loss: -5.938326 | norm:  0.030758 | fidelity:  0.997922 | Sz: -0.000000 | S^2:  0.001453
iter: 849 | loss: -5.938296 | norm:  0.075467 | fidelity:  0.997936 | Sz: -0.000000 | S^2:  0.001450
iter: 850 | loss: -5.938358 | norm:  0.077862 | fidelity:  0.997932 | Sz:  0.000000 | S^2:  0.001442
iter: 851 | loss: -5.938418 | norm:  0.065351 | fidelity:  0.997928 | Sz:  0.000000 | S^2:  0.001445
iter: 852 | loss: -5.938495 | norm:  0.046271 | fidelity:  0.997934 | Sz:  0.000000 | S^2:  0.001450
iter: 853 | loss: -5.938547 | norm:  0.064084 | fidelity:  0.997947 | Sz: -0.000000 | S^2:  0.001446
iter: 854 | loss: -5.938620 | norm:  0.058538 | fidelity:  0.997966 | Sz:  0.000000 | S^2:  0.001435
iter: 855 | loss: -5.938695 | norm:  0.035220 | fidelity:  0.997983 | Sz: -0.000000 | S^2:  0.001424
iter: 856 | loss: -5.938801 | norm:  0.039650 | fidelity:  0.998004 | Sz: -0.000000 | S^2:  0.001420
iter: 857 | loss: -5.938753 | norm:  0.052529 | fidelity:  0.997994 | Sz:  0.000000 | S^2:  0.001418
iter: 858 | loss: -5.938825 | norm:  0.047265 | fidelity:  0.998002 | Sz:  0.000000 | S^2:  0.001414
iter: 859 | loss: -5.938902 | norm:  0.033145 | fidelity:  0.998012 | Sz:  0.000000 | S^2:  0.001410
iter: 860 | loss: -5.938936 | norm:  0.032834 | fidelity:  0.998017 | Sz:  0.000000 | S^2:  0.001410
iter: 861 | loss: -5.938990 | norm:  0.040148 | fidelity:  0.998027 | Sz: -0.000000 | S^2:  0.001412
iter: 862 | loss: -5.939029 | norm:  0.037742 | fidelity:  0.998034 | Sz:  0.000000 | S^2:  0.001414
iter: 863 | loss: -5.939070 | norm:  0.029729 | fidelity:  0.998041 | Sz:  0.000000 | S^2:  0.001414
iter: 864 | loss: -5.939129 | norm:  0.029550 | fidelity:  0.998050 | Sz:  0.000000 | S^2:  0.001415
iter: 865 | loss: -5.939135 | norm:  0.033593 | fidelity:  0.998052 | Sz: -0.000000 | S^2:  0.001414
iter: 866 | loss: -5.939229 | norm:  0.031834 | fidelity:  0.998067 | Sz: -0.000000 | S^2:  0.001412
iter: 867 | loss: -5.939244 | norm:  0.026329 | fidelity:  0.998069 | Sz: -0.000000 | S^2:  0.001410
iter: 868 | loss: -5.939288 | norm:  0.025044 | fidelity:  0.998076 | Sz: -0.000000 | S^2:  0.001407
iter: 869 | loss: -5.939352 | norm:  0.027594 | fidelity:  0.998087 | Sz: -0.000000 | S^2:  0.001404
iter: 870 | loss: -5.939310 | norm:  0.027691 | fidelity:  0.998079 | Sz: -0.000000 | S^2:  0.001401
iter: 871 | loss: -5.939393 | norm:  0.024719 | fidelity:  0.998093 | Sz: -0.000000 | S^2:  0.001398
iter: 872 | loss: -5.939451 | norm:  0.022727 | fidelity:  0.998101 | Sz:  0.000000 | S^2:  0.001397
iter: 873 | loss: -5.939490 | norm:  0.023316 | fidelity:  0.998107 | Sz: -0.000000 | S^2:  0.001397
iter: 874 | loss: -5.939515 | norm:  0.023435 | fidelity:  0.998110 | Sz: -0.000000 | S^2:  0.001398
iter: 875 | loss: -5.939549 | norm:  0.022030 | fidelity:  0.998117 | Sz:  0.000000 | S^2:  0.001400
iter: 876 | loss: -5.939573 | norm:  0.021082 | fidelity:  0.998122 | Sz:  0.000000 | S^2:  0.001402
iter: 877 | loss: -5.939594 | norm:  0.021191 | fidelity:  0.998128 | Sz:  0.000000 | S^2:  0.001404
iter: 878 | loss: -5.939637 | norm:  0.020701 | fidelity:  0.998137 | Sz:  0.000000 | S^2:  0.001404
iter: 879 | loss: -5.939695 | norm:  0.019413 | fidelity:  0.998148 | Sz: -0.000000 | S^2:  0.001404
iter: 880 | loss: -5.939713 | norm:  0.018823 | fidelity:  0.998150 | Sz:  0.000000 | S^2:  0.001402
iter: 881 | loss: -5.939708 | norm:  0.018995 | fidelity:  0.998148 | Sz: -0.000000 | S^2:  0.001399
iter: 882 | loss: -5.939743 | norm:  0.018705 | fidelity:  0.998152 | Sz: -0.000000 | S^2:  0.001396
iter: 883 | loss: -5.939790 | norm:  0.017930 | fidelity:  0.998158 | Sz:  0.000000 | S^2:  0.001395
iter: 884 | loss: -5.939788 | norm:  0.017447 | fidelity:  0.998158 | Sz:  0.000000 | S^2:  0.001395
iter: 885 | loss: -5.939810 | norm:  0.017366 | fidelity:  0.998162 | Sz:  0.000000 | S^2:  0.001396
iter: 886 | loss: -5.939820 | norm:  0.017051 | fidelity:  0.998164 | Sz: -0.000000 | S^2:  0.001397
iter: 887 | loss: -5.939874 | norm:  0.016364 | fidelity:  0.998174 | Sz:  0.000000 | S^2:  0.001397
iter: 888 | loss: -5.939909 | norm:  0.016017 | fidelity:  0.998179 | Sz:  0.000000 | S^2:  0.001396
iter: 889 | loss: -5.939904 | norm:  0.016017 | fidelity:  0.998178 | Sz: -0.000000 | S^2:  0.001395
iter: 890 | loss: -5.939953 | norm:  0.015719 | fidelity:  0.998185 | Sz:  0.000000 | S^2:  0.001394
iter: 891 | loss: -5.939985 | norm:  0.015213 | fidelity:  0.998190 | Sz: -0.000000 | S^2:  0.001393
iter: 892 | loss: -5.940011 | norm:  0.014893 | fidelity:  0.998194 | Sz:  0.000000 | S^2:  0.001393
iter: 893 | loss: -5.940007 | norm:  0.014776 | fidelity:  0.998193 | Sz:  0.000000 | S^2:  0.001393
iter: 894 | loss: -5.940059 | norm:  0.014503 | fidelity:  0.998202 | Sz:  0.000000 | S^2:  0.001392
iter: 895 | loss: -5.940059 | norm:  0.013984 | fidelity:  0.998202 | Sz:  0.000000 | S^2:  0.001392
iter: 896 | loss: -5.940090 | norm:  0.013734 | fidelity:  0.998206 | Sz: -0.000000 | S^2:  0.001392
iter: 897 | loss: -5.940098 | norm:  0.013686 | fidelity:  0.998207 | Sz:  0.000000 | S^2:  0.001392
iter: 898 | loss: -5.940112 | norm:  0.013367 | fidelity:  0.998209 | Sz: -0.000000 | S^2:  0.001392
iter: 899 | loss: -5.940147 | norm:  0.013048 | fidelity:  0.998215 | Sz: -0.000000 | S^2:  0.001392
iter: 900 | loss: -5.940142 | norm:  0.012973 | fidelity:  0.998214 | Sz: -0.000000 | S^2:  0.001392
iter: 901 | loss: -5.940164 | norm:  0.012786 | fidelity:  0.998218 | Sz: -0.000000 | S^2:  0.001391
iter: 902 | loss: -5.940215 | norm:  0.012444 | fidelity:  0.998227 | Sz:  0.000000 | S^2:  0.001391
iter: 903 | loss: -5.940218 | norm:  0.012285 | fidelity:  0.998227 | Sz: -0.000000 | S^2:  0.001391
iter: 904 | loss: -5.940228 | norm:  0.012160 | fidelity:  0.998228 | Sz: -0.000000 | S^2:  0.001391
iter: 905 | loss: -5.940224 | norm:  0.011839 | fidelity:  0.998227 | Sz:  0.000000 | S^2:  0.001392
iter: 906 | loss: -5.940279 | norm:  0.011550 | fidelity:  0.998236 | Sz: -0.000000 | S^2:  0.001393
iter: 907 | loss: -5.940293 | norm:  0.011416 | fidelity:  0.998238 | Sz: -0.000000 | S^2:  0.001394
iter: 908 | loss: -5.940254 | norm:  0.011220 | fidelity:  0.998232 | Sz: -0.000000 | S^2:  0.001394
iter: 909 | loss: -5.940275 | norm:  0.010931 | fidelity:  0.998236 | Sz: -0.000000 | S^2:  0.001394
iter: 910 | loss: -5.940273 | norm:  0.010782 | fidelity:  0.998235 | Sz:  0.000000 | S^2:  0.001394
iter: 911 | loss: -5.940311 | norm:  0.010695 | fidelity:  0.998242 | Sz: -0.000000 | S^2:  0.001394
iter: 912 | loss: -5.940325 | norm:  0.010499 | fidelity:  0.998244 | Sz: -0.000000 | S^2:  0.001395
iter: 913 | loss: -5.940369 | norm:  0.010323 | fidelity:  0.998251 | Sz:  0.000000 | S^2:  0.001395
iter: 914 | loss: -5.940390 | norm:  0.010218 | fidelity:  0.998254 | Sz:  0.000000 | S^2:  0.001396
iter: 915 | loss: -5.940367 | norm:  0.010054 | fidelity:  0.998250 | Sz:  0.000000 | S^2:  0.001397
iter: 916 | loss: -5.940408 | norm:  0.009834 | fidelity:  0.998256 | Sz:  0.000000 | S^2:  0.001398

learning rate =  0.000546735804527998
Find operators
1j [4^ 1^ 12 9] + -1j [12^ 9^ 4 1]
with max gradients
[0.010934716]

iter: 917 | loss: -5.940426 | norm:  0.014608 | fidelity:  0.998259 | Sz: -0.000000 | S^2:  0.001399
iter: 918 | loss: -5.940361 | norm:  0.058734 | fidelity:  0.998255 | Sz: -0.000000 | S^2:  0.001408
iter: 919 | loss: -5.940393 | norm:  0.055170 | fidelity:  0.998257 | Sz: -0.000000 | S^2:  0.001404
iter: 920 | loss: -5.940467 | norm:  0.040810 | fidelity:  0.998264 | Sz: -0.000000 | S^2:  0.001406
iter: 921 | loss: -5.940422 | norm:  0.041959 | fidelity:  0.998254 | Sz:  0.000000 | S^2:  0.001424
iter: 922 | loss: -5.940430 | norm:  0.049146 | fidelity:  0.998257 | Sz:  0.000000 | S^2:  0.001430
iter: 923 | loss: -5.940472 | norm:  0.033701 | fidelity:  0.998267 | Sz:  0.000000 | S^2:  0.001420
iter: 924 | loss: -5.940547 | norm:  0.019424 | fidelity:  0.998283 | Sz: -0.000000 | S^2:  0.001409
iter: 925 | loss: -5.940486 | norm:  0.032203 | fidelity:  0.998275 | Sz:  0.000000 | S^2:  0.001406
iter: 926 | loss: -5.940527 | norm:  0.036131 | fidelity:  0.998283 | Sz: -0.000000 | S^2:  0.001407
iter: 927 | loss: -5.940542 | norm:  0.029095 | fidelity:  0.998283 | Sz:  0.000000 | S^2:  0.001409
iter: 928 | loss: -5.940579 | norm:  0.024740 | fidelity:  0.998287 | Sz: -0.000000 | S^2:  0.001411
iter: 929 | loss: -5.940578 | norm:  0.024508 | fidelity:  0.998284 | Sz:  0.000000 | S^2:  0.001412
iter: 930 | loss: -5.940618 | norm:  0.021736 | fidelity:  0.998289 | Sz:  0.000000 | S^2:  0.001412
iter: 931 | loss: -5.940629 | norm:  0.021291 | fidelity:  0.998291 | Sz:  0.000000 | S^2:  0.001413
iter: 932 | loss: -5.940614 | norm:  0.024354 | fidelity:  0.998289 | Sz: -0.000000 | S^2:  0.001414
iter: 933 | loss: -5.940659 | norm:  0.024048 | fidelity:  0.998298 | Sz: -0.000000 | S^2:  0.001416
iter: 934 | loss: -5.940675 | norm:  0.019400 | fidelity:  0.998301 | Sz: -0.000000 | S^2:  0.001418
iter: 935 | loss: -5.940650 | norm:  0.015714 | fidelity:  0.998297 | Sz: -0.000000 | S^2:  0.001420
iter: 936 | loss: -5.940673 | norm:  0.016788 | fidelity:  0.998300 | Sz:  0.000000 | S^2:  0.001423
iter: 937 | loss: -5.940683 | norm:  0.018457 | fidelity:  0.998302 | Sz: -0.000000 | S^2:  0.001425
iter: 938 | loss: -5.940685 | norm:  0.018194 | fidelity:  0.998302 | Sz:  0.000000 | S^2:  0.001426
iter: 939 | loss: -5.940685 | norm:  0.017006 | fidelity:  0.998301 | Sz: -0.000000 | S^2:  0.001424
iter: 940 | loss: -5.940724 | norm:  0.015549 | fidelity:  0.998307 | Sz: -0.000000 | S^2:  0.001423
iter: 941 | loss: -5.940722 | norm:  0.014046 | fidelity:  0.998305 | Sz: -0.000000 | S^2:  0.001423
iter: 942 | loss: -5.940778 | norm:  0.013481 | fidelity:  0.998313 | Sz: -0.000000 | S^2:  0.001423
iter: 943 | loss: -5.940720 | norm:  0.014022 | fidelity:  0.998302 | Sz: -0.000000 | S^2:  0.001424
iter: 944 | loss: -5.940775 | norm:  0.014502 | fidelity:  0.998311 | Sz:  0.000000 | S^2:  0.001425
iter: 945 | loss: -5.940751 | norm:  0.013672 | fidelity:  0.998308 | Sz: -0.000000 | S^2:  0.001427
iter: 946 | loss: -5.940790 | norm:  0.011569 | fidelity:  0.998316 | Sz: -0.000000 | S^2:  0.001428
iter: 947 | loss: -5.940774 | norm:  0.010470 | fidelity:  0.998315 | Sz:  0.000000 | S^2:  0.001430
iter: 948 | loss: -5.940771 | norm:  0.011398 | fidelity:  0.998315 | Sz:  0.000000 | S^2:  0.001431
iter: 949 | loss: -5.940799 | norm:  0.012038 | fidelity:  0.998319 | Sz: -0.000000 | S^2:  0.001431
iter: 950 | loss: -5.940836 | norm:  0.011410 | fidelity:  0.998324 | Sz:  0.000000 | S^2:  0.001431
iter: 951 | loss: -5.940835 | norm:  0.010541 | fidelity:  0.998323 | Sz:  0.000000 | S^2:  0.001431
iter: 952 | loss: -5.940862 | norm:  0.010195 | fidelity:  0.998326 | Sz: -0.000000 | S^2:  0.001431
iter: 953 | loss: -5.940843 | norm:  0.009871 | fidelity:  0.998322 | Sz: -0.000000 | S^2:  0.001431

learning rate =  0.0005165370524955009
Find operators
-1j [11^ 6^ 13 0] + 1j [13^ 0^ 11 6]
-1j [2^ 1^ 15 4] + 1j [15^ 4^ 2 1]
-1j [5^ 2^ 12 11] + 1j [12^ 11^ 5 2]
with max gradients
[0.010494524, 0.010325771, 0.010169371]

iter: 954 | loss: -5.940875 | norm:  0.020355 | fidelity:  0.998327 | Sz:  0.000000 | S^2:  0.001431
iter: 955 | loss: -5.940770 | norm:  0.092822 | fidelity:  0.998319 | Sz: -0.000000 | S^2:  0.001465
iter: 956 | loss: -5.940882 | norm:  0.046509 | fidelity:  0.998328 | Sz: -0.000000 | S^2:  0.001439
iter: 957 | loss: -5.940904 | norm:  0.050128 | fidelity:  0.998332 | Sz:  0.000000 | S^2:  0.001439
iter: 958 | loss: -5.940840 | norm:  0.065217 | fidelity:  0.998325 | Sz: -0.000000 | S^2:  0.001446
iter: 959 | loss: -5.940888 | norm:  0.059861 | fidelity:  0.998333 | Sz: -0.000000 | S^2:  0.001444
iter: 960 | loss: -5.940927 | norm:  0.040432 | fidelity:  0.998338 | Sz:  0.000000 | S^2:  0.001437
iter: 961 | loss: -5.940943 | norm:  0.026077 | fidelity:  0.998339 | Sz: -0.000000 | S^2:  0.001431
iter: 962 | loss: -5.940982 | norm:  0.036007 | fidelity:  0.998343 | Sz: -0.000000 | S^2:  0.001429
iter: 963 | loss: -5.941010 | norm:  0.046324 | fidelity:  0.998345 | Sz:  0.000000 | S^2:  0.001427
iter: 964 | loss: -5.941045 | norm:  0.045608 | fidelity:  0.998348 | Sz:  0.000000 | S^2:  0.001423
iter: 965 | loss: -5.941041 | norm:  0.035400 | fidelity:  0.998346 | Sz: -0.000000 | S^2:  0.001419
iter: 966 | loss: -5.941101 | norm:  0.022881 | fidelity:  0.998356 | Sz: -0.000000 | S^2:  0.001418
iter: 967 | loss: -5.941089 | norm:  0.022446 | fidelity:  0.998356 | Sz: -0.000000 | S^2:  0.001420
iter: 968 | loss: -5.941126 | norm:  0.030794 | fidelity:  0.998364 | Sz: -0.000000 | S^2:  0.001422
iter: 969 | loss: -5.941131 | norm:  0.034448 | fidelity:  0.998367 | Sz:  0.000000 | S^2:  0.001423
iter: 970 | loss: -5.941152 | norm:  0.031358 | fidelity:  0.998371 | Sz: -0.000000 | S^2:  0.001422
iter: 971 | loss: -5.941146 | norm:  0.024798 | fidelity:  0.998370 | Sz:  0.000000 | S^2:  0.001420
iter: 972 | loss: -5.941210 | norm:  0.019610 | fidelity:  0.998379 | Sz: -0.000000 | S^2:  0.001418
iter: 973 | loss: -5.941222 | norm:  0.019484 | fidelity:  0.998380 | Sz: -0.000000 | S^2:  0.001417
iter: 974 | loss: -5.941227 | norm:  0.022988 | fidelity:  0.998378 | Sz:  0.000000 | S^2:  0.001417
iter: 975 | loss: -5.941247 | norm:  0.025482 | fidelity:  0.998380 | Sz:  0.000000 | S^2:  0.001416
iter: 976 | loss: -5.941254 | norm:  0.024070 | fidelity:  0.998380 | Sz: -0.000000 | S^2:  0.001416
iter: 977 | loss: -5.941256 | norm:  0.019078 | fidelity:  0.998380 | Sz: -0.000000 | S^2:  0.001415
iter: 978 | loss: -5.941307 | norm:  0.014636 | fidelity:  0.998390 | Sz: -0.000000 | S^2:  0.001415
iter: 979 | loss: -5.941337 | norm:  0.015735 | fidelity:  0.998396 | Sz: -0.000000 | S^2:  0.001415
iter: 980 | loss: -5.941308 | norm:  0.019283 | fidelity:  0.998392 | Sz: -0.000000 | S^2:  0.001415
iter: 981 | loss: -5.941315 | norm:  0.020502 | fidelity:  0.998393 | Sz:  0.000000 | S^2:  0.001415
iter: 982 | loss: -5.941344 | norm:  0.018157 | fidelity:  0.998398 | Sz:  0.000000 | S^2:  0.001414
iter: 983 | loss: -5.941352 | norm:  0.013881 | fidelity:  0.998398 | Sz: -0.000000 | S^2:  0.001413
iter: 984 | loss: -5.941377 | norm:  0.012084 | fidelity:  0.998401 | Sz: -0.000000 | S^2:  0.001412
iter: 985 | loss: -5.941391 | norm:  0.014390 | fidelity:  0.998401 | Sz: -0.000000 | S^2:  0.001411
iter: 986 | loss: -5.941392 | norm:  0.016365 | fidelity:  0.998400 | Sz:  0.000000 | S^2:  0.001411
iter: 987 | loss: -5.941432 | norm:  0.015730 | fidelity:  0.998406 | Sz: -0.000000 | S^2:  0.001410
iter: 988 | loss: -5.941394 | norm:  0.013294 | fidelity:  0.998399 | Sz: -0.000000 | S^2:  0.001410
iter: 989 | loss: -5.941422 | norm:  0.011376 | fidelity:  0.998404 | Sz:  0.000000 | S^2:  0.001410
iter: 990 | loss: -5.941413 | norm:  0.011568 | fidelity:  0.998404 | Sz:  0.000000 | S^2:  0.001410
iter: 991 | loss: -5.941416 | norm:  0.012759 | fidelity:  0.998405 | Sz: -0.000000 | S^2:  0.001411
iter: 992 | loss: -5.941489 | norm:  0.013234 | fidelity:  0.998418 | Sz:  0.000000 | S^2:  0.001411
iter: 993 | loss: -5.941487 | norm:  0.012414 | fidelity:  0.998418 | Sz: -0.000000 | S^2:  0.001411
iter: 994 | loss: -5.941551 | norm:  0.010851 | fidelity:  0.998428 | Sz:  0.000000 | S^2:  0.001410
iter: 995 | loss: -5.941522 | norm:  0.010027 | fidelity:  0.998421 | Sz: -0.000000 | S^2:  0.001409
iter: 996 | loss: -5.941543 | norm:  0.010687 | fidelity:  0.998423 | Sz: -0.000000 | S^2:  0.001408
iter: 997 | loss: -5.941567 | norm:  0.011392 | fidelity:  0.998426 | Sz:  0.000000 | S^2:  0.001408
iter: 998 | loss: -5.941573 | norm:  0.010904 | fidelity:  0.998426 | Sz:  0.000000 | S^2:  0.001408
iter: 999 | loss: -5.941591 | norm:  0.009701 | fidelity:  0.998429 | Sz: -0.000000 | S^2:  0.001408


convergence criterion has satisfied, break the loop!
total run time:  87428.15228772163
