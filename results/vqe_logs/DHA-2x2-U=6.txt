spin up orbital energies: {0: -2.0, 2: 0, 4: 0, 6: 2.0}
spin down orbital energies:  {1: -2.0, 3: 0, 5: 0, 7: 2.0}
spin up indices:  [0, 2]    spin down indices:  [1, 3] 

ground state energy:  -1.634603054907389
particle number:  4

learning rate =  0.14999999321817448
Find operators
1j [1^ 0^ 5 4] + -1j [5^ 4^ 1 0]
1j [1^ 0^ 7 6] + -1j [7^ 6^ 1 0]
1j [3^ 0^ 7 4] + -1j [7^ 4^ 3 0]
1j [3^ 2^ 5 4] + -1j [5^ 4^ 3 2]
1j [3^ 2^ 7 6] + -1j [7^ 6^ 3 2]
-1j [2^ 1^ 7 4] + 1j [7^ 4^ 2 1]
1j [2^ 1^ 6 5] + -1j [6^ 5^ 2 1]
-1j [3^ 0^ 6 5] + 1j [6^ 5^ 3 0]
with max gradients
[3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0]

iter: 1 | loss:  2.000000 | norm:  8.485281 | fidelity:  0.383674 | Sz:  0.000000 | S^2: -0.000000
iter: 2 | loss: -0.664880 | norm:  4.051653 | fidelity:  0.631124 | Sz: -0.000000 | S^2:  0.000265
iter: 3 | loss: -1.161535 | norm:  3.081173 | fidelity:  0.723465 | Sz: -0.000000 | S^2:  0.009877
iter: 4 | loss: -0.766606 | norm:  4.606648 | fidelity:  0.729421 | Sz:  0.000000 | S^2:  0.039141
iter: 5 | loss: -0.603116 | norm:  4.455650 | fidelity:  0.746977 | Sz: -0.000000 | S^2:  0.057418
iter: 6 | loss: -0.688391 | norm:  3.571614 | fidelity:  0.781138 | Sz:  0.000000 | S^2:  0.047209
iter: 7 | loss: -0.806716 | norm:  3.130852 | fidelity:  0.819690 | Sz: -0.000000 | S^2:  0.023339
iter: 8 | loss: -0.909151 | norm:  3.196711 | fidelity:  0.858309 | Sz: -0.000000 | S^2:  0.006055
iter: 9 | loss: -1.031177 | norm:  3.005984 | fidelity:  0.894435 | Sz: -0.000000 | S^2:  0.001338
iter: 10 | loss: -1.148281 | norm:  2.548966 | fidelity:  0.922760 | Sz: -0.000000 | S^2:  0.003567
iter: 11 | loss: -1.222100 | norm:  2.316753 | fidelity:  0.940991 | Sz: -0.000000 | S^2:  0.004617
iter: 12 | loss: -1.256380 | norm:  2.479076 | fidelity:  0.950463 | Sz: -0.000000 | S^2:  0.002996
iter: 13 | loss: -1.283673 | norm:  2.643184 | fidelity:  0.952737 | Sz: -0.000000 | S^2:  0.007432
iter: 14 | loss: -1.327626 | norm:  2.516258 | fidelity:  0.948605 | Sz:  0.000000 | S^2:  0.030758
iter: 15 | loss: -1.380526 | norm:  2.101182 | fidelity:  0.938545 | Sz:  0.000000 | S^2:  0.082151
iter: 16 | loss: -1.414983 | norm:  1.611519 | fidelity:  0.923786 | Sz: -0.000000 | S^2:  0.160290
iter: 17 | loss: -1.410617 | norm:  1.444365 | fidelity:  0.907146 | Sz: -0.000000 | S^2:  0.249895
iter: 18 | loss: -1.374216 | norm:  1.723162 | fidelity:  0.892920 | Sz:  0.000000 | S^2:  0.327064
iter: 19 | loss: -1.338196 | norm:  2.035635 | fidelity:  0.885615 | Sz:  0.000000 | S^2:  0.371833
iter: 20 | loss: -1.333812 | norm:  2.098220 | fidelity:  0.887693 | Sz: -0.000000 | S^2:  0.377336
iter: 21 | loss: -1.366420 | norm:  1.868313 | fidelity:  0.898207 | Sz:  0.000000 | S^2:  0.348898
iter: 22 | loss: -1.416199 | norm:  1.451341 | fidelity:  0.913515 | Sz: -0.000000 | S^2:  0.298107
iter: 23 | loss: -1.457377 | norm:  1.067414 | fidelity:  0.929257 | Sz:  0.000000 | S^2:  0.237834
iter: 24 | loss: -1.476813 | norm:  0.975594 | fidelity:  0.942346 | Sz:  0.000000 | S^2:  0.179023
iter: 25 | loss: -1.478851 | norm:  1.118740 | fidelity:  0.951798 | Sz: -0.000000 | S^2:  0.128729
iter: 26 | loss: -1.476077 | norm:  1.232442 | fidelity:  0.957994 | Sz:  0.000000 | S^2:  0.089850
iter: 27 | loss: -1.476757 | norm:  1.221118 | fidelity:  0.961243 | Sz:  0.000000 | S^2:  0.062505
iter: 28 | loss: -1.480853 | norm:  1.129987 | fidelity:  0.961195 | Sz: -0.000000 | S^2:  0.045661
iter: 29 | loss: -1.485546 | norm:  1.046743 | fidelity:  0.957429 | Sz:  0.000000 | S^2:  0.037837
iter: 30 | loss: -1.491158 | norm:  0.997130 | fidelity:  0.950261 | Sz: -0.000000 | S^2:  0.037146
iter: 31 | loss: -1.499909 | norm:  0.932115 | fidelity:  0.940781 | Sz:  0.000000 | S^2:  0.041453
iter: 32 | loss: -1.510855 | norm:  0.832637 | fidelity:  0.930299 | Sz: -0.000000 | S^2:  0.048720
iter: 33 | loss: -1.519327 | norm:  0.759505 | fidelity:  0.919942 | Sz:  0.000000 | S^2:  0.057193
iter: 34 | loss: -1.521731 | norm:  0.764311 | fidelity:  0.910662 | Sz: -0.000000 | S^2:  0.065377
iter: 35 | loss: -1.519060 | norm:  0.791952 | fidelity:  0.903343 | Sz:  0.000000 | S^2:  0.071973
iter: 36 | loss: -1.515119 | norm:  0.774220 | fidelity:  0.898749 | Sz: -0.000000 | S^2:  0.075888
iter: 37 | loss: -1.512780 | norm:  0.728430 | fidelity:  0.897374 | Sz:  0.000000 | S^2:  0.076423
iter: 38 | loss: -1.513088 | norm:  0.718730 | fidelity:  0.899338 | Sz: -0.000000 | S^2:  0.073596
iter: 39 | loss: -1.516791 | norm:  0.737282 | fidelity:  0.904360 | Sz: -0.000000 | S^2:  0.068347
iter: 40 | loss: -1.524147 | norm:  0.702730 | fidelity:  0.911664 | Sz:  0.000000 | S^2:  0.062307
iter: 41 | loss: -1.532859 | norm:  0.573507 | fidelity:  0.919955 | Sz:  0.000000 | S^2:  0.057209
iter: 42 | loss: -1.538430 | norm:  0.412158 | fidelity:  0.927735 | Sz:  0.000000 | S^2:  0.054288
iter: 43 | loss: -1.538099 | norm:  0.390385 | fidelity:  0.933918 | Sz:  0.000000 | S^2:  0.054061
iter: 44 | loss: -1.533880 | norm:  0.507029 | fidelity:  0.938233 | Sz:  0.000000 | S^2:  0.056487
iter: 45 | loss: -1.530725 | norm:  0.580450 | fidelity:  0.941043 | Sz: -0.000000 | S^2:  0.061263
iter: 46 | loss: -1.531644 | norm:  0.544064 | fidelity:  0.942748 | Sz:  0.000000 | S^2:  0.067956
iter: 47 | loss: -1.535383 | norm:  0.433084 | fidelity:  0.943445 | Sz:  0.000000 | S^2:  0.075982
iter: 48 | loss: -1.538719 | norm:  0.350469 | fidelity:  0.943053 | Sz: -0.000000 | S^2:  0.084585
iter: 49 | loss: -1.540082 | norm:  0.358917 | fidelity:  0.941651 | Sz: -0.000000 | S^2:  0.092900
iter: 50 | loss: -1.540187 | norm:  0.376991 | fidelity:  0.939597 | Sz: -0.000000 | S^2:  0.100095
iter: 51 | loss: -1.540002 | norm:  0.347641 | fidelity:  0.937350 | Sz:  0.000000 | S^2:  0.105471
iter: 52 | loss: -1.539543 | norm:  0.310613 | fidelity:  0.935292 | Sz: -0.000000 | S^2:  0.108534
iter: 53 | loss: -1.538853 | norm:  0.323420 | fidelity:  0.933696 | Sz:  0.000000 | S^2:  0.109055
iter: 54 | loss: -1.538812 | norm:  0.349330 | fidelity:  0.932760 | Sz: -0.000000 | S^2:  0.107117
iter: 55 | loss: -1.540143 | norm:  0.324785 | fidelity:  0.932563 | Sz:  0.000000 | S^2:  0.103109
iter: 56 | loss: -1.542154 | norm:  0.246630 | fidelity:  0.933000 | Sz: -0.000000 | S^2:  0.097666
iter: 57 | loss: -1.543381 | norm:  0.186776 | fidelity:  0.933860 | Sz: -0.000000 | S^2:  0.091564
iter: 58 | loss: -1.543321 | norm:  0.216659 | fidelity:  0.934935 | Sz: -0.000000 | S^2:  0.085566
iter: 59 | loss: -1.542852 | norm:  0.255833 | fidelity:  0.936045 | Sz: -0.000000 | S^2:  0.080264
iter: 60 | loss: -1.542891 | norm:  0.244075 | fidelity:  0.936979 | Sz: -0.000000 | S^2:  0.076015
iter: 61 | loss: -1.543324 | norm:  0.200568 | fidelity:  0.937482 | Sz: -0.000000 | S^2:  0.072959
iter: 62 | loss: -1.543553 | norm:  0.182100 | fidelity:  0.937342 | Sz: -0.000000 | S^2:  0.071094
iter: 63 | loss: -1.543519 | norm:  0.195352 | fidelity:  0.936515 | Sz: -0.000000 | S^2:  0.070331
iter: 64 | loss: -1.543606 | norm:  0.194742 | fidelity:  0.935113 | Sz: -0.000000 | S^2:  0.070524
iter: 65 | loss: -1.543930 | norm:  0.173123 | fidelity:  0.933351 | Sz:  0.000000 | S^2:  0.071476
iter: 66 | loss: -1.544228 | norm:  0.161054 | fidelity:  0.931501 | Sz: -0.000000 | S^2:  0.072938
iter: 67 | loss: -1.544343 | norm:  0.165846 | fidelity:  0.929879 | Sz: -0.000000 | S^2:  0.074627
iter: 68 | loss: -1.544393 | norm:  0.157655 | fidelity:  0.928790 | Sz:  0.000000 | S^2:  0.076275
iter: 69 | loss: -1.544440 | norm:  0.131428 | fidelity:  0.928432 | Sz:  0.000000 | S^2:  0.077678
iter: 70 | loss: -1.544409 | norm:  0.126022 | fidelity:  0.928840 | Sz:  0.000000 | S^2:  0.078727
iter: 71 | loss: -1.544368 | norm:  0.151465 | fidelity:  0.929911 | Sz: -0.000000 | S^2:  0.079403
iter: 72 | loss: -1.544560 | norm:  0.159165 | fidelity:  0.931443 | Sz:  0.000000 | S^2:  0.079754
iter: 73 | loss: -1.545000 | norm:  0.123713 | fidelity:  0.933165 | Sz:  0.000000 | S^2:  0.079872
iter: 74 | loss: -1.545331 | norm:  0.062541 | fidelity:  0.934794 | Sz:  0.000000 | S^2:  0.079884
iter: 75 | loss: -1.545242 | norm:  0.067420 | fidelity:  0.936106 | Sz: -0.000000 | S^2:  0.079933
iter: 76 | loss: -1.544901 | norm:  0.115778 | fidelity:  0.936992 | Sz:  0.000000 | S^2:  0.080151
iter: 77 | loss: -1.544723 | norm:  0.130401 | fidelity:  0.937426 | Sz:  0.000000 | S^2:  0.080616
iter: 78 | loss: -1.544867 | norm:  0.109088 | fidelity:  0.937424 | Sz: -0.000000 | S^2:  0.081332
iter: 79 | loss: -1.545136 | norm:  0.076759 | fidelity:  0.937018 | Sz:  0.000000 | S^2:  0.082227
iter: 80 | loss: -1.545304 | norm:  0.064332 | fidelity:  0.936282 | Sz:  0.000000 | S^2:  0.083180
iter: 81 | loss: -1.545313 | norm:  0.067508 | fidelity:  0.935355 | Sz:  0.000000 | S^2:  0.084047
iter: 82 | loss: -1.545228 | norm:  0.070900 | fidelity:  0.934423 | Sz: -0.000000 | S^2:  0.084678
iter: 83 | loss: -1.545130 | norm:  0.078398 | fidelity:  0.933665 | Sz:  0.000000 | S^2:  0.084933
iter: 84 | loss: -1.545123 | norm:  0.083733 | fidelity:  0.933223 | Sz: -0.000000 | S^2:  0.084712
iter: 85 | loss: -1.545243 | norm:  0.072756 | fidelity:  0.933145 | Sz:  0.000000 | S^2:  0.083989
iter: 86 | loss: -1.545391 | norm:  0.045071 | fidelity:  0.933375 | Sz:  0.000000 | S^2:  0.082836
iter: 87 | loss: -1.545432 | norm:  0.030882 | fidelity:  0.933786 | Sz:  0.000000 | S^2:  0.081403
iter: 88 | loss: -1.545367 | norm:  0.051427 | fidelity:  0.934233 | Sz: -0.000000 | S^2:  0.079887
iter: 89 | loss: -1.545307 | norm:  0.062396 | fidelity:  0.934590 | Sz:  0.000000 | S^2:  0.078489
iter: 90 | loss: -1.545321 | norm:  0.055051 | fidelity:  0.934770 | Sz:  0.000000 | S^2:  0.077394
iter: 91 | loss: -1.545367 | norm:  0.042438 | fidelity:  0.934737 | Sz:  0.000000 | S^2:  0.076741
iter: 92 | loss: -1.545388 | norm:  0.040402 | fidelity:  0.934507 | Sz:  0.000000 | S^2:  0.076602
iter: 93 | loss: -1.545392 | norm:  0.041891 | fidelity:  0.934150 | Sz:  0.000000 | S^2:  0.076957
iter: 94 | loss: -1.545397 | norm:  0.038846 | fidelity:  0.933759 | Sz: -0.000000 | S^2:  0.077697
iter: 95 | loss: -1.545407 | norm:  0.037743 | fidelity:  0.933427 | Sz: -0.000000 | S^2:  0.078654
iter: 96 | loss: -1.545413 | norm:  0.039563 | fidelity:  0.933220 | Sz: -0.000000 | S^2:  0.079637
iter: 97 | loss: -1.545424 | norm:  0.035738 | fidelity:  0.933176 | Sz:  0.000000 | S^2:  0.080478
iter: 98 | loss: -1.545435 | norm:  0.027585 | fidelity:  0.933300 | Sz: -0.000000 | S^2:  0.081064
iter: 99 | loss: -1.545431 | norm:  0.029065 | fidelity:  0.933566 | Sz: -0.000000 | S^2:  0.081350
iter: 100 | loss: -1.545429 | norm:  0.035816 | fidelity:  0.933931 | Sz:  0.000000 | S^2:  0.081366
iter: 101 | loss: -1.545439 | norm:  0.033326 | fidelity:  0.934329 | Sz:  0.000000 | S^2:  0.081194
iter: 102 | loss: -1.545459 | norm:  0.021109 | fidelity:  0.934693 | Sz: -0.000000 | S^2:  0.080940
iter: 103 | loss: -1.545463 | norm:  0.015945 | fidelity:  0.934963 | Sz: -0.000000 | S^2:  0.080702
iter: 104 | loss: -1.545449 | norm:  0.025293 | fidelity:  0.935101 | Sz: -0.000000 | S^2:  0.080553
iter: 105 | loss: -1.545436 | norm:  0.029034 | fidelity:  0.935097 | Sz:  0.000000 | S^2:  0.080525
iter: 106 | loss: -1.545445 | norm:  0.024883 | fidelity:  0.934977 | Sz:  0.000000 | S^2:  0.080615
iter: 107 | loss: -1.545458 | norm:  0.019395 | fidelity:  0.934772 | Sz:  0.000000 | S^2:  0.080782
iter: 108 | loss: -1.545468 | norm:  0.016845 | fidelity:  0.934529 | Sz: -0.000000 | S^2:  0.080971
iter: 109 | loss: -1.545472 | norm:  0.014728 | fidelity:  0.934291 | Sz: -0.000000 | S^2:  0.081117
iter: 110 | loss: -1.545466 | norm:  0.015196 | fidelity:  0.934089 | Sz: -0.000000 | S^2:  0.081167
iter: 111 | loss: -1.545460 | norm:  0.019268 | fidelity:  0.933950 | Sz:  0.000000 | S^2:  0.081086
iter: 112 | loss: -1.545459 | norm:  0.019990 | fidelity:  0.933881 | Sz: -0.000000 | S^2:  0.080867
iter: 113 | loss: -1.545469 | norm:  0.014259 | fidelity:  0.933883 | Sz:  0.000000 | S^2:  0.080537
iter: 114 | loss: -1.545477 | norm:  0.007024 | fidelity:  0.933946 | Sz:  0.000000 | S^2:  0.080146

learning rate =  0.007610990207291116
Find operators
1j [4^ 1^ 7 2] + -1j [7^ 2^ 4 1]
-1j [5^ 0^ 6 3] + 1j [6^ 3^ 5 0]
1j [4^ 1^ 6 3] + -1j [6^ 3^ 4 1]
1j [5^ 0^ 7 2] + -1j [7^ 2^ 5 0]
1j [5^ 4^ 7 6] + -1j [7^ 6^ 5 4]
1j [1^ 0^ 3 2] + -1j [3^ 2^ 1 0]
with max gradients
[0.20489754, 0.20489752, 0.15736769, 0.15306637, 0.061907753, 0.055070315]

iter: 115 | loss: -1.545472 | norm:  0.373013 | fidelity:  0.934049 | Sz: -0.000000 | S^2:  0.079763
iter: 116 | loss: -1.548182 | norm:  0.505939 | fidelity:  0.936156 | Sz:  0.000000 | S^2:  0.083385
iter: 117 | loss: -1.556010 | norm:  0.358920 | fidelity:  0.939341 | Sz:  0.000000 | S^2:  0.080706
iter: 118 | loss: -1.561205 | norm:  0.346240 | fidelity:  0.941867 | Sz: -0.000000 | S^2:  0.076355
iter: 119 | loss: -1.565614 | norm:  0.385844 | fidelity:  0.944444 | Sz:  0.000000 | S^2:  0.072043
iter: 120 | loss: -1.570426 | norm:  0.384466 | fidelity:  0.947251 | Sz: -0.000000 | S^2:  0.068601
iter: 121 | loss: -1.575524 | norm:  0.340348 | fidelity:  0.950219 | Sz: -0.000000 | S^2:  0.065621
iter: 122 | loss: -1.580220 | norm:  0.298947 | fidelity:  0.953301 | Sz:  0.000000 | S^2:  0.062494
iter: 123 | loss: -1.584311 | norm:  0.293788 | fidelity:  0.956499 | Sz:  0.000000 | S^2:  0.058639
iter: 124 | loss: -1.588211 | norm:  0.304805 | fidelity:  0.959829 | Sz: -0.000000 | S^2:  0.053914
iter: 125 | loss: -1.592281 | norm:  0.302348 | fidelity:  0.963256 | Sz: -0.000000 | S^2:  0.048634
iter: 126 | loss: -1.596455 | norm:  0.283994 | fidelity:  0.966725 | Sz: -0.000000 | S^2:  0.043189
iter: 127 | loss: -1.600444 | norm:  0.265076 | fidelity:  0.970163 | Sz: -0.000000 | S^2:  0.037904
iter: 128 | loss: -1.604055 | norm:  0.260386 | fidelity:  0.973495 | Sz:  0.000000 | S^2:  0.033049
iter: 129 | loss: -1.607347 | norm:  0.265807 | fidelity:  0.976668 | Sz: -0.000000 | S^2:  0.028821
iter: 130 | loss: -1.610531 | norm:  0.264010 | fidelity:  0.979646 | Sz: -0.000000 | S^2:  0.025277
iter: 131 | loss: -1.613706 | norm:  0.245629 | fidelity:  0.982405 | Sz:  0.000000 | S^2:  0.022338
iter: 132 | loss: -1.616746 | norm:  0.215850 | fidelity:  0.984913 | Sz: -0.000000 | S^2:  0.019862
iter: 133 | loss: -1.619473 | norm:  0.188711 | fidelity:  0.987172 | Sz: -0.000000 | S^2:  0.017705
iter: 134 | loss: -1.621847 | norm:  0.173523 | fidelity:  0.989225 | Sz:  0.000000 | S^2:  0.015729
iter: 135 | loss: -1.623951 | norm:  0.163825 | fidelity:  0.991098 | Sz: -0.000000 | S^2:  0.013820
iter: 136 | loss: -1.625897 | norm:  0.148388 | fidelity:  0.992811 | Sz: -0.000000 | S^2:  0.011923
iter: 137 | loss: -1.627683 | norm:  0.126403 | fidelity:  0.994347 | Sz:  0.000000 | S^2:  0.010052
iter: 138 | loss: -1.629232 | norm:  0.108471 | fidelity:  0.995683 | Sz:  0.000000 | S^2:  0.008258
iter: 139 | loss: -1.630488 | norm:  0.104358 | fidelity:  0.996799 | Sz:  0.000000 | S^2:  0.006589
iter: 140 | loss: -1.631500 | norm:  0.107575 | fidelity:  0.997711 | Sz:  0.000000 | S^2:  0.005079
iter: 141 | loss: -1.632343 | norm:  0.104377 | fidelity:  0.998438 | Sz:  0.000000 | S^2:  0.003747
iter: 142 | loss: -1.633051 | norm:  0.088697 | fidelity:  0.998998 | Sz:  0.000000 | S^2:  0.002611
iter: 143 | loss: -1.633633 | norm:  0.064482 | fidelity:  0.999418 | Sz: -0.000000 | S^2:  0.001684
iter: 144 | loss: -1.634043 | norm:  0.044195 | fidelity:  0.999701 | Sz: -0.000000 | S^2:  0.000972
iter: 145 | loss: -1.634296 | norm:  0.040843 | fidelity:  0.999874 | Sz: -0.000000 | S^2:  0.000469
iter: 146 | loss: -1.634429 | norm:  0.045814 | fidelity:  0.999958 | Sz: -0.000000 | S^2:  0.000156
iter: 147 | loss: -1.634491 | norm:  0.046132 | fidelity:  0.999980 | Sz:  0.000000 | S^2:  0.000015
iter: 148 | loss: -1.634498 | norm:  0.041379 | fidelity:  0.999950 | Sz:  0.000000 | S^2:  0.000024
iter: 149 | loss: -1.634442 | norm:  0.038105 | fidelity:  0.999879 | Sz: -0.000000 | S^2:  0.000153
iter: 150 | loss: -1.634330 | norm:  0.039993 | fidelity:  0.999778 | Sz: -0.000000 | S^2:  0.000365
iter: 151 | loss: -1.634186 | norm:  0.042941 | fidelity:  0.999665 | Sz:  0.000000 | S^2:  0.000617
iter: 152 | loss: -1.634035 | norm:  0.044275 | fidelity:  0.999552 | Sz:  0.000000 | S^2:  0.000878
iter: 153 | loss: -1.633893 | norm:  0.045760 | fidelity:  0.999449 | Sz:  0.000000 | S^2:  0.001123
iter: 154 | loss: -1.633765 | norm:  0.049469 | fidelity:  0.999361 | Sz:  0.000000 | S^2:  0.001342
iter: 155 | loss: -1.633653 | norm:  0.054734 | fidelity:  0.999291 | Sz:  0.000000 | S^2:  0.001522
iter: 156 | loss: -1.633565 | norm:  0.059220 | fidelity:  0.999243 | Sz: -0.000000 | S^2:  0.001656
iter: 157 | loss: -1.633518 | norm:  0.061694 | fidelity:  0.999222 | Sz: -0.000000 | S^2:  0.001741
iter: 158 | loss: -1.633492 | norm:  0.062193 | fidelity:  0.999211 | Sz:  0.000000 | S^2:  0.001779
iter: 159 | loss: -1.633502 | norm:  0.060552 | fidelity:  0.999215 | Sz: -0.000000 | S^2:  0.001771
iter: 160 | loss: -1.633543 | norm:  0.056728 | fidelity:  0.999232 | Sz:  0.000000 | S^2:  0.001719
iter: 161 | loss: -1.633607 | norm:  0.051963 | fidelity:  0.999264 | Sz:  0.000000 | S^2:  0.001625
iter: 162 | loss: -1.633685 | norm:  0.048417 | fidelity:  0.999309 | Sz:  0.000000 | S^2:  0.001497
iter: 163 | loss: -1.633773 | norm:  0.046906 | fidelity:  0.999367 | Sz: -0.000000 | S^2:  0.001343
iter: 164 | loss: -1.633865 | norm:  0.045609 | fidelity:  0.999430 | Sz: -0.000000 | S^2:  0.001174
iter: 165 | loss: -1.633973 | norm:  0.042964 | fidelity:  0.999505 | Sz:  0.000000 | S^2:  0.000998
iter: 166 | loss: -1.634076 | norm:  0.040014 | fidelity:  0.999580 | Sz:  0.000000 | S^2:  0.000824
iter: 167 | loss: -1.634170 | norm:  0.038356 | fidelity:  0.999654 | Sz:  0.000000 | S^2:  0.000657
iter: 168 | loss: -1.634254 | norm:  0.037098 | fidelity:  0.999721 | Sz:  0.000000 | S^2:  0.000506
iter: 169 | loss: -1.634331 | norm:  0.033720 | fidelity:  0.999780 | Sz:  0.000000 | S^2:  0.000373
iter: 170 | loss: -1.634404 | norm:  0.027533 | fidelity:  0.999834 | Sz: -0.000000 | S^2:  0.000261
iter: 171 | loss: -1.634460 | norm:  0.021288 | fidelity:  0.999878 | Sz:  0.000000 | S^2:  0.000171
iter: 172 | loss: -1.634502 | norm:  0.018551 | fidelity:  0.999914 | Sz: -0.000000 | S^2:  0.000103
iter: 173 | loss: -1.634540 | norm:  0.017755 | fidelity:  0.999947 | Sz:  0.000000 | S^2:  0.000056
iter: 174 | loss: -1.634567 | norm:  0.014683 | fidelity:  0.999970 | Sz:  0.000000 | S^2:  0.000025
iter: 175 | loss: -1.634590 | norm:  0.008913 | fidelity:  0.999988 | Sz: -0.000000 | S^2:  0.000008


convergence criterion has satisfied, break the loop!
total run time:  2225.160909175873
